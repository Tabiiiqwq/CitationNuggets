{
  "paper_id": "Quantized Side Tunin",
  "meta": {
    "title": "Quantized Side Tuning: Fast and Memory-Efficient Tuning ofQuantized Large Language Models",
    "section_ids": [],
    "paragraph_ids": []
  },
  "paper_pred": [
    [
      "TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation",
      "A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models",
      "Prompting PaLM for Translation: Assessing Strategies and Performance",
      "When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method",
      "QLoRA: Efficient Finetuning of Quantized LLMs",
      "Efficient Finetuning for Dimensional Speech Emotion Recognition in the Age of Transformers",
      "Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models",
      "LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation"
    ]
  ],
  "paper_gt": [
    [
      {
        "tag": "Warstadt et\u00a0al. (2019)",
        "title": "Neural network acceptability judgments.",
        "authors": "Alex Warstadt, Amanpreet Singh, and Samuel\u00a0R Bowman. 2019.",
        "journal": "Transactions of the Association for Computational Linguistics, 7:625\u2013641."
      },
      {
        "tag": "Edalati et\u00a0al. (2022)",
        "title": "Krona: Parameter efficient tuning with kronecker adapter.",
        "authors": "Ali Edalati, Marzieh Tahaei, Ivan Kobyzev, Vahid\u00a0Partovi Nia, James\u00a0J Clark, and Mehdi Rezagholizadeh. 2022.",
        "journal": "arXiv preprint arXiv:2212.10650."
      },
      {
        "tag": "Hinton et\u00a0al. (2015)",
        "title": "Distilling the knowledge in a neural network.",
        "authors": "Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.",
        "journal": "arXiv preprint arXiv:1503.02531."
      },
      {
        "tag": "Liao et\u00a0al. (2023)",
        "title": "Make your pre-trained model reversible: From parameter to memory efficient fine-tuning.",
        "authors": "Baohao Liao, Shaomu Tan, and Christof Monz. 2023.",
        "journal": "arXiv preprint arXiv:2306.00477."
      },
      {
        "tag": "Williams et\u00a0al. (2017)",
        "title": "A broad-coverage challenge corpus for sentence understanding through inference.",
        "authors": "Adina Williams, Nikita Nangia, and Samuel\u00a0R Bowman. 2017.",
        "journal": "arXiv preprint arXiv:1704.05426."
      },
      {
        "tag": "Radford et\u00a0al. (2019)",
        "title": "Language models are unsupervised multitask learners.",
        "authors": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et\u00a0al. 2019.",
        "journal": "OpenAI blog, 1(8):9."
      },
      {
        "tag": "Bentivogli et\u00a0al. (2009)",
        "title": "The fifth pascal recognizing textual entailment challenge.",
        "authors": "Luisa Bentivogli, Peter Clark, Ido Dagan, and Danilo Giampiccolo. 2009.",
        "journal": "TAC, 7:8."
      },
      {
        "tag": "Dosovitskiy et\u00a0al. (2020)",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale.",
        "authors": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et\u00a0al. 2020.",
        "journal": "arXiv preprint arXiv:2010.11929."
      },
      {
        "tag": "Chowdhery et\u00a0al. (2022)",
        "title": "Palm: Scaling language modeling with pathways.",
        "authors": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung\u00a0Won Chung, Charles Sutton, Sebastian Gehrmann, et\u00a0al. 2022.",
        "journal": "arXiv preprint arXiv:2204.02311."
      },
      {
        "tag": "Zhang et\u00a0al. (2022)",
        "title": "Opt: Open pre-trained transformer language models.",
        "authors": "Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi\u00a0Victoria Lin, et\u00a0al. 2022.",
        "journal": "arXiv preprint arXiv:2205.01068."
      },
      {
        "tag": "OpenAI (2023)",
        "title": "GPT-4 technical report.",
        "authors": "OpenAI. 2023.",
        "journal": "CoRR, abs/2303.08774."
      },
      {
        "tag": "Hu et\u00a0al. (2021)",
        "title": "Lora: Low-rank adaptation of large language models.",
        "authors": "Edward\u00a0J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu\u00a0Wang, and Weizhu Chen. 2021.",
        "journal": "arXiv preprint arXiv:2106.09685."
      },
      {
        "tag": "Houlsby et\u00a0al. (2019)",
        "title": "Parameter-efficient transfer learning for nlp.",
        "authors": "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De\u00a0Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019.",
        "journal": "InInternational Conference on Machine Learning, pages 2790\u20132799. PMLR."
      },
      {
        "tag": "Lester et\u00a0al. (2021)",
        "title": "The power of scale for parameter-efficient prompt tuning.",
        "authors": "Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.",
        "journal": "arXiv preprint arXiv:2104.08691."
      },
      {
        "tag": "Chen et\u00a0al. (2016)",
        "title": "Training deep nets with sublinear memory cost.",
        "authors": "Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. 2016.",
        "journal": "arXiv preprint arXiv:1604.06174."
      },
      {
        "tag": "Hendrycks et\u00a0al. (2020)",
        "title": "Measuring massive multitask language understanding.",
        "authors": "Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020.",
        "journal": "arXiv preprint arXiv:2009.03300."
      },
      {
        "tag": "Sung et\u00a0al. (2022)",
        "title": "Lst: Ladder side-tuning for parameter and memory efficient transfer learning.",
        "authors": "Yi-Lin Sung, Jaemin Cho, and Mohit Bansal. 2022.",
        "journal": "Advances in Neural Information Processing Systems, 35:12991\u201313005."
      },
      {
        "tag": "Wang et\u00a0al. (2018)",
        "title": "Glue: A multi-task benchmark and analysis platform for natural language understanding.",
        "authors": "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel\u00a0R Bowman. 2018.",
        "journal": "arXiv preprint arXiv:1804.07461."
      },
      {
        "tag": "Dolan and Brockett (2005)",
        "title": "Automatically constructing a corpus of sentential paraphrases.",
        "authors": "Bill Dolan and Chris Brockett. 2005.",
        "journal": "InThird International Workshop on Paraphrasing (IWP2005)."
      },
      {
        "tag": "Raffel et\u00a0al. (2020)",
        "title": "Exploring the limits of transfer learning with a unified text-to-text transformer.",
        "authors": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter\u00a0J Liu. 2020.",
        "journal": "The Journal of Machine Learning Research, 21(1):5485\u20135551."
      },
      {
        "tag": "Rusu et\u00a0al. (2016)",
        "title": "Progressive neural networks.",
        "authors": "Andrei\u00a0A Rusu, Neil\u00a0C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. 2016.",
        "journal": "arXiv preprint arXiv:1606.04671."
      },
      {
        "tag": "Taori et\u00a0al. (2023)",
        "title": "Stanford alpaca: An instruction-following llama model.",
        "authors": "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori\u00a0B. Hashimoto. 2023.",
        "journal": "https://github.com/tatsu-lab/stanford_alpaca."
      },
      {
        "tag": "Askell et\u00a0al. (2021)",
        "title": "A general language assistant as a laboratory for alignment.",
        "authors": "Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et\u00a0al. 2021.",
        "journal": "arXiv preprint arXiv:2112.00861."
      },
      {
        "tag": "Wang et\u00a0al. (2022b)",
        "title": "Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.",
        "authors": "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut\u00a0Selvan Dhanasekaran, Atharva Naik, David Stap, et\u00a0al. 2022b.",
        "journal": "arXiv preprint arXiv:2204.07705."
      },
      {
        "tag": "Liu et\u00a0al. (2022)",
        "title": "Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning.",
        "authors": "Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, and Colin\u00a0A Raffel. 2022.",
        "journal": "Advances in Neural Information Processing Systems, 35:1950\u20131965."
      },
      {
        "tag": "Bai et\u00a0al. (2022)",
        "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback.",
        "authors": "Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et\u00a0al. 2022.",
        "journal": "arXiv preprint arXiv:2204.05862."
      },
      {
        "tag": "Socher et\u00a0al. (2013)",
        "title": "Recursive deep models for semantic compositionality over a sentiment treebank.",
        "authors": "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher\u00a0D Manning, Andrew\u00a0Y Ng, and Christopher Potts. 2013.",
        "journal": "InProceedings of the 2013 conference on empirical methods in natural language processing, pages 1631\u20131642."
      },
      {
        "tag": "Pfeiffer et\u00a0al. (2020)",
        "title": "Adapterfusion: Non-destructive task composition for transfer learning.",
        "authors": "Jonas Pfeiffer, Aishwarya Kamath, Andreas R\u00fcckl\u00e9, Kyunghyun Cho, and Iryna Gurevych. 2020.",
        "journal": "arXiv preprint arXiv:2005.00247."
      },
      {
        "tag": "Iyer (2017)",
        "title": "First quora dataset release: Question pairs.",
        "authors": "Shankar Iyer. 2017.",
        "journal": "https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs."
      },
      {
        "tag": "Cer et\u00a0al. (2017)",
        "title": "Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation.",
        "authors": "Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia. 2017.",
        "journal": "arXiv preprint arXiv:1708.00055."
      },
      {
        "tag": "Kingma and Ba (2014)",
        "title": "Adam: A method for stochastic optimization.",
        "authors": "Diederik\u00a0P Kingma and Jimmy Ba. 2014.",
        "journal": "arXiv preprint arXiv:1412.6980."
      },
      {
        "tag": "Rajpurkar et\u00a0al. (2016)",
        "title": "Squad: 100,000+ questions for machine comprehension of text.",
        "authors": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.",
        "journal": "arXiv preprint arXiv:1606.05250."
      },
      {
        "tag": "Koratana et\u00a0al. (2019)",
        "title": "Lit: Learned intermediate representation training for model compression.",
        "authors": "Animesh Koratana, Daniel Kang, Peter Bailis, and Matei Zaharia. 2019.",
        "journal": "InInternational Conference on Machine Learning, pages 3509\u20133518. PMLR."
      },
      {
        "tag": "Schick and Sch\u00fctze (2020)",
        "title": "Exploiting cloze questions for few shot text classification and natural language inference.",
        "authors": "Timo Schick and Hinrich Sch\u00fctze. 2020.",
        "journal": "arXiv preprint arXiv:2001.07676."
      },
      {
        "tag": "Zhou et\u00a0al. (2023)",
        "title": "Autopeft: Automatic configuration search for parameter-efficient fine-tuning.",
        "authors": "Han Zhou, Xingchen Wan, Ivan Vuli\u0107, and Anna Korhonen. 2023.",
        "journal": "arXiv preprint arXiv:2301.12132."
      },
      {
        "tag": "Stiennon et\u00a0al. (2020)",
        "title": "Learning to summarize with human feedback.",
        "authors": "Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul\u00a0F Christiano. 2020.",
        "journal": "Advances in Neural Information Processing Systems, 33:3008\u20133021."
      },
      {
        "tag": "Zoph and Le (2016)",
        "title": "Neural architecture search with reinforcement learning.",
        "authors": "Barret Zoph and Quoc\u00a0V Le. 2016.",
        "journal": "arXiv preprint arXiv:1611.01578."
      },
      {
        "tag": "Wolf et\u00a0al. (2019)",
        "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing.",
        "authors": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, et\u00a0al. 2019.",
        "journal": "arXiv preprint arXiv:1910.03771."
      },
      {
        "tag": "Paszke et\u00a0al. (2017)",
        "title": "Automatic differentiation in pytorch.",
        "authors": "Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017.",
        "journal": ""
      },
      {
        "tag": "Scao et\u00a0al. (2022)",
        "title": "Bloom: A 176b-parameter open-access multilingual language model.",
        "authors": "Teven\u00a0Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili\u0107, Daniel Hesslow, Roman Castagn\u00e9, Alexandra\u00a0Sasha Luccioni, Fran\u00e7ois Yvon, Matthias Gall\u00e9, et\u00a0al. 2022.",
        "journal": "arXiv preprint arXiv:2211.05100."
      },
      {
        "tag": "Wang et\u00a0al. (2022a)",
        "title": "Self-instruct: Aligning language model with self generated instructions.",
        "authors": "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah\u00a0A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022a.",
        "journal": "arXiv preprint arXiv:2212.10560."
      },
      {
        "tag": "He et\u00a0al. (2021)",
        "title": "Towards a unified view of parameter-efficient transfer learning.",
        "authors": "Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. 2021.",
        "journal": "arXiv preprint arXiv:2110.04366."
      },
      {
        "tag": "Touvron et\u00a0al. (2023)",
        "title": "Llama: Open and efficient foundation language models.",
        "authors": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et\u00a0al. 2023.",
        "journal": "arXiv preprint arXiv:2302.13971."
      },
      {
        "tag": "Ouyang et\u00a0al. (2022)",
        "title": "Training language models to follow instructions with human feedback.",
        "authors": "Long Ouyang, Jeffrey Wu, Xu\u00a0Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et\u00a0al. 2022.",
        "journal": "Advances in Neural Information Processing Systems, 35:27730\u201327744."
      },
      {
        "tag": "Brown et\u00a0al. (2020)",
        "title": "Language models are few-shot learners.",
        "authors": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared\u00a0D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et\u00a0al. 2020.",
        "journal": "Advances in neural information processing systems, 33:1877\u20131901."
      },
      {
        "tag": "Mangalam et\u00a0al. (2022)",
        "title": "Reversible vision transformers.",
        "authors": "Karttikeya Mangalam, Haoqi Fan, Yanghao Li, Chao-Yuan Wu, Bo\u00a0Xiong, Christoph Feichtenhofer, and Jitendra Malik. 2022.",
        "journal": "InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10830\u201310840."
      },
      {
        "tag": "Liu et\u00a0al. (2023)",
        "title": "Gpt understands, too.",
        "authors": "Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2023.",
        "journal": "AI Open."
      },
      {
        "tag": "Min et\u00a0al. (2021)",
        "title": "Metaicl: Learning to learn in context.",
        "authors": "Sewon Min, Mike Lewis, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2021.",
        "journal": "arXiv preprint arXiv:2110.15943."
      },
      {
        "tag": "Mao et\u00a0al. (2021)",
        "title": "Unipelt: A unified framework for parameter-efficient language model tuning.",
        "authors": "Yuning Mao, Lambert Mathias, Rui Hou, Amjad Almahairi, Hao Ma, Jiawei Han, Wen-tau Yih, and Madian Khabsa. 2021.",
        "journal": "arXiv preprint arXiv:2110.07577."
      },
      {
        "tag": "Frankle and Carbin (2018)",
        "title": "The lottery ticket hypothesis: Finding sparse, trainable neural networks.",
        "authors": "Jonathan Frankle and Michael Carbin. 2018.",
        "journal": "arXiv preprint arXiv:1803.03635."
      },
      {
        "tag": "Kitaev et\u00a0al. (2020)",
        "title": "Reformer: The efficient transformer.",
        "authors": "Nikita Kitaev, \u0141ukasz Kaiser, and Anselm Levskaya. 2020.",
        "journal": "arXiv preprint arXiv:2001.04451."
      },
      {
        "tag": "Li and Liang (2021)",
        "title": "Prefix-tuning: Optimizing continuous prompts for generation.",
        "authors": "Xiang\u00a0Lisa Li and Percy Liang. 2021.",
        "journal": "arXiv preprint arXiv:2101.00190."
      },
      {
        "tag": "Frankle et\u00a0al. (2020)",
        "title": "Linear mode connectivity and the lottery ticket hypothesis.",
        "authors": "Jonathan Frankle, Gintare\u00a0Karolina Dziugaite, Daniel Roy, and Michael Carbin. 2020.",
        "journal": "InInternational Conference on Machine Learning, pages 3259\u20133269. PMLR."
      },
      {
        "tag": "Devlin et\u00a0al. (2018)",
        "title": "Bert: Pre-training of deep bidirectional transformers for language understanding.",
        "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.",
        "journal": "arXiv preprint arXiv:1810.04805."
      },
      {
        "tag": "Zheng et\u00a0al. (2023)",
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena.",
        "authors": "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi\u00a0Lin, Zhuohan Li, Dacheng Li, Eric.\u00a0P Xing, Hao Zhang, Joseph\u00a0E. Gonzalez, and Ion Stoica. 2023.",
        "journal": ""
      },
      {
        "tag": "Gomez et\u00a0al. (2017)",
        "title": "The reversible residual network: Backpropagation without storing activations.",
        "authors": "Aidan\u00a0N Gomez, Mengye Ren, Raquel Urtasun, and Roger\u00a0B Grosse. 2017.",
        "journal": "Advances in neural information processing systems, 30."
      },
      {
        "tag": "LeCun et\u00a0al. (1998)",
        "title": "Gradient-based learning applied to document recognition.",
        "authors": "Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. 1998.",
        "journal": "Proceedings of the IEEE, 86(11):2278\u20132324."
      },
      {
        "tag": "Dettmers et\u00a0al. (2023)",
        "title": "Qlora: Efficient finetuning of quantized llms.",
        "authors": "Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.",
        "journal": "arXiv preprint arXiv:2305.14314."
      },
      {
        "tag": "Zhang et\u00a0al. (2020)",
        "title": "Side-tuning: a baseline for network adaptation via additive side networks.",
        "authors": "Jeffrey\u00a0O Zhang, Alexander Sax, Amir Zamir, Leonidas Guibas, and Jitendra Malik. 2020.",
        "journal": "InComputer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part III 16, pages 698\u2013714. Springer."
      },
      {
        "tag": "Floridi and Chiriatti (2020)",
        "title": "Gpt-3: Its nature, scope, limits, and consequences.",
        "authors": "Luciano Floridi and Massimo Chiriatti. 2020.",
        "journal": "Minds and Machines, 30:681\u2013694."
      },
      {
        "tag": "Matthews (1975)",
        "title": "Comparison of the predicted and observed secondary structure of t4 phage lysozyme.",
        "authors": "Brian\u00a0W Matthews. 1975.",
        "journal": "Biochimica et Biophysica Acta (BBA)-Protein Structure, 405(2):442\u2013451."
      },
      {
        "tag": "Wei et\u00a0al. (2022)",
        "title": "Chain-of-thought prompting elicits reasoning in large language models.",
        "authors": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed\u00a0Chi, Quoc\u00a0V Le, Denny Zhou, et\u00a0al. 2022.",
        "journal": "Advances in Neural Information Processing Systems, 35:24824\u201324837."
      }
    ]
  ],
  "section_preds": [],
  "section_gts": [],
  "paragraph_preds": [],
  "paragraph_gts": []
}