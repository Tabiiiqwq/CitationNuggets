{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab83692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-based rendering (IBR) methods rely on a set of two-\n",
      "dimensional images of a scene to generate a representation\n",
      "of the scene and render novel views. The very first novel-\n",
      "view synthesis approaches were based on light fields ,\n",
      "and developed the concept of volume rendering for novel\n",
      "views. Their work emphasized the importance of efficiently\n",
      "traversing volumetric data to produce realistic images.\n",
      "\n",
      "Various scene representations have been proposed since,\n",
      "such as triangle meshes, point clouds, voxel grids, multi-\n",
      "plane images, or neural implicit functions.\n",
      "\n",
      "Traditional mesh-based IBR methods. Structure-from-\n",
      "motion (SfM)\n",
      " and subsequent multi-view stereo\n",
      "(MVS)  allow for 3D reconstruction of surfaces, lead-\n",
      "ing to the development of several view synthesis algorithms\n",
      "relying on triangle meshes as the primary 3D representa-\n",
      "tion of scenes. Such algorithms consider textured triangles\n",
      "or warp and blend captured images on the mesh surface to\n",
      "generate novel views .\n",
      " consider deep\n",
      "learning-based mesh representations for better view synthe-\n",
      "sis, bridging the gap between traditional graphics and mod-\n",
      "ern machine learning techniques. While these mesh-based\n",
      "methods take advantage of existing graphics hardware and\n",
      "software for efficient rendering, they struggle with the cap-\n",
      "ture of accurate geometry and appearance in complex re-\n",
      "gions.\n",
      "\n",
      "Volumetric IBR methods. Volumetric methods use voxel\n",
      "grids, multiplane images, or neural networks to represent\n",
      "scenes as continuous volumetric functions of density and\n",
      "color. Recently, Neural Radiance Fields (NeRF)  intro-\n",
      "duced a novel scene representation based on a continuous\n",
      "volumetric function parameterized by a multilayer percep-\n",
      "tron (MLP). NeRF produces photorealistic renderings with\n",
      "fine details and view-dependent effects, achieved through\n",
      "volumetric ray tracing. However, the original NeRF is com-\n",
      "putationally expensive and memory intensive.\n",
      "\n",
      "To address these challenges, several works have im-\n",
      "proved NeRF’s performance and scalability. These meth-\n",
      "ods leverage discretized or sparse volumetric representa-\n",
      "tions like voxel grids and hash tables as ways to store\n",
      "learnable features acting as positional encodings for 3D\n",
      "points , hierarchical sampling strate-\n",
      "gies , or low-rank approximations . How-\n",
      "ever, they still rely on volumetric ray marching, which\n",
      "is incompatible with standard graphics hardware and soft-\n",
      "ware designed for rendering polygonal surfaces. Recent\n",
      "works have proposed modifying the NeRF’s representation\n",
      "of geometry and emitted radiance to allow for better recon-\n",
      "struction of specular materials  or relighting the scene\n",
      "through an explicit decomposition into material and lighting\n",
      "properties .\n",
      "\n",
      "Hybrid IBR methods. Some methods build on differen-\n",
      "tiable rendering to combine the advantages of mesh-based\n",
      "and volumetric methods, and allow for surface reconstruc-\n",
      "tion as well as better editability. They use a hybrid volume-\n",
      "surface representation, which enables high-quality meshes\n",
      "suitable for downstream graphics applications while effi-\n",
      "ciently modeling view-dependent appearance.\n",
      "In partic-\n",
      "ular, some works optimize neural signed distance func-\n",
      "tions (SDF) by training neural radiance fields in which the\n",
      "density is derived as a differentiable transformation of the\n",
      "SDF . A triangle mesh can finally\n",
      "be reconstructed from the SDF by applying the Marching\n",
      "Cubes algorithm . However, most of these methods do\n",
      "not target real-time rendering.\n",
      "\n",
      "Alternatively, other approaches “bake” the rendering ca-\n",
      "pacity of an optimized NeRF or neural SDF into a much ef-\n",
      "ficient structure relying on an underlying triangle mesh \n",
      "that could benefit from the traditional triangle rasteriza-\n",
      "tion pipeline. In particular, the recent BakedSDF  re-\n",
      "constructs high quality meshes by optimizing a full neural\n",
      "SDF model, baking it into a high-resolution triangle mesh\n",
      "that combines mesh rendering for interpolating features and\n",
      "deep learning to translate these features into images, and\n",
      "finally optimizes a view-dependent appearance model.\n",
      "\n",
      "However, even though it achieves real-time rendering\n",
      "and produces impressive meshes of the surface of the scene,\n",
      "this model demands training a full neural SDF with an ar-\n",
      "chitecture identical to Mip-NeRF360 , which necessi-\n",
      "tates 48 hours of training.\n",
      "\n",
      "Similarly, the recent method NeRFMeshing  pro-\n",
      "poses to also bake any NeRF model into a mesh structure,\n",
      "achieving real-time rendering. However, the meshing per-\n",
      "formed in this method lowers the quality of the rendering\n",
      "and results in a PSNR much lower than our method. Ad-\n",
      "ditionally, this method still requires training a full NeRF\n",
      "model beforehand, and needs approximately an hour of\n",
      "training on 8 V100 NVIDIA GPUs to allow for mesh train-\n",
      "ing and extraction.\n",
      "\n",
      "Our method is much faster at retrieveing a 3D mesh from\n",
      "3D Gaussian Splatting, which is itself much faster than\n",
      "NeRFs. As our experiments show, our rendering done by\n",
      "bounding Gaussians to the mesh results in higher quality\n",
      "than previous solutions based on meshes.\n",
      "\n",
      "Point-based IBR methods. Alternatively, point-based\n",
      "representations for radiance field excel at modeling thin ge-\n",
      "ometry and leverage fast point rasterization pipelines to ren-\n",
      "der images using α-blending rather than ray-marching .\n",
      "In particular, the very recent 3D Gaussian Splatting.\n",
      "model  allows for optimizing and rendering scenes with\n",
      "speed and quality never seen before.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(r'data\\output\\processed_full_citation\\no_citations\\sugar.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9997b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': [['Marc Levoy and Pat Hanrahan. Light Field Rendering. In ACM SIGGRAPH, 1996. 3'], ['Noah Snavely, Steven M. Seitz, and Richard Szeliski. Photo Tourism: Exploring Photo Collections in 3D. In ACM SIG- GRAPH, 2006. 3, 4'], ['Michael Goesele, Noah Snavely, Brian Curless, Hugues Hoppe, and Steven Seitz. Multi-View Stereo for Community Photo Collections. In International Conference on Computer Vision, 2007. 3'], ['Chris Buehler, Michael Bosse, Leonard Mcmillan, Steven Gortler, and Michael Cohen. Unstructured Lumigraph Ren- dering. In ACM SIGGRAPH, 2001. 3', 'Peter Hedman, Julien Philip, True Price, Jan-Michael Frahm, George Drettakis, and Gabriel Brostow. Deep Blending for Free-Viewpoint Image-Based Rendering. In ACM SIG- GRAPH, 2018. 3, 7, 2, 4', 'Daniel N. Wood, Daniel I. Azuma, Ken Aldinger, Brian Cur- less, Tom Duchamp, David H. Salesin, and Werner Stuet- zle. Surface Light Fields for 3D Photography. In ACM SIG- GRAPH, 2000. 3'], ['Gernot Riegler and Vladlen Koltun. Free View Synthesis. In European Conference on Computer Vision, 2020. 3', 'Gernot Riegler and Vladlen Koltun. Stable View Synthesis. In Conference on Computer Vision and Pattern Recognition, 2021. 3'], ['Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. NeRF: Representing Scenes as Neural Radiance Fields for View In European Conference on Computer Vision, Synthesis. 2020. 1, 3'], ['Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and Hao Su. TensoRF: Tensorial Radiance Fields. In European Conference on Computer Vision, 2022. 3', 'Animesh Karnewar, Tobias Ritschel, Oliver Wang, and Niloy Mitra. ReLU Fields: The Little Non-Linearity That Could. In ACM SIGGRAPH, 2022. 3', 'Thomas M¨uller, Alex Evans, Christoph Schied, and Alexan- der Keller. Instant Neural Graphics Primitives with a Mul- tiresolution Hash Encoding. In ACM SIGGRAPH, 2022. 3, 7, 8, 2', 'Cheng Sun, Min Sun, and Hwann-Tzong Chen. Direct Voxel Grid Optimization: Super-Fast Convergence for Radiance In Conference on Computer Vision Fields Reconstruction. and Pattern Recognition, 2022. 3', 'Alex Yu, Sara Fridovich-Keil, Matthew Tancik, Qinhong Chen, Benjamin Recht, and Angjoo Kanazawa. Plenoxels: In Conference Radiance Fields Without Neural Networks. on Computer Vision and Pattern Recognition, 2022. 3, 7, 8'], ['Jonathan T. Barron. Mip-NeRF 360: Unbounded Anti- Aliased Neural Radiance Fields. In Conference on Computer Vision and Pattern Recognition, 2022. 3, 7, 8, 2, 4', 'Peter Hedman and Pratul P. Srinivasan. Baking Neural Radi- ance Fields for Real-Time View Synthesis. In International Conference on Computer Vision, 2021. 3', 'Christian Reiser, Songyou Peng, Yiyi Liao, and Andreas Geiger. KiloNeRF: Speeding Up Neural Radiance Fields with Thousands of Tiny MLPs. In International Conference on Computer Vision, 2021. 3', 'Alex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, and Angjoo Kanazawa. PlenOctrees For Real-Time Rendering of Neural Radiance Fields. In International Conference on Computer Vision, 2021. 3'], ['Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and Hao Su. TensoRF: Tensorial Radiance Fields. In European Conference on Computer Vision, 2022. 3'], ['SDF'], '[3, 18, 33, 43]', '[7, 8, 20, 24, 36, 38]', ['Mark Boss, Raphael Braun, Varun Jampani, Jonathan T. Bar- ron, Ce Liu, and Hendrik P. A. Lensch. NeRD: Neural Re- flectance Decomposition from Image Collections. In Inter- national Conference on Computer Vision, 2021. 3', 'Zhengfei Kuang, Kyle Olszewski, Menglei Chai, Zeng Huang, Panos Achlioptas, and Sergey Tulyakov. NeROIC: Neural Rendering of Objects from Online Image Collections. In ACM SIGGRAPH, 2022. 3', 'Pratul P. Srinivasan, Boyang Deng, Xiuming Zhang, Matthew Tancik, Ben Mildenhall, and Jonathan T. Barron. NeRV: Neural Reflectance and Visibility Fields for Relight- ing and View Synthesis. In Conference on Computer Vision and Pattern Recognition, 2021. 3', 'Kai Zhang, Fujun Luan, Qianqian Wang, Kavita Bala, and Noah Snavely. PhySG: Inverse Rendering with Spherical Gaussians for Physics-Based Material Editing and Relight- ing. In Conference on Computer Vision and Pattern Recog- nition, 2021. 3'], ['Chong Bao and Bangbang Yang, Zeng Junyi, Bao Hu- jun, Zhang Yinda, Cui Zhaopeng, and Zhang Guofeng. NeuMesh: Learning Disentangled Neural Mesh-Based Im- plicit Field for Geometry and Texture Editing. In European Conference on Computer Vision, 2022. 4', 'Franc¸ois Darmon, B´en´edicte Bascle, Jean-Cl´ement Devaux, Pascal Monasse, and Mathieu Aubry. Improving Neural Im- plicit Surfaces Geometry with Patch Warping. In Conference on Computer Vision and Pattern Recognition, 2022. 4', 'Zhaoshuo Li, Thomas M¨uller, Alex Evans, Russell H. Tay- lor, Mathias Unberath, Ming-Yu Liu, and Chen-Hsuan Lin. Neuralangelo: High-Fidelity Neural Surface Reconstruction. In Conference on Computer Vision and Pattern Recognition, 2023. 2, 4', 'Michael Oechsle, Songyou Peng, and Andreas Geiger. UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction. In International Con- ference on Computer Vision, 2021. 4', 'Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. NeuS: Learning Neural Im- plicit Surfaces by Volume Rendering for Multi-View Recon- In Advances in Neural Information Processing struction. Systems, 2021. 2, 4', 'Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. Vol- ume Rendering of Neural Implicit Surfaces. In Advances in Neural Information Processing Systems, 2021. 2, 4'], ['William E. Lorensen and Harvey E. Cline. Marching Cubes: A High Resolution 3D Surface Construction Algorithm. In ACM SIGGRAPH, 1987. 2, 4, 8 9 Structured View-Dependent Appearance for Neural Radi- ance Fields. In Conference on Computer Vision and Pattern Recognition, 2022. 3'], ['Zhiqin Chen, Thomas Funkhouser, Peter Hedman, and An- drea Tagliasacchi. MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures. In Conference on Computer Vision and Pattern Recognition, 2023. 3, 4, 7, 8'], ['Lior Yariv, Peter Hedman, Christian Reiser, Dor Verbin, Pratul P. Srinivasan, Richard Szeliski, and Jonathan T. Bar- ron. BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis. In ACM SIGGRAPH, 2023. 2, 3, 4, 7, 8'], ['Jonathan T. Barron. Mip-NeRF: A Multiscale Representa- tion for Anti-Aliasing Neural Radiance Fields. In Interna- tional Conference on Computer Vision, 2021. 4, 7'], ['Marie-Julie Rakotosaona, Fabian Manhardt, Diego Martin Arroyo, Michael Niemeyer, Abhijit Kundu, and Federico Tombari. NeRFMeshing: Distilling Neural Radiance Fields into Geometrically-Accurate 3D Meshes. In DV, 2023. 2, 3, 4, 7, 8'], ['Georgios Kopanas, Julien Philip, Thomas Leimk¨uhler, and George Drettakis. Point-Based Neural Rendering with Per- View Optimization. In Computer Graphics Forum, 2021. 4', 'Darius R¨uckert, Linus Franke, and Marc Stamminger. ADOP: Approximate Differentiable One-Pixel Point Ren- dering. In ACM SIGGRAPH, 2022. 4'], ['Bernhard Kerbl, Georgios Kopanas, Thomas Leimk¨uhler, and George Drettakis. 3D Gaussian Splatting for Real-Time Radiance Field Rendering. In ACM SIGGRAPH, 2023. 1, 2, 4, 7, 8']], 'positions': [229, 628, 668, 971, 973, 1562, 2190, 2227, 2256, 2580, 1851, 2433, 2640, 3223, 3324, 3565, 3676, 4178, 4265, 5182, 5244]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(r'data\\output\\processed_full_citation\\citations\\sugar.json', 'r') as f:\n",
    "    citations = json.load(f)\n",
    "print(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5be00d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "and developed the \n",
      "--------------------------------------------------\n",
      " and subsequent mult\n",
      "--------------------------------------------------\n",
      " allow for 3D recons\n",
      "--------------------------------------------------\n",
      ".\n",
      " consider deep\n",
      "lea\n",
      "--------------------------------------------------\n",
      " consider deep\n",
      "learn\n",
      "--------------------------------------------------\n",
      " intro-\n",
      "duced a nove\n",
      "--------------------------------------------------\n",
      ", hierarchical sampl\n",
      "--------------------------------------------------\n",
      ", or low-rank approx\n",
      "--------------------------------------------------\n",
      ". How-\n",
      "ever, they st\n",
      "--------------------------------------------------\n",
      " or relighting the s\n",
      "--------------------------------------------------\n",
      "is com-\n",
      "putationally\n",
      "--------------------------------------------------\n",
      "orks have proposed m\n",
      "--------------------------------------------------\n",
      "nto material and lig\n",
      "--------------------------------------------------\n",
      "erentiable transform\n",
      "--------------------------------------------------\n",
      "pplying the Marching\n",
      "--------------------------------------------------\n",
      "lying on an underlyi\n",
      "--------------------------------------------------\n",
      ". In particular, the\n",
      "--------------------------------------------------\n",
      "\n",
      "chitecture identica\n",
      "--------------------------------------------------\n",
      "larly, the recent me\n",
      "--------------------------------------------------\n",
      " α-blending rather t\n",
      "--------------------------------------------------\n",
      " recent 3D Gaussian \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "positions = citations['positions']\n",
    "for p in positions:\n",
    "    print(text[p:p+20])\n",
    "    print('-----'*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AINuggets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
