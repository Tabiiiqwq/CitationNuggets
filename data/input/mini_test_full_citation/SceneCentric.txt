Approaches for unsupervised segmentation tasks have been
significantly influenced by the literature on self-supervised
learning (SSL) and low-level vision tasks (e.g., optical flow
estimation), which we review first.
Self-supervised representation learning focuses on learn-
ing generic feature extractors from unlabeled data, aiming
for expressive features that facilitate a broad range of down-
stream tasks ++ref++[ (Linus Ericsson, Henry Gouk, Chen Change Loy, and Timo- thy M. Hospedales. Self-supervised representation learning: Introduction, advances, and challenges. IEEE Trans. Signal Process., 39(3):42–62, 2022. 2) ]++ref++. To that end, various self-supervised pre-
text tasks have been proposed ++ref++[ (Saleh Albelwi. Survey on self-supervised learning: Auxil- iary pretext tasks and contrastive learning methods in imag- ing. Entropy, 24(4):551, 2022. 2), (Linus Ericsson, Henry Gouk, Chen Change Loy, and Timo- thy M. Hospedales. Self-supervised representation learning: Introduction, advances, and challenges. IEEE Trans. Signal Process., 39(3):42–62, 2022. 2) ]++ref++. The development
of Vision Transformers (ViTs) ++ref++[ (Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16×16 words: Transformers for image recognition at scale. In ICLR, 2021. 2) ]++ref++ shaped current pretext
tasks while allowing for data-scalable training ++ref++[ (Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg- ing properties in self-supervised vision transformers. In ICCV, pages 9650–9660, 2021. 2, 3, 4, ii), (Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick. Masked autoencoders are scalable vision learners. In CVPR, pages 16000–16009, 2022. 2) ]++ref++.
Current approaches typically train ViTs on contrastive ++ref++[ (Philip Bachman, R. Devon Hjelm, and William Buchwalter. Learning representations by maximizing mutual information across views. In NeurIPS, pages 15509–15519, 2019. 2), (Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He. Improved baselines with momentum contrastive learning. arXiv:2003.04297 [cs.CV], 2020. 2, 6, ii), (Xinlei Chen, Saining Xie, and Kaiming He. An empiri- cal study of training self-supervised vision transformers. In CVPR, pages 9640–9649, 2021. 2), (Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In CVPR, pages 9729–9738, 2020. 2, 5) ]++ref++, negative-free ++ref++[ (Adrien Bardes, Jean Ponce, and Yann LeCun. VICRegL: Self-supervised learning of local visual features. In NeurIPS, pages 8799–8810, 2022. 2), (Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg- ing properties in self-supervised vision transformers. In ICCV, pages 9650–9660, 2021. 2, 3, 4, ii), (Xinlei Chen and Kaiming He. Exploring simple Siamese In CVPR, pages 15750–15758, representation learning. 2021. 2), (Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Ghesh- laghi Azar, et al. Bootstrap your own latent: A new approach to self-supervised learning. In NeurIPS, pages 21271–21284, 2020. 2), (Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy V. Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mido Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, 10 et al. DINOv2: Learning robust visual features without su- pervision. Trans. Mach. Learn. Res., 2024. 2 Unsupervised zero-shot segmentation using stable diffusion. In CVPR, pages 3554–3563, 2024. 3, 7) ]++ref++, clustering-
based ++ref++[ (Yuki Markus Asano, Christian Rupprecht, and Andrea Vedaldi. Self-labelling via simultaneous clustering and rep- resentation learning. In ICLR, 2020. 2), (Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. Deep clustering for unsupervised learning of visual features. In ECCV, pages 132–149, 2018. 2), (Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Pi- otr Bojanowski, and Armand Joulin. Unsupervised learn- ing of visual features by contrasting cluster assignments. In NeurIPS, pages 9912–9924, 2020. 2) ]++ref++, or masked modeling ++ref++[ (Agrim Gupta, Jiajun Wu, Jia Deng, and Li Fei-Fei. Siamese In NeurIPS, pages 40676–40693, masked autoencoders. 2023. 2), (Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick. Masked autoencoders are scalable vision learners. In CVPR, pages 16000–16009, 2022. 2), (Duy Kien Nguyen, Yanghao Li, Vaibhav Aggarwal, Mar- tin R. Oswald, Alexander Kirillov, Cees G. M. Snoek, and Xinlei Chen. R-MAE: Regions meet masked autoencoders. In ICLR, 2024. 2) ]++ref++ pretext
tasks. Recent state-of-the-art models (e.g., DINO ++ref++[ (Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg- ing properties in self-supervised vision transformers. In ICCV, pages 9650–9660, 2021. 2, 3, 4, ii) ]++ref++) of-
fer semantically rich and dense features suitable for unsu-
pervised scene understanding ++ref++[ (Mark Hamilton, Zhoutong Zhang, Bharath Hariharan, Noah Snavely, and William T. Freeman. Unsupervised semantic segmentation by distilling feature correspondences. In ICLR, 2022. 2, 3, 6, 7, i, ii, iii), (Xudong Wang, Rohit Girdhar, Stella X. Yu, and Ishan Misra. Cut and learn for unsupervised object detection and instance segmentation. In CVPR, pages 3124–3134, 2023. 2, 3, 5, 6, 7, iv, v, vi) ]++ref++.

Unsupervised optical flow is concerned with learning op-
tical flow estimation without the need for ground-truth data.
While early deep networks relied on synthetic ground-truth
flow for supervision ++ref++[ (Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Häusser, Caner Hazırba¸s, Vladimir Golkov, Patrick v. d. Smagt, Daniel Cremers, and Thomas Brox. FlowNet: Learn- ing optical flow with convolutional networks. In ICCV, pages 2758–2766, 2015. 3), (Nikolaus Mayer, Eddy Ilg, Philip Hausser, Philipp Fischer, Daniel Cremers, Alexey Dosovitskiy, and Thomas Brox. A large dataset to train convolutional networks for disparity, In CVPR, pages optical flow, and scene flow estimation. 4040–4048, 2016. 3), (Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz. PWC-Net: CNNs for optical flow using pyramid, warping, and cost volume. In CVPR, pages 8934–8943, 2018. 3), (Zachary Teed and Jia Deng. RAFT: Recurrent all-pairs field transforms for optical flow. In ECCV, pages 402–419, 2022. 3, iii, iv) ]++ref++, the domain gap to real
videos, among other factors, has prompted the development
of unsupervised deep optical flow pipelines ++ref++[ (Rico Jonschkowski, Austin Stone, Jonathan T. Barron, Ariel Gordon, Kurt Konolige, and Anelia Angelova. What mat- ters in unsupervised optical flow. In ECCV, pages 557–572, 2020. 3), (Gal Lifshitz and Dan Raviv. Cost function unrolling in un- IEEE Trans. Pattern Anal. Mach. supervised optical flow. Intell., 46(2):869–880, 2024. 3), (Rémi Marsal, Florian Chabot, Angélique Loesch, and Hichem Sahbi. BrightFlow: Brightness-change-aware un- supervised learning of optical flow. In WACV, pages 2061– 2070, 2023. 3), (Simon Meister, Junhwa Hur, and Stefan Roth. UnFlow: Un- supervised learning of optical flow with a bidirectional cen- sus loss. In AAAI, pages 7251–7259, 2018. 3), (Jason J. Yu, Adam W. Harley, and Konstantinos G. Derpa- nis. Back to basics: Unsupervised learning of optical flow via brightness constancy and motion smoothness. In ECCV Workshops, pages 3–10, 2016. 3) ]++ref++. Current unsupervised optical flow methods (e.g.,
SMURF ++ref++[ (Austin Stone, Daniel Maurer, Alper Ayvaci, Anelia An- gelova, and Rico Jonschkowski. SMURF: Self-teaching multi-frame unsupervised RAFT with full-image warping. In CVPR, pages 3887–3896, 2021. 3, i, iii, iv) ]++ref++) offer accurate flow estimates, fast inference,
and generalization to various real-world domains.

Unsupervised instance segmentation aims to discover and
segment object instances in images ++ref++[ (Oriane Siméoni, Éloi Zablocki, Spyros Gidaris, Gilles Puy, and Patrick Pérez. Unsupervised object localization in the era of self-supervised ViTs: A survey. Int. J. Comput. Vis., 133(2):781–808, 2025. 3) ]++ref++. Recent work
++ref++[ (Oriane Siméoni, Gilles Puy, Huy V. Vo, Simon Roburin, Spyros Gidaris, Andrei Bursuc, Patrick Pérez, Renaud Mar- let, and Jean Ponce. Localizing objects with self-supervised transformers and no labels. In BMVC, 2021. 2, 3), (Wouter Van Gansbeke, Simon Vandenhende, and Luc Van Gool. Discovering object masks with transformers for unsupervised semantic segmentation. arXiv:2206.06363 [cs.CV], 2022. 3), (Xinlong Wang, Zhiding Yu, Shalini De Mello, Jan Kautz, Anima Anandkumar, Chunhua Shen, and José M. Álvarez. FreeSOLO: Learning to segment objects without annota- tions. In CVPR, pages 14156–14166, 2022. 2, 3), (Xudong Wang, Rohit Girdhar, Stella X. Yu, and Ishan Misra. Cut and learn for unsupervised object detection and instance segmentation. In CVPR, pages 3124–3134, 2023. 2, 3, 5, 6, 7, iv, v, vi), (XuDong Wang, Jingfeng Yang, and Trevor Darrell. Segment In NeurIPS, pages 138731– anything without supervision. 138755, 2024. 3, ix) ]++ref++ bootstraps class-agnostic instance segmen-
tation networks using pseudo labels extracted from SSL fea-
tures on object-centric data. TokenCut ++ref++[ (Yangtao Wang, Xi Shen, Yuan Yuan, Yuming Du, Maomao Li, Shell Xu Hu, James L. Crowley, and Dominique Vaufrey- daz. TokenCut: Segmenting objects in images and videos with self-supervised transformer and normalized cut. IEEE Trans. Pattern Anal. Mach. Intell., 45(12):15790–15801, 2023. 2, 3) ]++ref++ applies normal-
ized cuts [N-Cut, 61] to DINO features, providing a fore-
ground pseudo mask. CutLER ++ref++[ (Xudong Wang, Rohit Girdhar, Stella X. Yu, and Ishan Misra. Cut and learn for unsupervised object detection and instance segmentation. In CVPR, pages 3124–3134, 2023. 2, 3, 5, 6, 7, iv, v, vi) ]++ref++ proposes MaskCut by
iteratively applying N-Cuts, retrieving up to three pseudo
masks per image. A second stream of works uses motion
cues to obtain an unsupervised signal for object discov-
ery ++ref++[ (Subhabrata Choudhury, Laurynas Karazija, Iro Laina, An- drea Vedaldi, and Christian Rupprecht. Guess What Moves: Unsupervised video and image segmentation by anticipating motion. In BMVC, 2022. 3), (Laurynas Karazija, Subhabrata Choudhury, Iro Laina, Chris- tian Rupprecht, and Andrea Vedaldi. Unsupervised multi- object segmentation by predicting probable motion patterns. In NeurIPS, pages 2128–2141, 2022. 3), (Runtao Liu, Zhirong Wu, Stella Yu, and Stephen Lin. The emergence of objectness: Learning zero-shot segmentation from videos. In NeurIPS, pages 13137–13152, 2021. 3), (Sadra Safadoust and Fatma Güney. Multi-object discovery by low-dimensional object motion. In ICCV, pages 734–744, 2023. 3), (Yihong Sun and Bharath Hariharan. MOD-UV: Learning In ECCV, mobile object detectors from unlabeled videos. pages 289–307, 2024. 3, 6, 7), (Yanchao Yang, Brian Lai, and Stefano Soatto. DyStaB: Unsupervised object segmentation via dynamic-static boot- strapping. In CVPR, pages 2826–2836, 2021. 3) ]++ref++. SF2SE3 ++ref++[ (Leonhard Sommer, Philipp Schröppel, and Thomas Brox. SF2SE3: Clustering scene flow into SE(3)-motions via pro- posal and selection. In GCPR, pages 215–229, 2022. 3, 4, i) ]++ref++ clusters scene
flow from consecutive stereo frames into independent rigid
object motions in SE (3) space, improving object segmen-
tation and motion accuracy. MOD-UV ++ref++[ (Yihong Sun and Bharath Hariharan. MOD-UV: Learning In ECCV, mobile object detectors from unlabeled videos. pages 289–307, 2024. 3, 6, 7) ]++ref++ uses motion
segmentation for pseudo labeling and multi-stage training.

Unsupervised semantic segmentation is approached by
early deep learning methods via representation learning
++ref++[ (Jang Hyun Cho, Utkarsh Mall, Kavita Bala, and Bharath Hariharan. PiCIE: Unsupervised semantic segmentation us- In CVPR, ing invariance and equivariance in clustering. pages 16794–16804, 2021. 3, 6, 7, ii, iii), (Robert Harb and Patrick Knöbelreiter. InfoSeg: Unsuper- vised semantic image segmentation with mutual information maximization. In GCPR, pages 18–32, 2021. 3), (Xu Ji, Joao F. Henriques, and Andrea Vedaldi. Invariant information clustering for unsupervised image classification and segmentation. In ICCV, pages 9865–9874, 2019. 3, 6, ii, iii) ]++ref++. STEGO ++ref++[ (Mark Hamilton, Zhoutong Zhang, Bharath Hariharan, Noah Snavely, and William T. Freeman. Unsupervised semantic segmentation by distilling feature correspondences. In ICLR, 2022. 2, 3, 6, 7, i, ii, iii) ]++ref++ leverages the self-supervised
DINO features as an inductive prior and distills the fea-
tures into a lower-dimensional space before unsupervised
probing. Later, ++ref++[ (Chanyoung Kim, Woojung Han, Dayun Ju, and Seong Jae Hwang. EAGLE: Eigen aggregation learning for object- In CVPR, centric unsupervised semantic segmentation. pages 3523–3533, 2024. 2, 3, 7), (Hyun Seok Seong, WonJun Moon, SuBeen Lee, and Jae-Pil Heo. Leveraging hidden positives for unsupervised semantic segmentation. In CVPR, pages 19540–19549, 2023. 2, 3, 7), (Leon Sick, Dominik Engel, Pedro Hermosilla, and Timo Ropinski. Unsupervised semantic segmentation through In CVPR, depth-guided feature correlation and sampling. pages 3637–3646, 2024. 2, 3, 4, 6, 7, i, ii, iii, v, vi) ]++ref++ proposed improvements to the
feature distillation or probing ++ref++[ (Oliver Hahn, Nikita Araslanov, Simone Schaub-Meyer, and Stefan Roth. Boosting unsupervised semantic segmentation with principal mask proposals. Trans. Mach. Learn. Res., 2024. 3, 7) ]++ref++. DepthG ++ref++[ (Leon Sick, Dominik Engel, Pedro Hermosilla, and Timo Ropinski. Unsupervised semantic segmentation through In CVPR, depth-guided feature correlation and sampling. pages 3637–3646, 2024. 2, 3, 4, 6, 7, i, ii, iii, v, vi) ]++ref++ extends
STEGO by spatially correlating the feature maps with depth
maps and furthest point sampling in the contrastive loss.
DiffSeg ++ref++[ (Junjiao Tian, Lavisha Aggarwal, Andrea Colaco, Zsolt Kira, and Mar González-Franco. Diffuse, attend, and segment:) ]++ref++ utilizes Stable Diffusion ++ref++[ (Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image syn- thesis with latent diffusion models. In CVPR, pages 10684– 10695, 2022. 3) ]++ref++ and iterative at-
tention merging for unsupervised semantic segmentation.

Unsupervised panoptic segmentation is a nascent re-
search avenue following recent advancements in unsuper-
vised semantic and instance segmentation. To the best of
our knowledge, U2Seg ++ref++[ (Dantong Niu, Xudong Wang, Xinyang Han, Long Lian, Roei Herzig, and Trevor Darrell. Unsupervised universal image segmentation. In CVPR, pages 22744–22754, 2024. 1, 2, 3, 6, 7, 8, i, ii, iv, v, vi, vii, viii, ix) ]++ref++ is the only method to date to approach unsupervised panoptic segmentation. U2Seg
leverages STEGO ++ref++[ (Mark Hamilton, Zhoutong Zhang, Bharath Hariharan, Noah Snavely, and William T. Freeman. Unsupervised semantic segmentation by distilling feature correspondences. In ICLR, 2022. 2, 3, 6, 7, i, ii, iii) ]++ref++ and CutLER ++ref++[ (Xudong Wang, Rohit Girdhar, Stella X. Yu, and Ishan Misra. Cut and learn for unsupervised object detection and instance segmentation. In CVPR, pages 3124–3134, 2023. 2, 3, 5, 6, 7, iv, v, vi) ]++ref++ to create panoptic
pseudo labels for training a panoptic network. However, its
dependence on CutLER’s MaskCut approach significantly
In contrast, we
limits its accuracy on scene-centric data.
present the first unsupervised panoptic approach that learns
directly from scene-centric data, addressing key limitations
of U2Seg and MaskCut.

