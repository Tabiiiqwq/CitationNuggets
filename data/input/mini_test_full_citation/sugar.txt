Image-based rendering (IBR) methods rely on a set of two-
dimensional images of a scene to generate a representation
of the scene and render novel views. The very first novel-
view synthesis approaches were based on light fields ++ref++[ (Marc Levoy and Pat Hanrahan. Light Field Rendering. In ACM SIGGRAPH, 1996. 3) ]++ref++,
and developed the concept of volume rendering for novel
views. Their work emphasized the importance of efficiently
traversing volumetric data to produce realistic images.

Various scene representations have been proposed since,
such as triangle meshes, point clouds, voxel grids, multi-
plane images, or neural implicit functions.

Traditional mesh-based IBR methods. Structure-from-
motion (SfM)
++ref++[ (Noah Snavely, Steven M. Seitz, and Richard Szeliski. Photo Tourism: Exploring Photo Collections in 3D. In ACM SIG- GRAPH, 2006. 3, 4) ]++ref++ and subsequent multi-view stereo
(MVS) ++ref++[ (Michael Goesele, Noah Snavely, Brian Curless, Hugues Hoppe, and Steven Seitz. Multi-View Stereo for Community Photo Collections. In International Conference on Computer Vision, 2007. 3) ]++ref++ allow for 3D reconstruction of surfaces, lead-
ing to the development of several view synthesis algorithms
relying on triangle meshes as the primary 3D representa-
tion of scenes. Such algorithms consider textured triangles
or warp and blend captured images on the mesh surface to
generate novel views ++ref++[ (Chris Buehler, Michael Bosse, Leonard Mcmillan, Steven Gortler, and Michael Cohen. Unstructured Lumigraph Ren- dering. In ACM SIGGRAPH, 2001. 3), (Peter Hedman, Julien Philip, True Price, Jan-Michael Frahm, George Drettakis, and Gabriel Brostow. Deep Blending for Free-Viewpoint Image-Based Rendering. In ACM SIG- GRAPH, 2018. 3, 7, 2, 4), (Daniel N. Wood, Daniel I. Azuma, Ken Aldinger, Brian Cur- less, Tom Duchamp, David H. Salesin, and Werner Stuet- zle. Surface Light Fields for 3D Photography. In ACM SIG- GRAPH, 2000. 3) ]++ref++.
++ref++[ (Gernot Riegler and Vladlen Koltun. Free View Synthesis. In European Conference on Computer Vision, 2020. 3), (Gernot Riegler and Vladlen Koltun. Stable View Synthesis. In Conference on Computer Vision and Pattern Recognition, 2021. 3) ]++ref++ consider deep
learning-based mesh representations for better view synthe-
sis, bridging the gap between traditional graphics and mod-
ern machine learning techniques. While these mesh-based
methods take advantage of existing graphics hardware and
software for efficient rendering, they struggle with the cap-
ture of accurate geometry and appearance in complex re-
gions.

Volumetric IBR methods. Volumetric methods use voxel
grids, multiplane images, or neural networks to represent
scenes as continuous volumetric functions of density and
color. Recently, Neural Radiance Fields (NeRF) ++ref++[ (Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. NeRF: Representing Scenes as Neural Radiance Fields for View In European Conference on Computer Vision, Synthesis. 2020. 1, 3) ]++ref++ intro-
duced a novel scene representation based on a continuous
volumetric function parameterized by a multilayer percep-
tron (MLP). NeRF produces photorealistic renderings with
fine details and view-dependent effects, achieved through
volumetric ray tracing. However, the original NeRF is com-
putationally expensive and memory intensive.

To address these challenges, several works have im-
proved NeRF’s performance and scalability. These meth-
ods leverage discretized or sparse volumetric representa-
tions like voxel grids and hash tables as ways to store
learnable features acting as positional encodings for 3D
points ++ref++[ (Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and Hao Su. TensoRF: Tensorial Radiance Fields. In European Conference on Computer Vision, 2022. 3), (Animesh Karnewar, Tobias Ritschel, Oliver Wang, and Niloy Mitra. ReLU Fields: The Little Non-Linearity That Could. In ACM SIGGRAPH, 2022. 3), (Thomas M¨uller, Alex Evans, Christoph Schied, and Alexan- der Keller. Instant Neural Graphics Primitives with a Mul- tiresolution Hash Encoding. In ACM SIGGRAPH, 2022. 3, 7, 8, 2), (Cheng Sun, Min Sun, and Hwann-Tzong Chen. Direct Voxel Grid Optimization: Super-Fast Convergence for Radiance In Conference on Computer Vision Fields Reconstruction. and Pattern Recognition, 2022. 3), (Alex Yu, Sara Fridovich-Keil, Matthew Tancik, Qinhong Chen, Benjamin Recht, and Angjoo Kanazawa. Plenoxels: In Conference Radiance Fields Without Neural Networks. on Computer Vision and Pattern Recognition, 2022. 3, 7, 8) ]++ref++, hierarchical sampling strate-
gies ++ref++[ (Jonathan T. Barron. Mip-NeRF 360: Unbounded Anti- Aliased Neural Radiance Fields. In Conference on Computer Vision and Pattern Recognition, 2022. 3, 7, 8, 2, 4), (Peter Hedman and Pratul P. Srinivasan. Baking Neural Radi- ance Fields for Real-Time View Synthesis. In International Conference on Computer Vision, 2021. 3), (Christian Reiser, Songyou Peng, Yiyi Liao, and Andreas Geiger. KiloNeRF: Speeding Up Neural Radiance Fields with Thousands of Tiny MLPs. In International Conference on Computer Vision, 2021. 3), (Alex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, and Angjoo Kanazawa. PlenOctrees For Real-Time Rendering of Neural Radiance Fields. In International Conference on Computer Vision, 2021. 3) ]++ref++, or low-rank approximations ++ref++[ (Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and Hao Su. TensoRF: Tensorial Radiance Fields. In European Conference on Computer Vision, 2022. 3) ]++ref++. How-
ever, they still rely on volumetric ray marching, which
is incompatible with standard graphics hardware and soft-
ware designed for rendering polygonal surfaces. Recent
works have proposed modifying the NeRF’s representation
of geometry and emitted radiance to allow for better recon-
struction of specular materials ++ref++[ (Dor Verbin, Peter Hedman, Ben Mildenhall, Todd Zickler, Jonathan T. Barron, and Pratul P. Srinivasan. Ref-NeRF: 10 SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering) ]++ref++ or relighting the scene
through an explicit decomposition into material and lighting
properties ++ref++[ (Mark Boss, Raphael Braun, Varun Jampani, Jonathan T. Bar- ron, Ce Liu, and Hendrik P. A. Lensch. NeRD: Neural Re- flectance Decomposition from Image Collections. In Inter- national Conference on Computer Vision, 2021. 3), (Zhengfei Kuang, Kyle Olszewski, Menglei Chai, Zeng Huang, Panos Achlioptas, and Sergey Tulyakov. NeROIC: Neural Rendering of Objects from Online Image Collections. In ACM SIGGRAPH, 2022. 3), (Pratul P. Srinivasan, Boyang Deng, Xiuming Zhang, Matthew Tancik, Ben Mildenhall, and Jonathan T. Barron. NeRV: Neural Reflectance and Visibility Fields for Relight- ing and View Synthesis. In Conference on Computer Vision and Pattern Recognition, 2021. 3), (Kai Zhang, Fujun Luan, Qianqian Wang, Kavita Bala, and Noah Snavely. PhySG: Inverse Rendering with Spherical Gaussians for Physics-Based Material Editing and Relight- ing. In Conference on Computer Vision and Pattern Recog- nition, 2021. 3) ]++ref++.

Hybrid IBR methods. Some methods build on differen-
tiable rendering to combine the advantages of mesh-based
and volumetric methods, and allow for surface reconstruc-
tion as well as better editability. They use a hybrid volume-
surface representation, which enables high-quality meshes
suitable for downstream graphics applications while effi-
ciently modeling view-dependent appearance.
In partic-
ular, some works optimize neural signed distance func-
tions (SDF) by training neural radiance fields in which the
density is derived as a differentiable transformation of the
SDF ++ref++[ (Chong Bao and Bangbang Yang, Zeng Junyi, Bao Hu- jun, Zhang Yinda, Cui Zhaopeng, and Zhang Guofeng. NeuMesh: Learning Disentangled Neural Mesh-Based Im- plicit Field for Geometry and Texture Editing. In European Conference on Computer Vision, 2022. 4), (Franc¸ois Darmon, B´en´edicte Bascle, Jean-Cl´ement Devaux, Pascal Monasse, and Mathieu Aubry. Improving Neural Im- plicit Surfaces Geometry with Patch Warping. In Conference on Computer Vision and Pattern Recognition, 2022. 4), (Zhaoshuo Li, Thomas M¨uller, Alex Evans, Russell H. Tay- lor, Mathias Unberath, Ming-Yu Liu, and Chen-Hsuan Lin. Neuralangelo: High-Fidelity Neural Surface Reconstruction. In Conference on Computer Vision and Pattern Recognition, 2023. 2, 4), (Michael Oechsle, Songyou Peng, and Andreas Geiger. UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction. In International Con- ference on Computer Vision, 2021. 4), (Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. NeuS: Learning Neural Im- plicit Surfaces by Volume Rendering for Multi-View Recon- In Advances in Neural Information Processing struction. Systems, 2021. 2, 4), (Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. Vol- ume Rendering of Neural Implicit Surfaces. In Advances in Neural Information Processing Systems, 2021. 2, 4) ]++ref++. A triangle mesh can finally
be reconstructed from the SDF by applying the Marching
Cubes algorithm ++ref++[ (William E. Lorensen and Harvey E. Cline. Marching Cubes: A High Resolution 3D Surface Construction Algorithm. In ACM SIGGRAPH, 1987. 2, 4, 8 9 Structured View-Dependent Appearance for Neural Radi- ance Fields. In Conference on Computer Vision and Pattern Recognition, 2022. 3) ]++ref++. However, most of these methods do
not target real-time rendering.

Alternatively, other approaches “bake” the rendering ca-
pacity of an optimized NeRF or neural SDF into a much ef-
ficient structure relying on an underlying triangle mesh ++ref++[ (Zhiqin Chen, Thomas Funkhouser, Peter Hedman, and An- drea Tagliasacchi. MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures. In Conference on Computer Vision and Pattern Recognition, 2023. 3, 4, 7, 8) ]++ref++
that could benefit from the traditional triangle rasteriza-
tion pipeline. In particular, the recent BakedSDF ++ref++[ (Lior Yariv, Peter Hedman, Christian Reiser, Dor Verbin, Pratul P. Srinivasan, Richard Szeliski, and Jonathan T. Bar- ron. BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis. In ACM SIGGRAPH, 2023. 2, 3, 4, 7, 8) ]++ref++ re-
constructs high quality meshes by optimizing a full neural
SDF model, baking it into a high-resolution triangle mesh
that combines mesh rendering for interpolating features and
deep learning to translate these features into images, and
finally optimizes a view-dependent appearance model.

However, even though it achieves real-time rendering
and produces impressive meshes of the surface of the scene,
this model demands training a full neural SDF with an ar-
chitecture identical to Mip-NeRF360 ++ref++[ (Jonathan T. Barron. Mip-NeRF: A Multiscale Representa- tion for Anti-Aliasing Neural Radiance Fields. In Interna- tional Conference on Computer Vision, 2021. 4, 7) ]++ref++, which necessi-
tates 48 hours of training.

Similarly, the recent method NeRFMeshing ++ref++[ (Marie-Julie Rakotosaona, Fabian Manhardt, Diego Martin Arroyo, Michael Niemeyer, Abhijit Kundu, and Federico Tombari. NeRFMeshing: Distilling Neural Radiance Fields into Geometrically-Accurate 3D Meshes. In DV, 2023. 2, 3, 4, 7, 8) ]++ref++ pro-
poses to also bake any NeRF model into a mesh structure,
achieving real-time rendering. However, the meshing per-
formed in this method lowers the quality of the rendering
and results in a PSNR much lower than our method. Ad-
ditionally, this method still requires training a full NeRF
model beforehand, and needs approximately an hour of
training on 8 V100 NVIDIA GPUs to allow for mesh train-
ing and extraction.

Our method is much faster at retrieveing a 3D mesh from
3D Gaussian Splatting, which is itself much faster than
NeRFs. As our experiments show, our rendering done by
bounding Gaussians to the mesh results in higher quality
than previous solutions based on meshes.

Point-based IBR methods. Alternatively, point-based
representations for radiance field excel at modeling thin ge-
ometry and leverage fast point rasterization pipelines to ren-
der images using α-blending rather than ray-marching ++ref++[ (Georgios Kopanas, Julien Philip, Thomas Leimk¨uhler, and George Drettakis. Point-Based Neural Rendering with Per- View Optimization. In Computer Graphics Forum, 2021. 4), (Darius R¨uckert, Linus Franke, and Marc Stamminger. ADOP: Approximate Differentiable One-Pixel Point Ren- dering. In ACM SIGGRAPH, 2022. 4) ]++ref++.
In particular, the very recent 3D Gaussian Splatting.
model ++ref++[ (Bernhard Kerbl, Georgios Kopanas, Thomas Leimk¨uhler, and George Drettakis. 3D Gaussian Splatting for Real-Time Radiance Field Rendering. In ACM SIGGRAPH, 2023. 1, 2, 4, 7, 8) ]++ref++ allows for optimizing and rendering scenes with
speed and quality never seen before.


