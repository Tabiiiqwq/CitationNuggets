<!DOCTYPE html>
<!-- saved from url=(0044)https://arxiv.org/html/2401.06416v2#bib.bib9 -->
<html lang="en" data-theme="light" data-qb-installed="true"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Mission: Impossible Language Models</title>
<!--Generated on Fri Aug  2 21:55:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./Mission_ Impossible Language Models_files/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="./Mission_ Impossible Language Models_files/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./Mission_ Impossible Language Models_files/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./Mission_ Impossible Language Models_files/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="./Mission_ Impossible Language Models_files/bootstrap.bundle.min.js.download"></script>
<script src="./Mission_ Impossible Language Models_files/html2canvas.min.js.download"></script>
<script src="./Mission_ Impossible Language Models_files/addons_new.js.download"></script>
<script src="./Mission_ Impossible Language Models_files/feedbackOverlay.js.download"></script>
<!--<base href="/html/2401.06416v2/">--><base href="."><link rel="stylesheet" href="./Mission_ Impossible Language Models_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-toast {
  display: flex;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  right: 0;
  top: 1%;
  width: fit-content;
  padding: 12px 20px;
  margin: auto;
  overflow: auto;
  background: #fef6f9;
  box-shadow: 0px 4px 10px 0px rgba(0, 10, 30, 0.06);
  font-size: 15px;
  border-radius: 8px;
  color: #333;
}

.immersive-translate-toast-content {
  display: flex;
  flex-direction: row;
  align-items: center;
}

.immersive-translate-toast-hidden {
  margin: 0 20px 0 72px;
  text-decoration: underline;
  cursor: pointer;
}

.immersive-translate-toast-close {
  color: #666666;
  font-size: 20px;
  font-weight: bold;
  padding: 0 10px;
  cursor: pointer;
}

@media screen and (max-width: 768px) {
  .immersive-translate-toast {
    top: 0;
    padding: 12px 0px 0 10px;
  }
  .immersive-translate-toast-content {
    flex-direction: column;
    text-align: center;
  }
  .immersive-translate-toast-hidden {
    margin: 10px auto;
  }
}

.immersive-translate-modal {
  display: none;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border: 1px solid #888;
  border-radius: 10px;
  width: 80%;
  max-width: 270px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 50% auto !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  word-break: break-all;
  margin-top: 24px;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  color: black;
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 16px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #007bff;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}
</style><style type="text/css">.lf-progress {
  -webkit-appearance: none;
  -moz-apperance: none;
  width: 100%;
  /* margin: 0 10px; */
  height: 4px;
  border-radius: 3px;
  cursor: pointer;
}
.lf-progress:focus {
  outline: none;
  border: none;
}
.lf-progress::-moz-range-track {
  cursor: pointer;
  background: none;
  border: none;
  outline: none;
}
.lf-progress::-webkit-slider-thumb {
  -webkit-appearance: none !important;
  height: 13px;
  width: 13px;
  border: 0;
  border-radius: 50%;
  background: #0fccce;
  cursor: pointer;
}
.lf-progress::-moz-range-thumb {
  -moz-appearance: none !important;
  height: 13px;
  width: 13px;
  border: 0;
  border-radius: 50%;
  background: #0fccce;
  cursor: pointer;
}
.lf-progress::-ms-track {
  width: 100%;
  height: 3px;
  cursor: pointer;
  background: transparent;
  border-color: transparent;
  color: transparent;
}
.lf-progress::-ms-fill-lower {
  background: #ccc;
  border-radius: 3px;
}
.lf-progress::-ms-fill-upper {
  background: #ccc;
  border-radius: 3px;
}
.lf-progress::-ms-thumb {
  border: 0;
  height: 15px;
  width: 15px;
  border-radius: 50%;
  background: #0fccce;
  cursor: pointer;
}
.lf-progress:focus::-ms-fill-lower {
  background: #ccc;
}
.lf-progress:focus::-ms-fill-upper {
  background: #ccc;
}
.lf-player-container :focus {
  outline: 0;
}
.lf-popover {
  position: relative;
}

.lf-popover-content {
  display: inline-block;
  position: absolute;
  opacity: 1;
  visibility: visible;
  transform: translate(0, -10px);
  box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.26);
  transition: all 0.3s cubic-bezier(0.75, -0.02, 0.2, 0.97);
}

.lf-popover-content.hidden {
  opacity: 0;
  visibility: hidden;
  transform: translate(0, 0px);
}

.lf-player-btn-container {
  display: flex;
  align-items: center;
}
.lf-player-btn {
  cursor: pointer;
  fill: #999;
  width: 14px;
}

.lf-player-btn.active {
  fill: #555;
}

.lf-popover {
  position: relative;
}

.lf-popover-content {
  display: inline-block;
  position: absolute;
  background-color: #ffffff;
  opacity: 1;

  transform: translate(0, -10px);
  box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.26);
  transition: all 0.3s cubic-bezier(0.75, -0.02, 0.2, 0.97);
  padding: 10px;
}

.lf-popover-content.hidden {
  opacity: 0;
  visibility: hidden;
  transform: translate(0, 0px);
}

.lf-arrow {
  position: absolute;
  z-index: -1;
  content: '';
  bottom: -9px;
  border-style: solid;
  border-width: 10px 10px 0px 10px;
}

.lf-left-align,
.lf-left-align .lfarrow {
  left: 0;
  right: unset;
}

.lf-right-align,
.lf-right-align .lf-arrow {
  right: 0;
  left: unset;
}

.lf-text-input {
  border: 1px #ccc solid;
  border-radius: 5px;
  padding: 3px;
  width: 60px;
  margin: 0;
}

.lf-color-picker {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  height: 90px;
}

.lf-color-selectors {
  display: flex;
  flex-direction: column;
  justify-content: space-between;
}

.lf-color-component {
  display: flex;
  flex-direction: row;
  font-size: 12px;
  align-items: center;
  justify-content: center;
}

.lf-color-component strong {
  width: 40px;
}

.lf-color-component input[type='range'] {
  margin: 0 0 0 10px;
}

.lf-color-component input[type='number'] {
  width: 50px;
  margin: 0 0 0 10px;
}

.lf-color-preview {
  font-size: 12px;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: space-between;
  padding-left: 5px;
}

.lf-preview {
  height: 60px;
  width: 60px;
}

.lf-popover-snapshot {
  width: 150px;
}
.lf-popover-snapshot h5 {
  margin: 5px 0 10px 0;
  font-size: 0.75rem;
}
.lf-popover-snapshot a {
  display: block;
  text-decoration: none;
}
.lf-popover-snapshot a:before {
  content: '⥼';
  margin-right: 5px;
}
.lf-popover-snapshot .lf-note {
  display: block;
  margin-top: 10px;
  color: #999;
}
.lf-player-controls > div {
  margin-right: 5px;
  margin-left: 5px;
}
.lf-player-controls > div:first-child {
  margin-left: 0px;
}
.lf-player-controls > div:last-child {
  margin-right: 0px;
}
</style></head>
<body data-new-gr-c-s-check-loaded="14.1104.0" data-gr-ext-installed="" data-new-gr-c-s-loaded="14.1104.0"><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./Mission_ Impossible Language Models_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2401.06416v2">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./Mission_ Impossible Language Models_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2401.06416v2/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2401.06416v2">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2401.06416v2" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S1" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S2" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background and Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S2.SS1" title="In 2 Background and Related Work ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Impossible Human Languages and Language Universals</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S2.SS2" title="In 2 Background and Related Work ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Training Language Models with Unnatural Word Orders</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S2.SS3" title="In 2 Background and Related Work ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Language Models and Formal Languages</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S3" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Impossible Languages</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S3.SS1" title="In 3 Impossible Languages ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span><span class="ltx_text ltx_font_smallcaps">*Shuffle</span> Languages.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S3.SS2" title="In 3 Impossible Languages ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span><span class="ltx_text ltx_font_smallcaps">*Reverse</span> Languages.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S3.SS3" title="In 3 Impossible Languages ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span><span class="ltx_text ltx_font_smallcaps">*Hop</span> Languages.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS1" title="In 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS2" title="In 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Experiment 1: Language Models Reflect the Impossibility Continuum</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS2.SSS0.Px1" title="In 4.2 Experiment 1: Language Models Reflect the Impossibility Continuum ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Setup.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS2.SSS0.Px2" title="In 4.2 Experiment 1: Language Models Reflect the Impossibility Continuum ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Hypothesis.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS2.SSS0.Px3" title="In 4.2 Experiment 1: Language Models Reflect the Impossibility Continuum ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3" title="In 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Experiment 2: Language Models Disprefer Counting Rules</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px1" title="In 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Setup.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px2" title="In 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Hypothesis.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px3" title="In 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS4" title="In 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Experiment 3: Language Models Develop Natural Solutions to Unnatural Patterns</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS4.SSS0.Px1" title="In 4.4 Experiment 3: Language Models Develop Natural Solutions to Unnatural Patterns ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Setup.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS4.SSS0.Px2" title="In 4.4 Experiment 3: Language Models Develop Natural Solutions to Unnatural Patterns ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S5" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion and Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S6" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Acknowledgments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S7" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S8" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Ethics Statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A1" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Dataset Filters</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A1.SS0.SSS0.Px1" title="In Appendix A Dataset Filters ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">*Shuffle Filters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A1.SS0.SSS0.Px2" title="In Appendix A Dataset Filters ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">*Reverse Filters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A1.SS0.SSS0.Px3" title="In Appendix A Dataset Filters ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">*Hop Filters</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A2" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>GPT-2 Training Details and Hyperparameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A3" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Results for Models without Positional Encodings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A4" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Constituency Probing Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A4.SS0.SSS0.Px1" title="In Appendix D Constituency Probing Evaluation ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Setup.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A4.SS0.SSS0.Px2" title="In Appendix D Constituency Probing Evaluation ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Hypothesis.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A4.SS0.SSS0.Px3" title="In Appendix D Constituency Probing Evaluation ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A5" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Additional <span class="ltx_text ltx_font_smallcaps">DeterministicShuffle</span> Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6" title="In Mission: Impossible Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Confidence Intervals for Interchange Intervention Accuracies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found" style="display: none;">
      <button aria-label="Dismiss alert" onclick="closePopup()">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: inconsolata</li><li>failed: linguex</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0</a><div id="watermark-tr">arXiv:2401.06416v2 [cs.CL] 02 Aug 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
Mission: Impossible Language Models
</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Julie Kallini<sup class="ltx_sup" id="id9.9.id1"><span class="ltx_text ltx_font_italic" id="id9.9.id1.1">1</span></sup>,
Isabel Papadimitriou<sup class="ltx_sup" id="id10.10.id2"><span class="ltx_text ltx_font_italic" id="id10.10.id2.1">1</span></sup>,
Richard Futrell<sup class="ltx_sup" id="id11.11.id3"><span class="ltx_text ltx_font_italic" id="id11.11.id3.1">2</span></sup>, 
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id4.4.1">Kyle Mahowald<sup class="ltx_sup" id="id4.4.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id4.4.1.1.1">3</span></sup>,</span>
<span class="ltx_text ltx_font_bold" id="id5.5.2">Christopher Potts<sup class="ltx_sup" id="id5.5.2.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id5.5.2.1.1">1</span></sup></span>
<br class="ltx_break">
<sup class="ltx_sup" id="id12.12.id4"><span class="ltx_text ltx_font_italic" id="id12.12.id4.1">1</span></sup>Stanford University; <sup class="ltx_sup" id="id13.13.id5"><span class="ltx_text ltx_font_italic" id="id13.13.id5.1">2</span></sup>University of California, Irvine; <sup class="ltx_sup" id="id14.14.id6"><span class="ltx_text ltx_font_italic" id="id14.14.id6.1">3</span></sup>University of Texas, Austin 
<br class="ltx_break">
<span class="ltx_text ltx_font_typewriter" id="id15.15.id7">kallini@stanford.edu</span>
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id16.id1">Chomsky and others have very directly claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to support such a claim. Here, we develop a set of synthetic <em class="ltx_emph ltx_font_italic" id="id16.id1.1">impossible languages</em> of differing complexity, each designed by systematically altering English data with unnatural word orders and grammar rules. These languages lie on an impossibility continuum: at one end are languages that are inherently impossible, such as random and irreversible shuffles of English words, and on the other, languages that may not be intuitively impossible but are often considered so in linguistics, particularly those with rules based on counting word positions. We report on a wide range of evaluations to assess the capacity of GPT-2 small models to learn these uncontroversially impossible languages, and crucially, we perform these assessments at various stages throughout training to compare the learning process for each language. Our core finding is that GPT-2 struggles to learn impossible languages when compared to English as a control, challenging the core claim. More importantly, we hope our approach opens up a productive line of inquiry in which different LLM architectures are tested on a variety of impossible languages in an effort to learn more about how LLMs can be used as tools for these cognitive and typological investigations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="401" id="S1.F1.g1" src="./Mission_ Impossible Language Models_files/x1.png" width="373">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Partial impossibility continuum of languages based on complexity. We assess the learnability of languages at different points in the continuum and push the (currently unclear) boundary between possible and impossible.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Chomsky (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib9" title="">2023</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Chomsky et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib10" title="">2023</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Moro et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib47" title="">2023</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_citet">Bolhuis et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib3" title="">2024</a>)</cite> make very broad claims to the effect that large language models (LLMs) are equally capable of learning possible and impossible human languages. For these authors, it follows from this claim that LLMs cannot teach us anything about language, and so the claim (if true) would have significant consequences for linguistic methodology and potentially also for the viability of LLMs as the basis for robust language capabilities.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">These authors state this claim in absolute terms. For example, <cite class="ltx_cite ltx_citemacro_citet">Chomsky et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib10" title="">2023</a>)</cite> flatly assert that LLMs “are incapable of distinguishing the possible from the impossible,” <cite class="ltx_cite ltx_citemacro_citet">Chomsky (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib9" title="">2023</a>)</cite> says this property “can’t be modified,” and <cite class="ltx_cite ltx_citemacro_citet">Moro et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib47" title="">2023</a>)</cite> write that “the distinction between possible versus impossible languages cannot be formulated by definition for LLM.” <cite class="ltx_cite ltx_citemacro_citet">Bolhuis et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib3" title="">2024</a>)</cite> go so far as to claim that “LLMs can produce ‘impossible’ languages […] just as well as (if not better than) natural language output.”
One might expect such strong claims to be supported by extensive formal analysis and/or experimental evidence. However, as far as we are aware, this is not the case. The sole experimental paper cited by the above authors is <cite class="ltx_cite ltx_citemacro_citet">Mitchell and Bowers <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib46" title="">2020</a></cite>—an important and inspiring paper but not one that can resolve these questions on its own. In addition, linguists themselves do not even have an agreed upon notion of what defines the possible or the impossible languages, to say nothing of having formal results with respect to LLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Here we provide extensive new experimental evidence to inform the claim that LLMs are equally capable of learning possible and impossible languages in the human sense. Arguably, the central challenge for such work is the fact that there is no agreed-upon way of distinguishing these two groups. We do not feel positioned ourselves to assert such a definition, so we instead offer some examples of impossible languages on a continuum of intuitive complexity (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S1.F1" title="In 1 Introduction ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>).
Some of these examples seem intuitively impossible, such as random sentence-level shuffling of English words. Others operationalize less obvious but common claims in the linguistics literature about rules that are impossible, like those that depend on counting words.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">All of our examples are, we take it, uncontroversial instances of impossible languages. Thus, our experiments can inform the core hypotheses as follows: if LLMs learn these languages as well as they learn natural languages, then the claims of Chomsky and others are supported (for the specific class of LLMs tested). Conversely, if LLMs do not learn these languages as well as the possible ones, it would call into question those assertions. In that case, proponents of those claims ought to provide examples of impossible languages that they find more informative, which we can then evaluate using our approach to further advance the discussion.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our experiments use GPT-2 small models <cite class="ltx_cite ltx_citemacro_cite">Radford et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib57" title="">2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib58" title="">2019</a>)</cite>,
and our base training corpus is the BabyLM dataset <cite class="ltx_cite ltx_citemacro_cite">Warstadt et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib63" title="">2023</a>)</cite>, which we modify in various ways to implement our impossible languages.
What we find is that these models indeed struggle to learn impossible languages, shown through three core experiments:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">In <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Experiment 1</span>, we train GPT-2 models on our set of defined possible and impossible languages, measuring their learning efficiency through test set perplexities. We find that <em class="ltx_emph ltx_font_italic" id="S1.I1.i1.p1.1.2">models trained on possible languages learn more efficiently</em>, evident from lower perplexities achieved in fewer training steps.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">In <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Experiment 2</span>, we more closely examine a set of languages that exhibit count-based verb marking rules, using surprisal comparisons to target the relevant patterns. We find that <span class="ltx_text" id="S1.I1.i2.p1.1.2">GPT-2s</span> trained on possible languages are more surprised by ungrammatical constructions, indicating that <em class="ltx_emph ltx_font_italic" id="S1.I1.i2.p1.1.3">models disprefer agreement rules involving counting</em>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">In <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Experiment 3</span>, we dive deeper into the internal mechanisms that models may develop to learn such count-based grammar rules using causal abstraction analysis. We find that <em class="ltx_emph ltx_font_italic" id="S1.I1.i3.p1.1.2">models develop natural, modular solutions to unnatural grammatical patterns</em>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Overall, our experimental results strongly challenge the claims of Chomsky and others given above, and we believe they pave the way for even deeper discussions of LLMs as models of language learning. At the same time, we recognize that models and humans exhibit fundamental differences, but the extent to which models favor or disfavor natural languages can be influenced by specific architectural decisions (as demonstrated by our findings on tokenization and positional encodings). We hope this paper initiates a new line of work that explores how different model architectures can distinguish between the possible and impossible languages.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The code for this paper is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/jkallini/mission-impossible-language-models" title="">https://github.com/jkallini/mission-impossible-language-models</a>.</span></span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Impossible Human Languages and Language Universals</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The notion of an impossible human language is elusive and difficult to define, in part due to a lack of consensus on which properties are universal in human language and which properties are “impossible” <cite class="ltx_cite ltx_citemacro_citep">(Comrie, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib11" title="">1989</a>; Evans and Levinson, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib16" title="">2009</a>; Nefdt, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib50" title="">2024</a>)</cite>.
For instance, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.1">recursion</em>, or the principle that all languages produce hierarchical syntactic structures via recursive procedures, has been claimed to be a universal property of human language <cite class="ltx_cite ltx_citemacro_citep">(Chomsky, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib5" title="">1957</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib7" title="">1965</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib8" title="">2002</a>; Hauser et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib31" title="">2002</a>)</cite>.
However, the motivations for recursion have been questioned, with empirical limits on the maximum depth of nested phrases <cite class="ltx_cite ltx_citemacro_cite">Karlsson (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib39" title="">2007</a>); Jin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib36" title="">2018</a>)</cite> and counterevidence from at least one natural language that seems to lack embedded structures <cite class="ltx_cite ltx_citemacro_cite">Everett (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib17" title="">2012</a>)</cite>. Still, if we grant that possible languages are defined by hierarchical, recursive rules, what defines the impossible languages? <cite class="ltx_cite ltx_citemacro_citet">Moro et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib47" title="">2023</a>)</cite> claim that the class of impossible languages would use the “opposite” type of rules: those based on the linear order of words. <cite class="ltx_cite ltx_citemacro_citet">Musso et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib49" title="">2003</a>)</cite> provide a few concrete examples that involve counting word positions to mark features like negation and agreement, and we include languages with similar rules in our set of tested impossible languages.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">It is important to also distinguish what is impossible from what is merely typologically marked, such as the word order patterns listed in <cite class="ltx_cite ltx_citemacro_citeauthor"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib25" title="">Greenberg</a></cite>’s (<cite class="ltx_cite ltx_citemacro_citeyear"><a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib25" title="">1963</a></cite>) language universals. Previous work has shown that such word order universals can arise through a language’s optimization of communication efficiency, achieved by balancing complexity and ambiguity <cite class="ltx_cite ltx_citemacro_cite">Hahn et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib28" title="">2020</a>); Futrell and Hahn (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib19" title="">2022</a>)</cite>.
While our current exploration does not encompass attested languages, various impossible languages can similarly differ in their information-theoretic complexity, informing the patterns that lie at the boundary between possible and impossible.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Training Language Models with Unnatural Word Orders</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The only work cited by Chomsky that investigates neural language models’ ability to learn impossible languages is <cite class="ltx_cite ltx_citemacro_citet">Mitchell and Bowers <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib46" title="">2020</a></cite>, which finds that recurrent neural networks (RNNs; <cite class="ltx_cite ltx_citemacro_citep">Elman, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib15" title="">1990</a></cite>) trained on various unnatural language constructs, such as reversed sentences and randomized vocabularies, achieve high accuracy on a subject–verb number agreement task.
Other work turns to more recent Transformer-based language models <cite class="ltx_cite ltx_citemacro_cite">Vaswani et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib62" title="">2017</a>)</cite>, observing their sensitivity to word order and phrase structure <cite class="ltx_cite ltx_citemacro_cite">Alleman et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib2" title="">2021</a>); Galke et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib21" title="">2023</a>)</cite> as well as their surprising ability to learn from syntactic information alone <cite class="ltx_cite ltx_citemacro_cite">Huang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib35" title="">2023</a>)</cite>.
Studies by <cite class="ltx_cite ltx_citemacro_citet">Sinha et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib60" title="">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Abdou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib1" title="">2022</a>)</cite> debate the impact of tokenization, pretraining adjustments, and positional encodings in recovering word order information from shuffled languages.
Further investigations into BERT’s <cite class="ltx_cite ltx_citemacro_cite">Devlin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib13" title="">2019</a>)</cite> reliance on word order for grammatical role classification suggest that lexical cues alone may not always be sufficient for good performance (<cite class="ltx_cite ltx_citemacro_citep">Papadimitriou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib51" title="">2022</a></cite>; see also <cite class="ltx_cite ltx_citemacro_citep">Hessel and Schofield, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib32" title="">2021</a>; Pham et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib53" title="">2021</a></cite>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Language Models and Formal Languages</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">A related line of research examines the abilities of neural language models to express formal languages, as defined by the <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.1.1">Chomsky hierarchy</em>
<cite class="ltx_cite ltx_citemacro_cite">Chomsky (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib4" title="">1956</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib6" title="">1959</a>)</cite>. Human language is considered to be slightly more expressive than context-free languages due to certain syntactic phenomena that interleave constituents <cite class="ltx_cite ltx_citemacro_cite">Shieber (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib59" title="">1985</a>); Joshi (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib37" title="">1985</a>)</cite>.
Previous work has shown that RNNs or related models can represent variants of counter and <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p1.1.2">Dyck</span> languages, which are context-free <cite class="ltx_cite ltx_citemacro_cite">Weiss et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib64" title="">2018</a>); Merrill (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib44" title="">2019</a>); Merrill et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib45" title="">2020</a>); Hewitt et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib33" title="">2020</a>)</cite>.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Though counter and <span class="ltx_text ltx_font_smallcaps" id="footnote2.1">Dyck</span> languages are context-free, some of the variants in the cited work are regular.</span></span></span>
Similar work on Transformer architectures has shown that, while they are theoretically Turing-complete provided arbitrary precision and decoder steps <cite class="ltx_cite ltx_citemacro_cite">Pérez et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib55" title="">2021</a>)</cite>, they cannot empirically model many regular and non-regular languages <cite class="ltx_cite ltx_citemacro_cite">Hahn (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib26" title="">2020</a>); Ebrahimi et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib14" title="">2020</a>); Deletang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib12" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">The inability of Transformer-based language models to learn more complex languages in the Chomsky hierarchy seems surprising, given their impressive performance on natural language. This could be interpreted as evidence that theoretically weak computational models are sufficient for expressing human language. Alternatively, Transformer-based models can be augmented to have inductive biases for nested, hierarchical structures through architecture changes, like the addition of a stack component <cite class="ltx_cite ltx_citemacro_cite">Hao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib30" title="">2018</a>); Murty et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib48" title="">2023</a>)</cite>, or data-centered approaches, like structural pretraining <cite class="ltx_cite ltx_citemacro_cite">Papadimitriou and Jurafsky (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib52" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Impossible Languages</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.6" style="width:433.6pt;height:218.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-69.9pt,35.1pt) scale(0.75621100756889,0.75621100756889) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.6.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.6.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.6.6.7.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.6.6.7.1.1.1">Class</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.6.6.7.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.6.6.7.1.2.1">Language</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.6.6.7.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.6.6.7.1.3.1">Example 1</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.6.6.7.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.6.6.7.1.4.1">Example 2</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.6.6.8.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S3.T1.6.6.8.1.1" rowspan="6" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.8.1.1.1">*Shuffle</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S3.T1.6.6.8.1.2" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.8.1.2.1" style="color:#606060;">NoShuffle</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S3.T1.6.6.8.1.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.8.1.3.1" style="background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.8.1.3.2"> <span class="ltx_text" id="S3.T1.6.6.8.1.3.2.1" style="background-color:#FDE4CF;"> cleans</span> <span class="ltx_text" id="S3.T1.6.6.8.1.3.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.8.1.3.2.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.8.1.3.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.8.1.3.2.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.8.1.3.2.6" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.8.1.3.2.7" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.8.1.3.2.8" style="background-color:#B9FBC0;">.</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.6.6.8.1.4" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.8.1.4.1" style="background-color:#FDFD95;">They</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.8.1.4.2"> <span class="ltx_text" id="S3.T1.6.6.8.1.4.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.8.1.4.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.8.1.4.2.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.8.1.4.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.8.1.4.2.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.8.1.4.2.6" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.8.1.4.2.7" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.8.1.4.2.8" style="background-color:#B9FBC0;">.</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.9.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.9.2.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.9.2.1.1" style="color:#E8384F;">NondeterministicShuffle</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.9.2.2" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.9.2.2.1" style="background-color:#CFBAF0;">messy</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.9.2.2.2"> <span class="ltx_text" id="S3.T1.6.6.9.2.2.2.1" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.9.2.2.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.9.2.2.2.3" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.9.2.2.2.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.9.2.2.2.5" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.6.6.9.2.2.2.6" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.9.2.2.2.7" style="background-color:#FDFD95;">He</span> <span class="ltx_text" id="S3.T1.6.6.9.2.2.2.8" style="background-color:#FDE4CF;"> cleans</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.6.6.9.2.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.9.2.3.1" style="background-color:#FFCFD2;">his</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.9.2.3.2"> <span class="ltx_text" id="S3.T1.6.6.9.2.3.2.1" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.6.6.9.2.3.2.2" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.9.2.3.2.3" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.9.2.3.2.4" style="background-color:#FDFD95;">They</span> <span class="ltx_text" id="S3.T1.6.6.9.2.3.2.5" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.9.2.3.2.6" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.9.2.3.2.7" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.9.2.3.2.8" style="background-color:#FDE4CF;"> clean</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.1.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.1.1.1.1.1" style="color:#FFB000;">DeterministicShuffle<math alttext="(s=21)" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.1.m1.1a"><mrow id="S3.T1.1.1.1.1.1.m1.1.1.1" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.cmml"><mo id="S3.T1.1.1.1.1.1.m1.1.1.1.2" mathcolor="#FFB000" stretchy="false" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.T1.1.1.1.1.1.m1.1.1.1.1" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.cmml"><mi id="S3.T1.1.1.1.1.1.m1.1.1.1.1.2" mathcolor="#FFB000" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.2.cmml">s</mi><mo id="S3.T1.1.1.1.1.1.m1.1.1.1.1.1" mathcolor="#FFB000" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S3.T1.1.1.1.1.1.m1.1.1.1.1.3" mathcolor="#FFB000" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.3.cmml">21</mn></mrow><mo id="S3.T1.1.1.1.1.1.m1.1.1.1.3" mathcolor="#FFB000" stretchy="false" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="S3.T1.1.1.1.1.1.m1.1.1.1"><eq id="S3.T1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.1"></eq><ci id="S3.T1.1.1.1.1.1.m1.1.1.1.1.2.cmml" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.2">𝑠</ci><cn id="S3.T1.1.1.1.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S3.T1.1.1.1.1.1.m1.1.1.1.1.3">21</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.1.m1.1c">(s=21)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.1.m1.1d">( italic_s = 21 )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.1.1.1.2" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.1.1.1.2.1" style="background-color:#FDE4CF;">cleans</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.1.1.1.2.2"> <span class="ltx_text" id="S3.T1.1.1.1.2.2.1" style="background-color:#FDFD95;">He</span> <span class="ltx_text" id="S3.T1.1.1.1.2.2.2" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.1.1.1.2.2.3" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.1.1.1.2.2.4" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.1.1.1.2.2.5" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.1.1.1.2.2.6" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.1.1.1.2.2.7" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.1.1.1.2.2.8" style="background-color:#FFCFD2;"> his</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.1.1.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.1.1.1.3.1" style="background-color:#FDE4CF;">clean</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.1.1.1.3.2"> <span class="ltx_text" id="S3.T1.1.1.1.3.2.1" style="background-color:#FDFD95;">They</span> <span class="ltx_text" id="S3.T1.1.1.1.3.2.2" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.1.1.1.3.2.3" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.1.1.1.3.2.4" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.1.1.1.3.2.5" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.1.1.1.3.2.6" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.1.1.1.3.2.7" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.1.1.1.3.2.8" style="background-color:#FFCFD2;"> his</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.2.2.2.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.2.2.2.1.1" style="color:#8DB000;">DeterministicShuffle<math alttext="(s=57)" class="ltx_Math" display="inline" id="S3.T1.2.2.2.1.1.m1.1"><semantics id="S3.T1.2.2.2.1.1.m1.1a"><mrow id="S3.T1.2.2.2.1.1.m1.1.1.1" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.cmml"><mo id="S3.T1.2.2.2.1.1.m1.1.1.1.2" mathcolor="#8DB000" stretchy="false" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.T1.2.2.2.1.1.m1.1.1.1.1" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.cmml"><mi id="S3.T1.2.2.2.1.1.m1.1.1.1.1.2" mathcolor="#8DB000" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.2.cmml">s</mi><mo id="S3.T1.2.2.2.1.1.m1.1.1.1.1.1" mathcolor="#8DB000" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S3.T1.2.2.2.1.1.m1.1.1.1.1.3" mathcolor="#8DB000" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.3.cmml">57</mn></mrow><mo id="S3.T1.2.2.2.1.1.m1.1.1.1.3" mathcolor="#8DB000" stretchy="false" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.1.1.m1.1b"><apply id="S3.T1.2.2.2.1.1.m1.1.1.1.1.cmml" xref="S3.T1.2.2.2.1.1.m1.1.1.1"><eq id="S3.T1.2.2.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.1"></eq><ci id="S3.T1.2.2.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.2">𝑠</ci><cn id="S3.T1.2.2.2.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S3.T1.2.2.2.1.1.m1.1.1.1.1.3">57</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.1.1.m1.1c">(s=57)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.1.1.m1.1d">( italic_s = 57 )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.2.2.2.2" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.2.2.2.2.1" style="background-color:#FDE4CF;">cleans</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.2.2.2.2.2"> <span class="ltx_text" id="S3.T1.2.2.2.2.2.1" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.2.2.2.2.2.2" style="background-color:#FDFD95;">He</span> <span class="ltx_text" id="S3.T1.2.2.2.2.2.3" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.2.2.2.2.2.4" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.2.2.2.2.2.5" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.2.2.2.2.2.6" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.2.2.2.2.2.7" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.2.2.2.2.2.8" style="background-color:#A3C4F3;"> books</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.2.2.2.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.2.2.2.3.1" style="background-color:#FDE4CF;">clean</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.2.2.2.3.2"> <span class="ltx_text" id="S3.T1.2.2.2.3.2.1" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.2.2.2.3.2.2" style="background-color:#FDFD95;">They</span> <span class="ltx_text" id="S3.T1.2.2.2.3.2.3" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.2.2.2.3.2.4" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.2.2.2.3.2.5" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.2.2.2.3.2.6" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.2.2.2.3.2.7" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.2.2.2.3.2.8" style="background-color:#A3C4F3;"> books</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.3.3.3.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.3.3.3.1.1" style="color:#62BB35;">DeterministicShuffle<math alttext="(s=84)" class="ltx_Math" display="inline" id="S3.T1.3.3.3.1.1.m1.1"><semantics id="S3.T1.3.3.3.1.1.m1.1a"><mrow id="S3.T1.3.3.3.1.1.m1.1.1.1" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.cmml"><mo id="S3.T1.3.3.3.1.1.m1.1.1.1.2" mathcolor="#62BB35" stretchy="false" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.T1.3.3.3.1.1.m1.1.1.1.1" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.cmml"><mi id="S3.T1.3.3.3.1.1.m1.1.1.1.1.2" mathcolor="#62BB35" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.2.cmml">s</mi><mo id="S3.T1.3.3.3.1.1.m1.1.1.1.1.1" mathcolor="#62BB35" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S3.T1.3.3.3.1.1.m1.1.1.1.1.3" mathcolor="#62BB35" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.3.cmml">84</mn></mrow><mo id="S3.T1.3.3.3.1.1.m1.1.1.1.3" mathcolor="#62BB35" stretchy="false" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.1.1.m1.1b"><apply id="S3.T1.3.3.3.1.1.m1.1.1.1.1.cmml" xref="S3.T1.3.3.3.1.1.m1.1.1.1"><eq id="S3.T1.3.3.3.1.1.m1.1.1.1.1.1.cmml" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.1"></eq><ci id="S3.T1.3.3.3.1.1.m1.1.1.1.1.2.cmml" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.2">𝑠</ci><cn id="S3.T1.3.3.3.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S3.T1.3.3.3.1.1.m1.1.1.1.1.3">84</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.1.1.m1.1c">(s=84)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.3.1.1.m1.1d">( italic_s = 84 )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.3.3.3.2" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.3.3.3.2.1" style="background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.3.3.3.2.2"> <span class="ltx_text" id="S3.T1.3.3.3.2.2.1" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.3.3.3.2.2.2" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.3.3.3.2.2.3" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.3.3.3.2.2.4" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.3.3.3.2.2.5" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.3.3.3.2.2.6" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.3.3.3.2.2.7" style="background-color:#FDE4CF;"> cleans</span> <span class="ltx_text" id="S3.T1.3.3.3.2.2.8" style="background-color:#90DBF4;">he</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.3.3.3.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.3.3.3.3.1" style="background-color:#FDFD95;">They</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.3.3.3.3.2"> <span class="ltx_text" id="S3.T1.3.3.3.3.2.1" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.3.3.3.3.2.2" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.3.3.3.3.2.3" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.3.3.3.3.2.4" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.3.3.3.3.2.5" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.3.3.3.3.2.6" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.3.3.3.3.2.7" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.3.3.3.3.2.8" style="background-color:#90DBF4;">he</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.4.4.4.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.4.4.1.1" style="color:#208EA3;">LocalShuffle<math alttext="(w=3)" class="ltx_Math" display="inline" id="S3.T1.4.4.4.1.1.m1.1"><semantics id="S3.T1.4.4.4.1.1.m1.1a"><mrow id="S3.T1.4.4.4.1.1.m1.1.1.1" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.cmml"><mo id="S3.T1.4.4.4.1.1.m1.1.1.1.2" mathcolor="#208EA3" stretchy="false" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.T1.4.4.4.1.1.m1.1.1.1.1" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.cmml"><mi id="S3.T1.4.4.4.1.1.m1.1.1.1.1.2" mathcolor="#208EA3" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.2.cmml">w</mi><mo id="S3.T1.4.4.4.1.1.m1.1.1.1.1.1" mathcolor="#208EA3" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S3.T1.4.4.4.1.1.m1.1.1.1.1.3" mathcolor="#208EA3" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.3.cmml">3</mn></mrow><mo id="S3.T1.4.4.4.1.1.m1.1.1.1.3" mathcolor="#208EA3" stretchy="false" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.1.1.m1.1b"><apply id="S3.T1.4.4.4.1.1.m1.1.1.1.1.cmml" xref="S3.T1.4.4.4.1.1.m1.1.1.1"><eq id="S3.T1.4.4.4.1.1.m1.1.1.1.1.1.cmml" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.1"></eq><ci id="S3.T1.4.4.4.1.1.m1.1.1.1.1.2.cmml" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.2">𝑤</ci><cn id="S3.T1.4.4.4.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S3.T1.4.4.4.1.1.m1.1.1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.1.1.m1.1c">(w=3)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.4.1.1.m1.1d">( italic_w = 3 )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.4.4.4.2" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.4.4.4.2.1" style="background-color:#FFCFD2;">his</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.4.4.4.2.2"> <span class="ltx_text" id="S3.T1.4.4.4.2.2.1" style="background-color:#FDFD95;">He</span> <span class="ltx_text" id="S3.T1.4.4.4.2.2.2" style="background-color:#FDE4CF;"> cleans</span> <span class="ltx_text" id="S3.T1.4.4.4.2.2.3" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.4.4.4.2.2.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.4.4.4.2.2.5" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.4.4.4.2.2.6" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.4.4.4.2.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.4.4.4.2.2.8" style="background-color:#98F5E1;">lf</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.4.4.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.4.4.4.3.1" style="background-color:#FFCFD2;">his</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.4.4.4.3.2"> <span class="ltx_text" id="S3.T1.4.4.4.3.2.1" style="background-color:#FDFD95;">They</span> <span class="ltx_text" id="S3.T1.4.4.4.3.2.2" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.4.4.4.3.2.3" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.4.4.4.3.2.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.4.4.4.3.2.5" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.4.4.4.3.2.6" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.4.4.4.3.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.4.4.4.3.2.8" style="background-color:#98F5E1;">lf</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5.5">
<td class="ltx_td ltx_border_r" id="S3.T1.5.5.5.2" style="padding-bottom:3.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.5.5.5.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.5.5.5.1.1" style="color:#4178BC;">LocalShuffle<math alttext="(w=5)" class="ltx_Math" display="inline" id="S3.T1.5.5.5.1.1.m1.1"><semantics id="S3.T1.5.5.5.1.1.m1.1a"><mrow id="S3.T1.5.5.5.1.1.m1.1.1.1" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.cmml"><mo id="S3.T1.5.5.5.1.1.m1.1.1.1.2" mathcolor="#4178BC" stretchy="false" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.T1.5.5.5.1.1.m1.1.1.1.1" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.cmml"><mi id="S3.T1.5.5.5.1.1.m1.1.1.1.1.2" mathcolor="#4178BC" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.2.cmml">w</mi><mo id="S3.T1.5.5.5.1.1.m1.1.1.1.1.1" mathcolor="#4178BC" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S3.T1.5.5.5.1.1.m1.1.1.1.1.3" mathcolor="#4178BC" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.3.cmml">5</mn></mrow><mo id="S3.T1.5.5.5.1.1.m1.1.1.1.3" mathcolor="#4178BC" stretchy="false" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.1.1.m1.1b"><apply id="S3.T1.5.5.5.1.1.m1.1.1.1.1.cmml" xref="S3.T1.5.5.5.1.1.m1.1.1.1"><eq id="S3.T1.5.5.5.1.1.m1.1.1.1.1.1.cmml" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.1"></eq><ci id="S3.T1.5.5.5.1.1.m1.1.1.1.1.2.cmml" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.2">𝑤</ci><cn id="S3.T1.5.5.5.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S3.T1.5.5.5.1.1.m1.1.1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.1.1.m1.1c">(w=5)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.5.1.1.m1.1d">( italic_w = 5 )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.5.5.5.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.5.5.5.3.1" style="background-color:#FFCFD2;">his</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.5.5.5.3.2"> <span class="ltx_text" id="S3.T1.5.5.5.3.2.1" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.5.5.5.3.2.2" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.5.5.5.3.2.3" style="background-color:#FDFD95;">He</span> <span class="ltx_text" id="S3.T1.5.5.5.3.2.4" style="background-color:#FDE4CF;"> cleans</span> <span class="ltx_text" id="S3.T1.5.5.5.3.2.5" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.5.5.5.3.2.6" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.5.5.5.3.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.5.5.5.3.2.8" style="background-color:#B9FBC0;">.</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.5.5.5.4" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.5.5.5.4.1" style="background-color:#FFCFD2;">his</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.5.5.5.4.2"> <span class="ltx_text" id="S3.T1.5.5.5.4.2.1" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.5.5.5.4.2.2" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.5.5.5.4.2.3" style="background-color:#FDFD95;">They</span> <span class="ltx_text" id="S3.T1.5.5.5.4.2.4" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.5.5.5.4.2.5" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.5.5.5.4.2.6" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.5.5.5.4.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.5.5.5.4.2.8" style="background-color:#B9FBC0;">.</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.6">
<td class="ltx_td ltx_border_r" id="S3.T1.6.6.6.2" style="padding-bottom:3.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.6.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.6.1.1" style="color:#AA71FF;">LocalShuffle<math alttext="(w=10)" class="ltx_Math" display="inline" id="S3.T1.6.6.6.1.1.m1.1"><semantics id="S3.T1.6.6.6.1.1.m1.1a"><mrow id="S3.T1.6.6.6.1.1.m1.1.1.1" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.cmml"><mo id="S3.T1.6.6.6.1.1.m1.1.1.1.2" mathcolor="#AA71FF" stretchy="false" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.T1.6.6.6.1.1.m1.1.1.1.1" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.cmml"><mi id="S3.T1.6.6.6.1.1.m1.1.1.1.1.2" mathcolor="#AA71FF" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.2.cmml">w</mi><mo id="S3.T1.6.6.6.1.1.m1.1.1.1.1.1" mathcolor="#AA71FF" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S3.T1.6.6.6.1.1.m1.1.1.1.1.3" mathcolor="#AA71FF" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.3.cmml">10</mn></mrow><mo id="S3.T1.6.6.6.1.1.m1.1.1.1.3" mathcolor="#AA71FF" stretchy="false" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.1.1.m1.1b"><apply id="S3.T1.6.6.6.1.1.m1.1.1.1.1.cmml" xref="S3.T1.6.6.6.1.1.m1.1.1.1"><eq id="S3.T1.6.6.6.1.1.m1.1.1.1.1.1.cmml" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.1"></eq><ci id="S3.T1.6.6.6.1.1.m1.1.1.1.1.2.cmml" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.2">𝑤</ci><cn id="S3.T1.6.6.6.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S3.T1.6.6.6.1.1.m1.1.1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.1.1.m1.1c">(w=10)</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.6.1.1.m1.1d">( italic_w = 10 )</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.6.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.6.3.1" style="background-color:#CFBAF0;">messy</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.6.3.2"> <span class="ltx_text" id="S3.T1.6.6.6.3.2.1" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.6.3.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.6.3.2.3" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.6.3.2.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.6.3.2.5" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.6.6.6.3.2.6" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.6.3.2.7" style="background-color:#FDFD95;">He</span> <span class="ltx_text" id="S3.T1.6.6.6.3.2.8" style="background-color:#FDE4CF;"> cleans</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.6.6.6.4" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.6.4.1" style="background-color:#CFBAF0;">messy</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.6.4.2"> <span class="ltx_text" id="S3.T1.6.6.6.4.2.1" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.6.4.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.6.4.2.3" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.6.4.2.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.6.4.2.5" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.6.6.6.4.2.6" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.6.4.2.7" style="background-color:#FDFD95;">They</span> <span class="ltx_text" id="S3.T1.6.6.6.4.2.8" style="background-color:#FDE4CF;"> clean</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.10.3">
<td class="ltx_td ltx_border_r" id="S3.T1.6.6.10.3.1" style="padding-bottom:3.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.10.3.2" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.10.3.2.1" style="color:#E37CFF;">EvenOddShuffle</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.10.3.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.10.3.3.1" style="background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.10.3.3.2"> <span class="ltx_text" id="S3.T1.6.6.10.3.3.2.1" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.10.3.3.2.2" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.10.3.3.2.3" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.10.3.3.2.4" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.6.6.10.3.3.2.5" style="background-color:#FDE4CF;"> cleans</span> <span class="ltx_text" id="S3.T1.6.6.10.3.3.2.6" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.10.3.3.2.7" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.10.3.3.2.8" style="background-color:#98F5E1;">lf</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.6.6.10.3.4" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.10.3.4.1" style="background-color:#FDFD95;">They</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.10.3.4.2"> <span class="ltx_text" id="S3.T1.6.6.10.3.4.2.1" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.10.3.4.2.2" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.10.3.4.2.3" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.10.3.4.2.4" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.6.6.10.3.4.2.5" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.10.3.4.2.6" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.10.3.4.2.7" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.10.3.4.2.8" style="background-color:#98F5E1;">lf</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.11.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.11.4.1" rowspan="2" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.11.4.1.1">*Reverse</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.11.4.2" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.11.4.2.1" style="color:#606060;">NoReverse</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.11.4.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.11.4.3.1" style="background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.11.4.3.2"> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.1" style="background-color:#FDE4CF;"> cleans</span> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.6" style="background-color:#8DE969;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.11.4.3.2.6.1" style="border-color: #000000;padding:1.0pt;">R</span></span> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.8" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.11.4.3.2.9" style="background-color:#B9FBC0;">.</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.6.6.11.4.4" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.11.4.4.1" style="background-color:#FDFD95;">They</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.11.4.4.2"> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.3" style="background-color:#8DE969;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.11.4.4.2.3.1" style="border-color: #000000;padding:1.0pt;">R</span></span> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.5" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.6" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.8" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.11.4.4.2.9" style="background-color:#B9FBC0;">.</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.12.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.12.5.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.12.5.1.1" style="color:#E5A836;">PartialReverse</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.12.5.2" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.12.5.2.1" style="background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.12.5.2.2"> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.1" style="background-color:#FDE4CF;"> cleans</span> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.6" style="background-color:#8DE969;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.12.5.2.2.6.1" style="border-color: #000000;padding:1.0pt;">R</span></span> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.7" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.8" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.12.5.2.2.9" style="background-color:#90DBF4;">he</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.6.6.12.5.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.12.5.3.1" style="background-color:#FDFD95;">They</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.12.5.3.2"> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.3" style="background-color:#8DE969;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.12.5.3.2.3.1" style="border-color: #000000;padding:1.0pt;">R</span></span> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.4" style="background-color:#B9FBC0;">.</span> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.5" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.6" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.7" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.8" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.12.5.3.2.9" style="background-color:#F1C0E8;"> very</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.13.6">
<td class="ltx_td ltx_border_r" id="S3.T1.6.6.13.6.1" style="padding-bottom:3.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.13.6.2" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.13.6.2.1" style="color:#A348A6;">FullReverse</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.13.6.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.13.6.3.1" style="background-color:#B9FBC0;">.</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.13.6.3.2"> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.1" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.2" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.3" style="background-color:#8DE969;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.13.6.3.2.3.1" style="border-color: #000000;padding:1.0pt;">R</span></span> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.4" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.5" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.6" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.7" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.8" style="background-color:#FDE4CF;"> cleans</span> <span class="ltx_text" id="S3.T1.6.6.13.6.3.2.9" style="background-color:#FDFD95;">He</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.6.6.13.6.4" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.13.6.4.1" style="background-color:#B9FBC0;">.</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.13.6.4.2"> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.1" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.2" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.3" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.5" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.6" style="background-color:#8DE969;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.13.6.4.2.6.1" style="border-color: #000000;padding:1.0pt;">R</span></span> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.7" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.8" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.13.6.4.2.9" style="background-color:#FDFD95;">They</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.14.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.14.7.1" rowspan="2" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.14.7.1.1">*Hop</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.14.7.2" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.14.7.2.1" style="color:#606060;">NoHop</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.14.7.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.14.7.3.1" style="background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.14.7.3.2"> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.2" style="background-color:#FF77E6;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.14.7.3.2.2.1" style="border-color: #000000;padding:1.0pt;">S</span></span> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.3" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.5" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.6" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.8" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.14.7.3.2.9" style="background-color:#B9FBC0;">.</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.6.6.14.7.4" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.14.7.4.1" style="background-color:#FDFD95;">They</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.14.7.4.2"> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.2" style="background-color:#3EC8FF;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.14.7.4.2.2.1" style="border-color: #000000;padding:1.0pt;">P</span></span> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.3" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.5" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.6" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.8" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.14.7.4.2.9" style="background-color:#B9FBC0;">.</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.15.8">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.15.8.1" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.15.8.1.1" style="color:#FA8128;">TokenHop</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.15.8.2" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.15.8.2.1" style="background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.15.8.2.2"> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.6" style="background-color:#FF77E6;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.15.8.2.2.6.1" style="border-color: #000000;padding:1.0pt;">S</span></span> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.8" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.15.8.2.2.9" style="background-color:#B9FBC0;">.</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.6.6.15.8.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.15.8.3.1" style="background-color:#FDFD95;">They</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.15.8.3.2"> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.6" style="background-color:#3EC8FF;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.15.8.3.2.6.1" style="border-color: #000000;padding:1.0pt;">P</span></span> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.8" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.15.8.3.2.9" style="background-color:#B9FBC0;">.</span></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6.16.9">
<td class="ltx_td ltx_border_bb ltx_border_r" id="S3.T1.6.6.16.9.1" style="padding-bottom:3.0pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.6.6.16.9.2" style="padding-bottom:3.0pt;"><span class="ltx_text ltx_font_smallcaps" id="S3.T1.6.6.16.9.2.1" style="color:#03A0FF;">WordHop</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.6.6.16.9.3" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.16.9.3.1" style="background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.16.9.3.2"> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.6" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.7" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.8" style="background-color:#FF77E6;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.16.9.3.2.8.1" style="border-color: #000000;padding:1.0pt;">S</span></span> <span class="ltx_text" id="S3.T1.6.6.16.9.3.2.9" style="background-color:#B9FBC0;">.</span></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T1.6.6.16.9.4" style="padding-bottom:3.0pt;">
<span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.16.9.4.1" style="background-color:#FDFD95;">They</span><span class="ltx_text ltx_font_typewriter" id="S3.T1.6.6.16.9.4.2"> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.2" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.6" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.7" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.8" style="background-color:#3EC8FF;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S3.T1.6.6.16.9.4.2.8.1" style="border-color: #000000;padding:1.0pt;">P</span></span> <span class="ltx_text" id="S3.T1.6.6.16.9.4.2.9" style="background-color:#B9FBC0;">.</span></span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>List of impossible languages with examples. Control (‘<span class="ltx_text ltx_font_smallcaps" id="S3.T1.8.1">No*</span>’) languages have patterns that resemble English. Differently colored
blocks represent different GPT-2 tokens. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Core to our experiments are the set of <em class="ltx_emph ltx_font_italic" id="S3.p1.1.1">impossible languages</em> we synthesize. In constructing these artificial counterfactual languages, we consider their information-theoretic attributes relevant to machine learning, such as entropy rate, as well as their formal linguistic characteristics, such as adherence to hierarchical grammatical structures. We believe that our choice of languages broadly spans the impossibility continuum hypothesized in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S1.F1" title="In 1 Introduction ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Concretely, we specify impossible languages by defining <em class="ltx_emph ltx_font_italic" id="S3.p2.1.1">perturbation functions</em> of English sentences. These perturbation functions map English input sentences to sequences of tokens. We categorize our languages into three classes: <span class="ltx_text ltx_font_smallcaps" id="S3.p2.1.2">*Shuffle</span>, <span class="ltx_text ltx_font_smallcaps" id="S3.p2.1.3">*Reverse</span>, and <span class="ltx_text ltx_font_smallcaps" id="S3.p2.1.4">*Hop</span>, defined in the next subsections. Each class has one control language that represents unaltered English, or a pattern that is very similar to English. <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S3.T1" title="In 3 Impossible Languages ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a> provides examples of perturbed sentences in each language.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span class="ltx_text ltx_font_smallcaps" id="S3.SS1.1.1">*Shuffle</span> Languages.</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The first set of impossible languages, which we call the <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p1.1.1">*Shuffle</span> languages, involve different shuffles of tokenized English sentences.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I1.i1.p1.1.1" style="color:#606060;">NoShuffle</span>: The input sentence is tokenized, and the token sequence is unaltered. This language is simply English, used for comparison with other <span class="ltx_text ltx_font_smallcaps" id="S3.I1.i1.p1.1.2">*Shuffle</span> languages.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I1.i2.p1.1.1" style="color:#E8384F;">NondeterministicShuffle</span>: The tokenized input sentence is randomly shuffled. A different random shuffle is used for each input sentence, with no consistency across inputs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.2"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I1.i3.p1.1.1" style="color:#8DB000;">DeterministicShuffle<span class="ltx_text ltx_font_upright" id="S3.I1.i3.p1.1.1.1">(<math alttext="s" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.1.1.m1.1"><semantics id="S3.I1.i3.p1.1.1.1.m1.1a"><mi id="S3.I1.i3.p1.1.1.1.m1.1.1" mathcolor="#8DB000" xref="S3.I1.i3.p1.1.1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.1.1.m1.1b"><ci id="S3.I1.i3.p1.1.1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.1.1.m1.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.1.1.m1.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.1.1.m1.1d">italic_s</annotation></semantics></math>)</span></span>: The tokenized input sentence is deterministically shuffled based on the length of the token sequence. For example, all token sequences of length&nbsp;5 are shuffled in the same order. We create several languages by varying the random seed&nbsp;<math alttext="s" class="ltx_Math" display="inline" id="S3.I1.i3.p1.2.m1.1"><semantics id="S3.I1.i3.p1.2.m1.1a"><mi id="S3.I1.i3.p1.2.m1.1.1" xref="S3.I1.i3.p1.2.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.2.m1.1b"><ci id="S3.I1.i3.p1.2.m1.1.1.cmml" xref="S3.I1.i3.p1.2.m1.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.2.m1.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.2.m1.1d">italic_s</annotation></semantics></math> that produces the shuffle.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.3"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I1.i4.p1.1.1" style="color:#4178BC;">LocalShuffle<span class="ltx_text ltx_font_upright" id="S3.I1.i4.p1.1.1.1">(<math alttext="w" class="ltx_Math" display="inline" id="S3.I1.i4.p1.1.1.1.m1.1"><semantics id="S3.I1.i4.p1.1.1.1.m1.1a"><mi id="S3.I1.i4.p1.1.1.1.m1.1.1" mathcolor="#4178BC" xref="S3.I1.i4.p1.1.1.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i4.p1.1.1.1.m1.1b"><ci id="S3.I1.i4.p1.1.1.1.m1.1.1.cmml" xref="S3.I1.i4.p1.1.1.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i4.p1.1.1.1.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i4.p1.1.1.1.m1.1d">italic_w</annotation></semantics></math>)</span></span>: The tokenized input sentence is deterministically shuffled in local windows of a fixed size <math alttext="w" class="ltx_Math" display="inline" id="S3.I1.i4.p1.2.m1.1"><semantics id="S3.I1.i4.p1.2.m1.1a"><mi id="S3.I1.i4.p1.2.m1.1.1" xref="S3.I1.i4.p1.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i4.p1.2.m1.1b"><ci id="S3.I1.i4.p1.2.m1.1.1.cmml" xref="S3.I1.i4.p1.2.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i4.p1.2.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i4.p1.2.m1.1d">italic_w</annotation></semantics></math>. We create several languages by varying <math alttext="w" class="ltx_Math" display="inline" id="S3.I1.i4.p1.3.m2.1"><semantics id="S3.I1.i4.p1.3.m2.1a"><mi id="S3.I1.i4.p1.3.m2.1.1" xref="S3.I1.i4.p1.3.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i4.p1.3.m2.1b"><ci id="S3.I1.i4.p1.3.m2.1.1.cmml" xref="S3.I1.i4.p1.3.m2.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i4.p1.3.m2.1c">w</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i4.p1.3.m2.1d">italic_w</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I1.i5.p1.1.1" style="color:#E37CFF;">EvenOddShuffle</span>: The tokenized input sentence is reordered such that all even-indexed tokens appear first, followed by all odd-indexed tokens.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">The random shuffling function that generates the <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p3.1.1">NondeterministicShuffle</span> language is irreversible, resulting in sentences that are purely bags of words—any structural information in the original linguistic signal is irretrievable.
While the <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p3.1.2">DeterministicShuffle</span> languages are created using a reversible perturbation function, this function operates in an entirely non-linguistic manner; words are ordered based solely on the random seed and sentence length, without considerations for linguistic features or <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.3">information locality</em>—the property that, when parts of text predict each other, they are often close together <cite class="ltx_cite ltx_citemacro_citep">(Futrell, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib18" title="">2019</a>; Mansfield and Kemp, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib42" title="">2023</a>)</cite>. This method is arguably even less humanly feasible than <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p3.1.4">NondeterministicShuffle</span>, as it relies on an arbitrarily complex yet consistent rule to determine word order.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Even in the imaginable case of a language with completely free word order, it seems extremely unlikely that this freedom would be totally insensitive to any clause boundaries while the language otherwise looks morphologically like English does. It thus seems very safe to assume that our <span class="ltx_text ltx_font_smallcaps" id="footnote3.1">NondeterministicShuffle</span> language counts as impossible.</span></span></span>
The question of ranking these two families of languages in the impossibility continuum probes at the definition of impossibility and whether reversibility to an attested language like English is a relevant quantity.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">The <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p4.1.1">LocalShuffle</span> languages offer a finer-grained testbed for the importance of information locality, since we can observe the effects of different window sizes. Finally, <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p4.1.2">EvenOddShuffle</span> also manipulates locality, but interestingly preserves part of the linear word order of English while introducing new long-distance dependencies.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.1.1">*Reverse</span> Languages.</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p1.1.1">*Reverse</span> impossible languages involve reversals of all or part of input sentences.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I2.i1.p1.1.1" style="color:#606060;">NoReverse</span>: The input sentence is tokenized, and a special marker token <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S3.I2.i1.p1.1.2" style="border-color: #000000;padding:1.0pt;">R</span> is inserted at a random position in the token list. Like <span class="ltx_text ltx_font_smallcaps" id="S3.I2.i1.p1.1.3">NoShuffle</span>, this language is most similar to English. We use it for comparison with other <span class="ltx_text ltx_font_smallcaps" id="S3.I2.i1.p1.1.4">*Reverse</span> languages.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I2.i2.p1.1.1" style="color:#E5A836;">PartialReverse</span>: The input sentence is tokenized, a special marker token <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S3.I2.i2.p1.1.2" style="border-color: #000000;padding:1.0pt;">R</span> is inserted at a random position in the list of tokens, and the following tokens are reversed.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I2.i3.p1.1.1" style="color:#A348A6;">FullReverse</span>: The input sentence is tokenized, a special marker token <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S3.I2.i3.p1.1.2" style="border-color: #000000;padding:1.0pt;">R</span> is inserted at a random position in the token list, and <em class="ltx_emph ltx_font_italic" id="S3.I2.i3.p1.1.3">all</em> tokens are reversed.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">The <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p3.1.1">PartialReverse</span> language is inspired by the experiments of <cite class="ltx_cite ltx_citemacro_citet">Mitchell and Bowers (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib46" title="">2020</a>)</cite> on partially reversed English data, though our experiments are not a direct replication, since we use a different model architecture and dataset. <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p3.1.2">FullReverse</span> may seem like a plausible language syntactically, but higher-level linguistic concepts like anaphora would be highly disrupted.
The <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S3.SS2.p3.1.3" style="border-color: #000000;padding:1.0pt;">R</span> tokens are placed at the same positions across the data in all <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p3.1.4">*Reverse</span> languages to control for the entropy introduced by their random placement.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span class="ltx_text ltx_font_smallcaps" id="S3.SS3.1.1">*Hop</span> Languages.</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p1.1.1">*Hop</span> languages perturb verb inflection with counting rules.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<ol class="ltx_enumerate" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p" id="S3.I3.i1.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I3.i1.p1.1.1" style="color:#606060;">NoHop</span>: All 3rd-person present tense verbs in the input sentence are lemmatized, and the sentence is tokenized. For each 3rd-person present tense verb, a special marker representing the verb’s number and tense is placed right after the lemmatized verb. Singular verbs are marked with a special token <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S3.I3.i1.p1.1.2" style="border-color: #000000;padding:1.0pt;">S</span>, and plural verbs are marked with <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S3.I3.i1.p1.1.3" style="border-color: #000000;padding:1.0pt;">P</span>. Like the other control languages, <span class="ltx_text ltx_font_smallcaps" id="S3.I3.i1.p1.1.4">NoHop</span> has a pattern that is most similar to English.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p" id="S3.I3.i2.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I3.i2.p1.1.1" style="color:#FA8128;">TokenHop</span>: Identical transformation to <span class="ltx_text ltx_font_smallcaps" id="S3.I3.i2.p1.1.2">NoHop</span>, but the special number/tense markers are placed 4 tokens after the verb.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I3.i3.p1">
<p class="ltx_p" id="S3.I3.i3.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.I3.i3.p1.1.1" style="color:#03A0FF;">WordHop</span>: Identical transformation to <span class="ltx_text ltx_font_smallcaps" id="S3.I3.i3.p1.1.2">NoHop</span> and <span class="ltx_text ltx_font_smallcaps" id="S3.I3.i3.p1.1.3">TokenHop</span>, but the special number/tense markers are placed 4 <em class="ltx_emph ltx_font_italic" id="S3.I3.i3.p1.1.4">words</em> after the verb, skipping punctuation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">These languages specifically investigate GPT-2’s ability to learn grammar rules that involve counting the positions of words or tokens.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="298" id="S4.F2.g1" src="./Mission_ Impossible Language Models_files/x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Perplexities on a sample of 10K test sentences for each
impossible language model over training steps. Error bars indicate 95% confidence intervals across 5 training runs initialized with different random seeds and evaluated on different test samples.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We run several experiments to assess GPT-2’s learning of our impossible languages. Our first experiment (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS2" title="4.2 Experiment 1: Language Models Reflect the Impossibility Continuum ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.2</span></a>) uses perplexities as a general evaluation to compare how well each impossible language model has learned its own perturbed language and see whether this reflects the hypothesized impossibility continuum. In our second and third experiments, we conduct a closer examination of the <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.1">*Hop</span> languages. Given that their count-based verb marking rules appear to be the least clearly implausible among our proposed languages, we focus on examining these rules specifically through targeted assessments using surprisal theory (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3" title="4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.3</span></a>). Finally, we dive deeper into the mechanisms each <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.2">*Hop</span> model uses to predict their respective verb marking rules using causal abstraction analysis (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS4" title="4.4 Experiment 3: Language Models Develop Natural Solutions to Unnatural Patterns ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.4</span></a>). For all evaluations, we run tests on several model checkpoints to observe the learning process over intervals of training steps.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>
We also conduct a constituency probing experiment to test effects on GPT-2’s implicit understanding of syntax, with minimal observed differences among models (see <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A4" title="Appendix D Constituency Probing Evaluation ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">D</span></a>).</span></span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Implementation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">For each impossible language, we apply its perturbation function to each sentence of the BabyLM dataset <cite class="ltx_cite ltx_citemacro_cite">Warstadt et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib63" title="">2023</a>)</cite> to create a transformed dataset.
<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A1" title="Appendix A Dataset Filters ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">A</span></a> provides details on preprocessing and formatting, and describes the language-specific filtering needed to achieve the criteria that define each language.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">We train standard GPT-2 small models <cite class="ltx_cite ltx_citemacro_cite">Radford et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib57" title="">2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib58" title="">2019</a>)</cite> on each impossible language. To produce confidence intervals for our experiments, we train 5 sets of models for each language using different random seeds, which affect the model parameter initialization and dataset shuffling during training. Training and model hyperparameter choices are detailed in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A2" title="Appendix B GPT-2 Training Details and Hyperparameters ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">B</span></a>.
The primary set of GPT-2 models we train have absolute positional encodings. We also train a set of GPT-2 small models with an architecture in which the positional encodings are removed, so that the models’ only notion of word order is derived from <span class="ltx_text" id="S4.SS1.p2.1.1">GPT-2’s</span> causal language modeling learning objective <cite class="ltx_cite ltx_citemacro_cite">Kazemnejad et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib40" title="">2023</a>)</cite>. Results for these additional experiments supported our main findings on the unaltered GPT-2 architecture. These results are provided in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A3" title="Appendix C Results for Models without Positional Encodings ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">C</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experiment 1: Language Models Reflect the Impossibility Continuum</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We train GPT-2 models on all of the languages described in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S3.T1" title="In 3 Impossible Languages ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>, and evaluate each model’s perplexities on a test set over the course of training. Test perplexities provide a general metric for the extent to which a model has learned a language.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setup.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">We sample 10K sentences from the BabyLM test set and perturb this sample for each impossible language. For a given impossible language model, we report the geometric mean of the individual sentence perplexities in the corresponding test sample.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Hypothesis.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">Models trained on possible languages will achieve lower average perplexities more quickly (as measured in training steps) than those trained on impossible languages.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px3.p1.1">Our results are in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.F2" title="In 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>.
There are clear distinctions between model perplexities after about 500 training steps. First considering the <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p1.1.1">*Shuffle</span> models, the <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p1.1.2">NondeterministicShuffle</span> model has the highest perplexities, followed by the three <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p1.1.3">DeterministicShuffle</span> models, indicating that GPT-2 is better at learning shuffling patterns when they are deterministic, invertible functions.<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>This result is also supported by separate evaluations of each <span class="ltx_text ltx_font_smallcaps" id="footnote5.1">DeterministicShuffle</span> model on test data from other shuffles (see <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A5" title="Appendix E Additional DeterministicShuffle Results ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">E</span></a>). Each model has lower perplexities on its own deterministic shuffle.</span></span></span>
The prevalence of certain sentence lengths in the corpus could also limit the variety of sentence shuffles in the <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p1.1.4">DeterministicShuffle</span> languages, potentially resulting in similarly functioning words frequently occupying the same token positions, thus increasing their predictability.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS2.SSS0.Px3.p2.1">Following the sentence-level shuffles, the next models in the order of decreasing perplexity are the three <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.1.2">LocalShuffle</span> models, with smaller window sizes having lower perplexities. <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.1.1">LocalShuffle<math alttext="(w=3)" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px3.p2.1.1.m1.1"><semantics id="S4.SS2.SSS0.Px3.p2.1.1.m1.1a"><mrow id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.cmml"><mo id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.2" stretchy="false" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.cmml"><mi id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.2" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.2.cmml">w</mi><mo id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.1" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.3" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.3.cmml">3</mn></mrow><mo id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.3" stretchy="false" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.1.1.m1.1b"><apply id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1"><eq id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.1"></eq><ci id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.2">𝑤</ci><cn id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p2.1.1.m1.1c">(w=3)</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px3.p2.1.1.m1.1d">( italic_w = 3 )</annotation></semantics></math></span> and <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.1.3">EvenOddShuffle</span> have perplexities closest to the <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.1.4">NoShuffle</span> model (which represents unaltered English), but <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.1.5">NoShuffle</span> consistently has the lowest perplexities throughout the training process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.SSS0.Px3.p3">
<p class="ltx_p" id="S4.SS2.SSS0.Px3.p3.1">Compared to the <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p3.1.1">*Shuffle</span> models, the experimental <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p3.1.2">*Reverse</span> models have perplexities that are much closer to the <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p3.1.3">NoReverse</span> model, and <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p3.1.4">PartialReverse</span> is slightly better than <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p3.1.5">FullReverse</span>. For the <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p3.1.6">*Hop</span> languages, their respective control model again has the lowest perplexities, although differences among the models are quite minimal.
This warrants our deep-dive into the particular verb marking patterns for this set of models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Experiment 2: Language Models Disprefer Counting Rules</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="595" id="S4.F3.sf1.g1" src="./Mission_ Impossible Language Models_files/x3.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Test 1: mean surprisals of the verb marker token (<span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.F3.sf1.4.1" style="border-color: #000000;padding:1.0pt;">S</span> or <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.F3.sf1.5.2" style="border-color: #000000;padding:1.0pt;">P</span>) for each <span class="ltx_text ltx_font_smallcaps" id="S4.F3.sf1.6.3">*Hop</span> model. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="595" id="S4.F3.sf2.g1" src="./Mission_ Impossible Language Models_files/x4.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Test 2: mean surprisal difference between the verb marker token (<span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.F3.sf2.4.1" style="border-color: #000000;padding:1.0pt;">S</span> or <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.F3.sf2.5.2" style="border-color: #000000;padding:1.0pt;">P</span>) and the following token for each <span class="ltx_text ltx_font_smallcaps" id="S4.F3.sf2.6.3">*Hop</span> model.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Surprisal tests for each <span class="ltx_text ltx_font_smallcaps" id="S4.F3.2.1">*Hop</span> model over training steps. Error bars indicate 95% confidence intervals across 5 training runs initialized with different random seeds and evaluated on different test samples.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In Experiment 1, we show that impossible languages are harder for GPT-2 to learn. However, perplexity is a coarse-grained metric of language learning, and the question remains: do language models learn natural grammatical structures better than impossible grammars?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.5">The structure of the <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p2.5.1">*Hop</span> languages invites a
finer-grained evaluation of their verb marking rules. We use <em class="ltx_emph ltx_font_italic" id="S4.SS3.p2.5.2">surprisals</em> to measure how well each <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p2.5.3">*Hop</span> model can predict the placement of its
verb marker tokens, <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS3.p2.5.4" style="border-color: #000000;padding:1.0pt;">S</span> and <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS3.p2.5.5" style="border-color: #000000;padding:1.0pt;">P</span>. The surprisal
<math alttext="S(w_{i})" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">S</mi><mo id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">⁢</mo><mrow id="S4.SS3.p2.1.m1.1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.1.1.cmml"><mo id="S4.SS3.p2.1.m1.1.1.1.1.2" stretchy="false" xref="S4.SS3.p2.1.m1.1.1.1.1.1.cmml">(</mo><msub id="S4.SS3.p2.1.m1.1.1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.1.1.1.2.cmml">w</mi><mi id="S4.SS3.p2.1.m1.1.1.1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS3.p2.1.m1.1.1.1.1.3" stretchy="false" xref="S4.SS3.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><times id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2"></times><ci id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">𝑆</ci><apply id="S4.SS3.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.1.1.1.2">𝑤</ci><ci id="S4.SS3.p2.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">S(w_{i})</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">italic_S ( italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> of a word <math alttext="w_{i}" class="ltx_Math" display="inline" id="S4.SS3.p2.2.m2.1"><semantics id="S4.SS3.p2.2.m2.1a"><msub id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mi id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">w</mi><mi id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">𝑤</ci><ci id="S4.SS3.p2.2.m2.1.1.3.cmml" xref="S4.SS3.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">w_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.2.m2.1d">italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the negative log probability of <math alttext="w_{i}" class="ltx_Math" display="inline" id="S4.SS3.p2.3.m3.1"><semantics id="S4.SS3.p2.3.m3.1a"><msub id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">w</mi><mi id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">𝑤</ci><ci id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">w_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.3.m3.1d">italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> given
the context words <math alttext="w_{1},\ldots,w_{i-1}" class="ltx_Math" display="inline" id="S4.SS3.p2.4.m4.3"><semantics id="S4.SS3.p2.4.m4.3a"><mrow id="S4.SS3.p2.4.m4.3.3.2" xref="S4.SS3.p2.4.m4.3.3.3.cmml"><msub id="S4.SS3.p2.4.m4.2.2.1.1" xref="S4.SS3.p2.4.m4.2.2.1.1.cmml"><mi id="S4.SS3.p2.4.m4.2.2.1.1.2" xref="S4.SS3.p2.4.m4.2.2.1.1.2.cmml">w</mi><mn id="S4.SS3.p2.4.m4.2.2.1.1.3" xref="S4.SS3.p2.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.SS3.p2.4.m4.3.3.2.3" xref="S4.SS3.p2.4.m4.3.3.3.cmml">,</mo><mi id="S4.SS3.p2.4.m4.1.1" mathvariant="normal" xref="S4.SS3.p2.4.m4.1.1.cmml">…</mi><mo id="S4.SS3.p2.4.m4.3.3.2.4" xref="S4.SS3.p2.4.m4.3.3.3.cmml">,</mo><msub id="S4.SS3.p2.4.m4.3.3.2.2" xref="S4.SS3.p2.4.m4.3.3.2.2.cmml"><mi id="S4.SS3.p2.4.m4.3.3.2.2.2" xref="S4.SS3.p2.4.m4.3.3.2.2.2.cmml">w</mi><mrow id="S4.SS3.p2.4.m4.3.3.2.2.3" xref="S4.SS3.p2.4.m4.3.3.2.2.3.cmml"><mi id="S4.SS3.p2.4.m4.3.3.2.2.3.2" xref="S4.SS3.p2.4.m4.3.3.2.2.3.2.cmml">i</mi><mo id="S4.SS3.p2.4.m4.3.3.2.2.3.1" xref="S4.SS3.p2.4.m4.3.3.2.2.3.1.cmml">−</mo><mn id="S4.SS3.p2.4.m4.3.3.2.2.3.3" xref="S4.SS3.p2.4.m4.3.3.2.2.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.3b"><list id="S4.SS3.p2.4.m4.3.3.3.cmml" xref="S4.SS3.p2.4.m4.3.3.2"><apply id="S4.SS3.p2.4.m4.2.2.1.1.cmml" xref="S4.SS3.p2.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.2.2.1.1.1.cmml" xref="S4.SS3.p2.4.m4.2.2.1.1">subscript</csymbol><ci id="S4.SS3.p2.4.m4.2.2.1.1.2.cmml" xref="S4.SS3.p2.4.m4.2.2.1.1.2">𝑤</ci><cn id="S4.SS3.p2.4.m4.2.2.1.1.3.cmml" type="integer" xref="S4.SS3.p2.4.m4.2.2.1.1.3">1</cn></apply><ci id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">…</ci><apply id="S4.SS3.p2.4.m4.3.3.2.2.cmml" xref="S4.SS3.p2.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.4.m4.3.3.2.2.1.cmml" xref="S4.SS3.p2.4.m4.3.3.2.2">subscript</csymbol><ci id="S4.SS3.p2.4.m4.3.3.2.2.2.cmml" xref="S4.SS3.p2.4.m4.3.3.2.2.2">𝑤</ci><apply id="S4.SS3.p2.4.m4.3.3.2.2.3.cmml" xref="S4.SS3.p2.4.m4.3.3.2.2.3"><minus id="S4.SS3.p2.4.m4.3.3.2.2.3.1.cmml" xref="S4.SS3.p2.4.m4.3.3.2.2.3.1"></minus><ci id="S4.SS3.p2.4.m4.3.3.2.2.3.2.cmml" xref="S4.SS3.p2.4.m4.3.3.2.2.3.2">𝑖</ci><cn id="S4.SS3.p2.4.m4.3.3.2.2.3.3.cmml" type="integer" xref="S4.SS3.p2.4.m4.3.3.2.2.3.3">1</cn></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.3c">w_{1},\ldots,w_{i-1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.4.m4.3d">italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_w start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT</annotation></semantics></math> that precede it:
<math alttext="S(w_{i})=-\log_{2}p(w_{i}|w_{1},\ldots,w_{i-1})" class="ltx_Math" display="inline" id="S4.SS3.p2.5.m5.3"><semantics id="S4.SS3.p2.5.m5.3a"><mrow id="S4.SS3.p2.5.m5.3.3" xref="S4.SS3.p2.5.m5.3.3.cmml"><mrow id="S4.SS3.p2.5.m5.2.2.1" xref="S4.SS3.p2.5.m5.2.2.1.cmml"><mi id="S4.SS3.p2.5.m5.2.2.1.3" xref="S4.SS3.p2.5.m5.2.2.1.3.cmml">S</mi><mo id="S4.SS3.p2.5.m5.2.2.1.2" xref="S4.SS3.p2.5.m5.2.2.1.2.cmml">⁢</mo><mrow id="S4.SS3.p2.5.m5.2.2.1.1.1" xref="S4.SS3.p2.5.m5.2.2.1.1.1.1.cmml"><mo id="S4.SS3.p2.5.m5.2.2.1.1.1.2" stretchy="false" xref="S4.SS3.p2.5.m5.2.2.1.1.1.1.cmml">(</mo><msub id="S4.SS3.p2.5.m5.2.2.1.1.1.1" xref="S4.SS3.p2.5.m5.2.2.1.1.1.1.cmml"><mi id="S4.SS3.p2.5.m5.2.2.1.1.1.1.2" xref="S4.SS3.p2.5.m5.2.2.1.1.1.1.2.cmml">w</mi><mi id="S4.SS3.p2.5.m5.2.2.1.1.1.1.3" xref="S4.SS3.p2.5.m5.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS3.p2.5.m5.2.2.1.1.1.3" stretchy="false" xref="S4.SS3.p2.5.m5.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.p2.5.m5.3.3.3" xref="S4.SS3.p2.5.m5.3.3.3.cmml">=</mo><mrow id="S4.SS3.p2.5.m5.3.3.2" xref="S4.SS3.p2.5.m5.3.3.2.cmml"><mo id="S4.SS3.p2.5.m5.3.3.2a" rspace="0.167em" xref="S4.SS3.p2.5.m5.3.3.2.cmml">−</mo><mrow id="S4.SS3.p2.5.m5.3.3.2.1" xref="S4.SS3.p2.5.m5.3.3.2.1.cmml"><mrow id="S4.SS3.p2.5.m5.3.3.2.1.3" xref="S4.SS3.p2.5.m5.3.3.2.1.3.cmml"><msub id="S4.SS3.p2.5.m5.3.3.2.1.3.1" xref="S4.SS3.p2.5.m5.3.3.2.1.3.1.cmml"><mi id="S4.SS3.p2.5.m5.3.3.2.1.3.1.2" xref="S4.SS3.p2.5.m5.3.3.2.1.3.1.2.cmml">log</mi><mn id="S4.SS3.p2.5.m5.3.3.2.1.3.1.3" xref="S4.SS3.p2.5.m5.3.3.2.1.3.1.3.cmml">2</mn></msub><mo id="S4.SS3.p2.5.m5.3.3.2.1.3a" lspace="0.167em" xref="S4.SS3.p2.5.m5.3.3.2.1.3.cmml">⁡</mo><mi id="S4.SS3.p2.5.m5.3.3.2.1.3.2" xref="S4.SS3.p2.5.m5.3.3.2.1.3.2.cmml">p</mi></mrow><mo id="S4.SS3.p2.5.m5.3.3.2.1.2" xref="S4.SS3.p2.5.m5.3.3.2.1.2.cmml">⁢</mo><mrow id="S4.SS3.p2.5.m5.3.3.2.1.1.1" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.cmml"><mo id="S4.SS3.p2.5.m5.3.3.2.1.1.1.2" stretchy="false" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.cmml"><msub id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.cmml"><mi id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.2" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.2.cmml">w</mi><mi id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.3" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.3.cmml">i</mi></msub><mo fence="false" id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.3" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.3.cmml">|</mo><mrow id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.3.cmml"><msub id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.cmml"><mi id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.2" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.2.cmml">w</mi><mn id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.3" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.3" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.3.cmml">,</mo><mi id="S4.SS3.p2.5.m5.1.1" mathvariant="normal" xref="S4.SS3.p2.5.m5.1.1.cmml">…</mi><mo id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.4" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.3.cmml">,</mo><msub id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.cmml"><mi id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.2" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.2.cmml">w</mi><mrow id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.cmml"><mi id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.2" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.2.cmml">i</mi><mo id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.1" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.1.cmml">−</mo><mn id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.3" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msub></mrow></mrow><mo id="S4.SS3.p2.5.m5.3.3.2.1.1.1.3" stretchy="false" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.3b"><apply id="S4.SS3.p2.5.m5.3.3.cmml" xref="S4.SS3.p2.5.m5.3.3"><eq id="S4.SS3.p2.5.m5.3.3.3.cmml" xref="S4.SS3.p2.5.m5.3.3.3"></eq><apply id="S4.SS3.p2.5.m5.2.2.1.cmml" xref="S4.SS3.p2.5.m5.2.2.1"><times id="S4.SS3.p2.5.m5.2.2.1.2.cmml" xref="S4.SS3.p2.5.m5.2.2.1.2"></times><ci id="S4.SS3.p2.5.m5.2.2.1.3.cmml" xref="S4.SS3.p2.5.m5.2.2.1.3">𝑆</ci><apply id="S4.SS3.p2.5.m5.2.2.1.1.1.1.cmml" xref="S4.SS3.p2.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.2.2.1.1.1.1.1.cmml" xref="S4.SS3.p2.5.m5.2.2.1.1.1">subscript</csymbol><ci id="S4.SS3.p2.5.m5.2.2.1.1.1.1.2.cmml" xref="S4.SS3.p2.5.m5.2.2.1.1.1.1.2">𝑤</ci><ci id="S4.SS3.p2.5.m5.2.2.1.1.1.1.3.cmml" xref="S4.SS3.p2.5.m5.2.2.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S4.SS3.p2.5.m5.3.3.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2"><minus id="S4.SS3.p2.5.m5.3.3.2.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2"></minus><apply id="S4.SS3.p2.5.m5.3.3.2.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1"><times id="S4.SS3.p2.5.m5.3.3.2.1.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.2"></times><apply id="S4.SS3.p2.5.m5.3.3.2.1.3.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.3"><apply id="S4.SS3.p2.5.m5.3.3.2.1.3.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.3.1"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.3.3.2.1.3.1.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.3.1">subscript</csymbol><log id="S4.SS3.p2.5.m5.3.3.2.1.3.1.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.3.1.2"></log><cn id="S4.SS3.p2.5.m5.3.3.2.1.3.1.3.cmml" type="integer" xref="S4.SS3.p2.5.m5.3.3.2.1.3.1.3">2</cn></apply><ci id="S4.SS3.p2.5.m5.3.3.2.1.3.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.3.2">𝑝</ci></apply><apply id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1"><csymbol cd="latexml" id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.3.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.3">conditional</csymbol><apply id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4">subscript</csymbol><ci id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.2">𝑤</ci><ci id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.3.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.4.3">𝑖</ci></apply><list id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.3.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2"><apply id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.2">𝑤</ci><cn id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.1.1.1.3">1</cn></apply><ci id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">…</ci><apply id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.2">𝑤</ci><apply id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3"><minus id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.1.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.1"></minus><ci id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.2.cmml" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.2">𝑖</ci><cn id="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.3.cmml" type="integer" xref="S4.SS3.p2.5.m5.3.3.2.1.1.1.1.2.2.2.3.3">1</cn></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.3c">S(w_{i})=-\log_{2}p(w_{i}|w_{1},\ldots,w_{i-1})</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.5.m5.3d">italic_S ( italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = - roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_p ( italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_w start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT )</annotation></semantics></math>.
Surprisals have been used as acceptability judgments from neural language models to probe for their processing of syntactic information
<cite class="ltx_cite ltx_citemacro_cite">Wilcox et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib65" title="">2018</a>); Futrell et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib20" title="">2019</a>); Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib34" title="">2020</a>); Wilcox et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib66" title="">2023</a>)</cite> and have been shown to correlate with human sentence processing difficulty
<cite class="ltx_cite ltx_citemacro_cite">Hale (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib29" title="">2001</a>); Levy (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib41" title="">2008</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setup.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">To test the <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.1">*Hop</span> models’ sensitivity to marker placement, we conduct two tests on a sample of 10K sentences extracted from the BabyLM dataset containing the verb marker tokens (<span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p1.1.2" style="border-color: #000000;padding:1.0pt;">S</span> or <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p1.1.3" style="border-color: #000000;padding:1.0pt;">P</span>).
As an example, consider the following pair of sentences for the <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.4">NoHop</span> language shown in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px1" title="Setup. ‣ 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p2">
<span class="ltx_ERROR undefined" id="S4.SS3.SSS0.Px1.p2.1">\ex</span>
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p2.2">. 
<span class="ltx_ERROR undefined" id="S4.SS3.SSS0.Px1.p2.2.1">\a</span>. <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p2.2.2" style="font-size:83%;background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p2.2.3" style="font-size:83%;"> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.1" style="background-color:#FDE4CF;"> clean</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.2" style="background-color:#FF77E6;"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p2.2.3.2.1" style="border-color: #000000;padding:1.0pt;">S</span></span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.3" style="background-color:#FFCFD2;"> his</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.4" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.5" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.6" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.7" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.8" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.3.9" style="background-color:#B9FBC0;">.</span></span> 
.̱ *<span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p2.2.4" style="font-size:83%;background-color:#FDFD95;">He</span><span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p2.2.5" style="font-size:83%;"> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.5.1" style="background-color:#FDE4CF;"> clean</span><span class="ltx_text ltx_font_serif" id="S4.SS3.SSS0.Px1.p2.2.5.2">__<span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p2.2.5.2.1" style="background-color:#FFCFD2;"> his</span></span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.5.3" style="background-color:#F1C0E8;"> very</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.5.4" style="background-color:#CFBAF0;"> messy</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.5.5" style="background-color:#A3C4F3;"> books</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.5.6" style="background-color:#90DBF4;">he</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.5.7" style="background-color:#98F5E1;">lf</span> <span class="ltx_text" id="S4.SS3.SSS0.Px1.p2.2.5.8" style="background-color:#B9FBC0;">.</span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p3.1">Sentence&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px1" title="Setup. ‣ 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a> is an example in the <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p3.1.1">NoHop</span> language, and <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px1" title="Setup. ‣ 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a> is an ungrammatical counterfactual in which the marker token does not appear.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p4">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p4.1">In the first test, we compare the average surprisals of the marker tokens across the three <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p4.1.1">*Hop</span> languages, using grammatical examples like&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px1" title="Setup. ‣ 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>.
In the case of&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px1" title="Setup. ‣ 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>, the marker is singular, and its surprisal <math alttext="S(\texttt{\,\definecolor{hlcolor}{HTML}{FF77E6}\lx@texthl@color{\framebox{{S}}%
}\,})" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p4.1.m1.1"><semantics id="S4.SS3.SSS0.Px1.p4.1.m1.1a"><mrow id="S4.SS3.SSS0.Px1.p4.1.m1.1.2" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2.cmml"><mi id="S4.SS3.SSS0.Px1.p4.1.m1.1.2.2" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2.2.cmml">S</mi><mo id="S4.SS3.SSS0.Px1.p4.1.m1.1.2.1" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2.1.cmml">⁢</mo><mrow id="S4.SS3.SSS0.Px1.p4.1.m1.1.2.3.2" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1e.cmml"><mo id="S4.SS3.SSS0.Px1.p4.1.m1.1.2.3.2.1" stretchy="false" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1e.cmml">(</mo><mrow id="S4.SS3.SSS0.Px1.p4.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1e.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p4.1.m1.1.1a" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p4.1.m1.1.1b" style="padding:1.0pt" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1e.cmml"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p4.1.m1.1.1.2.1nest" style="border-color: #000000;padding:1.0pt;">S</span></mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p4.1.m1.1.1d" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1a.cmml">&nbsp;</mtext></mrow><mo id="S4.SS3.SSS0.Px1.p4.1.m1.1.2.3.2.2" stretchy="false" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1e.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p4.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p4.1.m1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2"><times id="S4.SS3.SSS0.Px1.p4.1.m1.1.2.1.cmml" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2.1"></times><ci id="S4.SS3.SSS0.Px1.p4.1.m1.1.2.2.cmml" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2.2">𝑆</ci><ci id="S4.SS3.SSS0.Px1.p4.1.m1.1.1e.cmml" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2.3.2"><mrow id="S4.SS3.SSS0.Px1.p4.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2.3.2"><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p4.1.m1.1.1a.cmml" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p4.1.m1.1.1b.cmml" style="padding:1.0pt" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.2.3.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p4.1.m1.1.1.2.1anest" style="border-color: #000000;padding:1.0pt;">S</span></mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p4.1.m1.1.1d.cmml" xref="S4.SS3.SSS0.Px1.p4.1.m1.1.1a">&nbsp;</mtext></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p4.1.m1.1c">S(\texttt{\,\definecolor{hlcolor}{HTML}{FF77E6}\lx@texthl@color{\framebox{{S}}%
}\,})</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p4.1.m1.1d">italic_S ( typewriter_S )</annotation></semantics></math> is defined as:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S(\texttt{\,\definecolor{hlcolor}{HTML}{FF77E6}\lx@texthl@color{\framebox{{S}}%
}\,})=-\log_{2}p(\texttt{\,\definecolor{hlcolor}{HTML}{FF77E6}\lx@texthl@color%
{\framebox{{S}}}\,$|$\,\definecolor{hlcolor}{HTML}{FDFD95}\lx@texthl@color{He}%
\,\definecolor{hlcolor}{HTML}{FDE4CF}\lx@texthl@color{ clean}\,})" class="ltx_Math" display="block" id="S4.Ex1.m1.2"><semantics id="S4.Ex1.m1.2a"><mrow id="S4.Ex1.m1.2.3" xref="S4.Ex1.m1.2.3.cmml"><mrow id="S4.Ex1.m1.2.3.2" xref="S4.Ex1.m1.2.3.2.cmml"><mi id="S4.Ex1.m1.2.3.2.2" xref="S4.Ex1.m1.2.3.2.2.cmml">S</mi><mo id="S4.Ex1.m1.2.3.2.1" xref="S4.Ex1.m1.2.3.2.1.cmml">⁢</mo><mrow id="S4.Ex1.m1.2.3.2.3.2" xref="S4.Ex1.m1.2.2e.cmml"><mo id="S4.Ex1.m1.2.3.2.3.2.1" stretchy="false" xref="S4.Ex1.m1.2.2e.cmml">(</mo><mrow id="S4.Ex1.m1.2.2" xref="S4.Ex1.m1.2.2e.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2a" xref="S4.Ex1.m1.2.2a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2b" style="padding:1.0pt" xref="S4.Ex1.m1.2.2e.cmml"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.Ex1.m1.2.2.2.1nest" style="border-color: #000000;padding:1.0pt;">S</span></mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2d" xref="S4.Ex1.m1.2.2a.cmml">&nbsp;</mtext></mrow><mo id="S4.Ex1.m1.2.3.2.3.2.2" stretchy="false" xref="S4.Ex1.m1.2.2e.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.2.3.1" xref="S4.Ex1.m1.2.3.1.cmml">=</mo><mrow id="S4.Ex1.m1.2.3.3" xref="S4.Ex1.m1.2.3.3.cmml"><mo id="S4.Ex1.m1.2.3.3a" rspace="0.167em" xref="S4.Ex1.m1.2.3.3.cmml">−</mo><mrow id="S4.Ex1.m1.2.3.3.2" xref="S4.Ex1.m1.2.3.3.2.cmml"><mrow id="S4.Ex1.m1.2.3.3.2.2" xref="S4.Ex1.m1.2.3.3.2.2.cmml"><msub id="S4.Ex1.m1.2.3.3.2.2.1" xref="S4.Ex1.m1.2.3.3.2.2.1.cmml"><mi id="S4.Ex1.m1.2.3.3.2.2.1.2" xref="S4.Ex1.m1.2.3.3.2.2.1.2.cmml">log</mi><mn id="S4.Ex1.m1.2.3.3.2.2.1.3" xref="S4.Ex1.m1.2.3.3.2.2.1.3.cmml">2</mn></msub><mo id="S4.Ex1.m1.2.3.3.2.2a" lspace="0.167em" xref="S4.Ex1.m1.2.3.3.2.2.cmml">⁡</mo><mi id="S4.Ex1.m1.2.3.3.2.2.2" xref="S4.Ex1.m1.2.3.3.2.2.2.cmml">p</mi></mrow><mo id="S4.Ex1.m1.2.3.3.2.1" xref="S4.Ex1.m1.2.3.3.2.1.cmml">⁢</mo><mrow id="S4.Ex1.m1.2.3.3.2.3.2" xref="S4.Ex1.m1.1.1.1j.cmml"><mo id="S4.Ex1.m1.2.3.3.2.3.2.1" stretchy="false" xref="S4.Ex1.m1.1.1.1j.cmml">(</mo><mrow id="S4.Ex1.m1.1.1.1" xref="S4.Ex1.m1.1.1.1j.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1a" xref="S4.Ex1.m1.1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1b" style="padding:1.0pt" xref="S4.Ex1.m1.1.1.1j.cmml"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.Ex1.m1.1.1.1.3.1nest" style="border-color: #000000;padding:1.0pt;">S</span></mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1d" xref="S4.Ex1.m1.1.1.1a.cmml">&nbsp;</mtext><mo fence="false" id="S4.Ex1.m1.1.1.1.m1.1.1" rspace="0.167em" stretchy="false" xref="S4.Ex1.m1.1.1.1.m1.1.1.cmml">|</mo><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1e" xref="S4.Ex1.m1.1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1f" xref="S4.Ex1.m1.1.1.1a.cmml">He</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1g" xref="S4.Ex1.m1.1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1h" xref="S4.Ex1.m1.1.1.1a.cmml">&nbsp;clean</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1i" xref="S4.Ex1.m1.1.1.1a.cmml">&nbsp;</mtext></mrow><mo id="S4.Ex1.m1.2.3.3.2.3.2.2" stretchy="false" xref="S4.Ex1.m1.1.1.1j.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.2b"><apply id="S4.Ex1.m1.2.3.cmml" xref="S4.Ex1.m1.2.3"><eq id="S4.Ex1.m1.2.3.1.cmml" xref="S4.Ex1.m1.2.3.1"></eq><apply id="S4.Ex1.m1.2.3.2.cmml" xref="S4.Ex1.m1.2.3.2"><times id="S4.Ex1.m1.2.3.2.1.cmml" xref="S4.Ex1.m1.2.3.2.1"></times><ci id="S4.Ex1.m1.2.3.2.2.cmml" xref="S4.Ex1.m1.2.3.2.2">𝑆</ci><ci id="S4.Ex1.m1.2.2e.cmml" xref="S4.Ex1.m1.2.3.2.3.2"><mrow id="S4.Ex1.m1.2.2.cmml" xref="S4.Ex1.m1.2.3.2.3.2"><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2a.cmml" xref="S4.Ex1.m1.2.2a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2b.cmml" style="padding:1.0pt" xref="S4.Ex1.m1.2.3.2.3.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.Ex1.m1.2.2.2.1anest" style="border-color: #000000;padding:1.0pt;">S</span></mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2d.cmml" xref="S4.Ex1.m1.2.2a">&nbsp;</mtext></mrow></ci></apply><apply id="S4.Ex1.m1.2.3.3.cmml" xref="S4.Ex1.m1.2.3.3"><minus id="S4.Ex1.m1.2.3.3.1.cmml" xref="S4.Ex1.m1.2.3.3"></minus><apply id="S4.Ex1.m1.2.3.3.2.cmml" xref="S4.Ex1.m1.2.3.3.2"><times id="S4.Ex1.m1.2.3.3.2.1.cmml" xref="S4.Ex1.m1.2.3.3.2.1"></times><apply id="S4.Ex1.m1.2.3.3.2.2.cmml" xref="S4.Ex1.m1.2.3.3.2.2"><apply id="S4.Ex1.m1.2.3.3.2.2.1.cmml" xref="S4.Ex1.m1.2.3.3.2.2.1"><csymbol cd="ambiguous" id="S4.Ex1.m1.2.3.3.2.2.1.1.cmml" xref="S4.Ex1.m1.2.3.3.2.2.1">subscript</csymbol><log id="S4.Ex1.m1.2.3.3.2.2.1.2.cmml" xref="S4.Ex1.m1.2.3.3.2.2.1.2"></log><cn id="S4.Ex1.m1.2.3.3.2.2.1.3.cmml" type="integer" xref="S4.Ex1.m1.2.3.3.2.2.1.3">2</cn></apply><ci id="S4.Ex1.m1.2.3.3.2.2.2.cmml" xref="S4.Ex1.m1.2.3.3.2.2.2">𝑝</ci></apply><ci id="S4.Ex1.m1.1.1.1j.cmml" xref="S4.Ex1.m1.2.3.3.2.3.2"><mrow id="S4.Ex1.m1.1.1.1.cmml" xref="S4.Ex1.m1.2.3.3.2.3.2"><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1a.cmml" xref="S4.Ex1.m1.1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1b.cmml" style="padding:1.0pt" xref="S4.Ex1.m1.2.3.3.2.3.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.Ex1.m1.1.1.1.3.1anest" style="border-color: #000000;padding:1.0pt;">S</span></mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1d.cmml" xref="S4.Ex1.m1.1.1.1a">&nbsp;</mtext><mo fence="false" id="S4.Ex1.m1.1.1.1.m1.1.1.cmml" stretchy="false" xref="S4.Ex1.m1.1.1.1.m1.1.1">|</mo><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1e.cmml" xref="S4.Ex1.m1.1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1f.cmml" xref="S4.Ex1.m1.1.1.1a">He</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1g.cmml" xref="S4.Ex1.m1.1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1h.cmml" xref="S4.Ex1.m1.1.1.1a">&nbsp;clean</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.1.1.1i.cmml" xref="S4.Ex1.m1.1.1.1a">&nbsp;</mtext></mrow></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.2c">S(\texttt{\,\definecolor{hlcolor}{HTML}{FF77E6}\lx@texthl@color{\framebox{{S}}%
}\,})=-\log_{2}p(\texttt{\,\definecolor{hlcolor}{HTML}{FF77E6}\lx@texthl@color%
{\framebox{{S}}}\,$|$\,\definecolor{hlcolor}{HTML}{FDFD95}\lx@texthl@color{He}%
\,\definecolor{hlcolor}{HTML}{FDE4CF}\lx@texthl@color{ clean}\,})</annotation><annotation encoding="application/x-llamapun" id="S4.Ex1.m1.2d">italic_S ( typewriter_S ) = - roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_p ( typewriter_S | typewriter_He typewriter_clean )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p4.2">We average this surprisal value for instances of <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p4.2.1" style="border-color: #000000;padding:1.0pt;">S</span> or <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p4.2.2" style="border-color: #000000;padding:1.0pt;">P</span> in the test sample.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p5">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p5.1">In the second test, we construct minimal pairs from the example sentences in which the marker token appears and does not appear, and then compare the surprisal of the marker token to the surprisal of the token that follows it, both conditioned on the same context.
In example&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS3.SSS0.Px1" title="Setup. ‣ 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>, the surprisal of the following token <math alttext="S(\texttt{\,\definecolor{hlcolor}{HTML}{FFCFD2}\lx@texthl@color{ his}\,})" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p5.1.m1.1"><semantics id="S4.SS3.SSS0.Px1.p5.1.m1.1a"><mrow id="S4.SS3.SSS0.Px1.p5.1.m1.1.2" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.2.cmml"><mi id="S4.SS3.SSS0.Px1.p5.1.m1.1.2.2" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.2.2.cmml">S</mi><mo id="S4.SS3.SSS0.Px1.p5.1.m1.1.2.1" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.2.1.cmml">⁢</mo><mrow id="S4.SS3.SSS0.Px1.p5.1.m1.1.2.3.2" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1d.cmml"><mo id="S4.SS3.SSS0.Px1.p5.1.m1.1.2.3.2.1" stretchy="false" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1d.cmml">(</mo><mrow id="S4.SS3.SSS0.Px1.p5.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1d.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.1.m1.1.1a" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.1.m1.1.1b" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1a.cmml">&nbsp;his</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.1.m1.1.1c" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1a.cmml">&nbsp;</mtext></mrow><mo id="S4.SS3.SSS0.Px1.p5.1.m1.1.2.3.2.2" stretchy="false" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1d.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p5.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p5.1.m1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.2"><times id="S4.SS3.SSS0.Px1.p5.1.m1.1.2.1.cmml" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.2.1"></times><ci id="S4.SS3.SSS0.Px1.p5.1.m1.1.2.2.cmml" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.2.2">𝑆</ci><ci id="S4.SS3.SSS0.Px1.p5.1.m1.1.1d.cmml" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.2.3.2"><mrow id="S4.SS3.SSS0.Px1.p5.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.2.3.2"><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.1.m1.1.1a.cmml" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.1.m1.1.1b.cmml" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1a">&nbsp;his</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.1.m1.1.1c.cmml" xref="S4.SS3.SSS0.Px1.p5.1.m1.1.1a">&nbsp;</mtext></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p5.1.m1.1c">S(\texttt{\,\definecolor{hlcolor}{HTML}{FFCFD2}\lx@texthl@color{ his}\,})</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p5.1.m1.1d">italic_S ( typewriter_his )</annotation></semantics></math> is defined as:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S(\texttt{\,\definecolor{hlcolor}{HTML}{FFCFD2}\lx@texthl@color{ his}\,})=-%
\log_{2}p(\texttt{\,\definecolor{hlcolor}{HTML}{FFCFD2}\lx@texthl@color{ his}%
\,$|$\,\definecolor{hlcolor}{HTML}{FDFD95}\lx@texthl@color{He}\,\definecolor{%
hlcolor}{HTML}{FDE4CF}\lx@texthl@color{ clean}\,})" class="ltx_Math" display="block" id="S4.Ex2.m1.2"><semantics id="S4.Ex2.m1.2a"><mrow id="S4.Ex2.m1.2.3" xref="S4.Ex2.m1.2.3.cmml"><mrow id="S4.Ex2.m1.2.3.2" xref="S4.Ex2.m1.2.3.2.cmml"><mi id="S4.Ex2.m1.2.3.2.2" xref="S4.Ex2.m1.2.3.2.2.cmml">S</mi><mo id="S4.Ex2.m1.2.3.2.1" xref="S4.Ex2.m1.2.3.2.1.cmml">⁢</mo><mrow id="S4.Ex2.m1.2.3.2.3.2" xref="S4.Ex2.m1.2.2d.cmml"><mo id="S4.Ex2.m1.2.3.2.3.2.1" stretchy="false" xref="S4.Ex2.m1.2.2d.cmml">(</mo><mrow id="S4.Ex2.m1.2.2" xref="S4.Ex2.m1.2.2d.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.2.2a" xref="S4.Ex2.m1.2.2a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.2.2b" xref="S4.Ex2.m1.2.2a.cmml">&nbsp;his</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.2.2c" xref="S4.Ex2.m1.2.2a.cmml">&nbsp;</mtext></mrow><mo id="S4.Ex2.m1.2.3.2.3.2.2" stretchy="false" xref="S4.Ex2.m1.2.2d.cmml">)</mo></mrow></mrow><mo id="S4.Ex2.m1.2.3.1" xref="S4.Ex2.m1.2.3.1.cmml">=</mo><mrow id="S4.Ex2.m1.2.3.3" xref="S4.Ex2.m1.2.3.3.cmml"><mo id="S4.Ex2.m1.2.3.3a" rspace="0.167em" xref="S4.Ex2.m1.2.3.3.cmml">−</mo><mrow id="S4.Ex2.m1.2.3.3.2" xref="S4.Ex2.m1.2.3.3.2.cmml"><mrow id="S4.Ex2.m1.2.3.3.2.2" xref="S4.Ex2.m1.2.3.3.2.2.cmml"><msub id="S4.Ex2.m1.2.3.3.2.2.1" xref="S4.Ex2.m1.2.3.3.2.2.1.cmml"><mi id="S4.Ex2.m1.2.3.3.2.2.1.2" xref="S4.Ex2.m1.2.3.3.2.2.1.2.cmml">log</mi><mn id="S4.Ex2.m1.2.3.3.2.2.1.3" xref="S4.Ex2.m1.2.3.3.2.2.1.3.cmml">2</mn></msub><mo id="S4.Ex2.m1.2.3.3.2.2a" lspace="0.167em" xref="S4.Ex2.m1.2.3.3.2.2.cmml">⁡</mo><mi id="S4.Ex2.m1.2.3.3.2.2.2" xref="S4.Ex2.m1.2.3.3.2.2.2.cmml">p</mi></mrow><mo id="S4.Ex2.m1.2.3.3.2.1" xref="S4.Ex2.m1.2.3.3.2.1.cmml">⁢</mo><mrow id="S4.Ex2.m1.2.3.3.2.3.2" xref="S4.Ex2.m1.1.1.1i.cmml"><mo id="S4.Ex2.m1.2.3.3.2.3.2.1" stretchy="false" xref="S4.Ex2.m1.1.1.1i.cmml">(</mo><mrow id="S4.Ex2.m1.1.1.1" xref="S4.Ex2.m1.1.1.1i.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1a" xref="S4.Ex2.m1.1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1b" xref="S4.Ex2.m1.1.1.1a.cmml">&nbsp;his</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1c" xref="S4.Ex2.m1.1.1.1a.cmml">&nbsp;</mtext><mo fence="false" id="S4.Ex2.m1.1.1.1.m1.1.1" rspace="0.167em" stretchy="false" xref="S4.Ex2.m1.1.1.1.m1.1.1.cmml">|</mo><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1d" xref="S4.Ex2.m1.1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1e" xref="S4.Ex2.m1.1.1.1a.cmml">He</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1f" xref="S4.Ex2.m1.1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1g" xref="S4.Ex2.m1.1.1.1a.cmml">&nbsp;clean</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1h" xref="S4.Ex2.m1.1.1.1a.cmml">&nbsp;</mtext></mrow><mo id="S4.Ex2.m1.2.3.3.2.3.2.2" stretchy="false" xref="S4.Ex2.m1.1.1.1i.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m1.2b"><apply id="S4.Ex2.m1.2.3.cmml" xref="S4.Ex2.m1.2.3"><eq id="S4.Ex2.m1.2.3.1.cmml" xref="S4.Ex2.m1.2.3.1"></eq><apply id="S4.Ex2.m1.2.3.2.cmml" xref="S4.Ex2.m1.2.3.2"><times id="S4.Ex2.m1.2.3.2.1.cmml" xref="S4.Ex2.m1.2.3.2.1"></times><ci id="S4.Ex2.m1.2.3.2.2.cmml" xref="S4.Ex2.m1.2.3.2.2">𝑆</ci><ci id="S4.Ex2.m1.2.2d.cmml" xref="S4.Ex2.m1.2.3.2.3.2"><mrow id="S4.Ex2.m1.2.2.cmml" xref="S4.Ex2.m1.2.3.2.3.2"><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.2.2a.cmml" xref="S4.Ex2.m1.2.2a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.2.2b.cmml" xref="S4.Ex2.m1.2.2a">&nbsp;his</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.2.2c.cmml" xref="S4.Ex2.m1.2.2a">&nbsp;</mtext></mrow></ci></apply><apply id="S4.Ex2.m1.2.3.3.cmml" xref="S4.Ex2.m1.2.3.3"><minus id="S4.Ex2.m1.2.3.3.1.cmml" xref="S4.Ex2.m1.2.3.3"></minus><apply id="S4.Ex2.m1.2.3.3.2.cmml" xref="S4.Ex2.m1.2.3.3.2"><times id="S4.Ex2.m1.2.3.3.2.1.cmml" xref="S4.Ex2.m1.2.3.3.2.1"></times><apply id="S4.Ex2.m1.2.3.3.2.2.cmml" xref="S4.Ex2.m1.2.3.3.2.2"><apply id="S4.Ex2.m1.2.3.3.2.2.1.cmml" xref="S4.Ex2.m1.2.3.3.2.2.1"><csymbol cd="ambiguous" id="S4.Ex2.m1.2.3.3.2.2.1.1.cmml" xref="S4.Ex2.m1.2.3.3.2.2.1">subscript</csymbol><log id="S4.Ex2.m1.2.3.3.2.2.1.2.cmml" xref="S4.Ex2.m1.2.3.3.2.2.1.2"></log><cn id="S4.Ex2.m1.2.3.3.2.2.1.3.cmml" type="integer" xref="S4.Ex2.m1.2.3.3.2.2.1.3">2</cn></apply><ci id="S4.Ex2.m1.2.3.3.2.2.2.cmml" xref="S4.Ex2.m1.2.3.3.2.2.2">𝑝</ci></apply><ci id="S4.Ex2.m1.1.1.1i.cmml" xref="S4.Ex2.m1.2.3.3.2.3.2"><mrow id="S4.Ex2.m1.1.1.1.cmml" xref="S4.Ex2.m1.2.3.3.2.3.2"><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1a.cmml" xref="S4.Ex2.m1.1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1b.cmml" xref="S4.Ex2.m1.1.1.1a">&nbsp;his</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1c.cmml" xref="S4.Ex2.m1.1.1.1a">&nbsp;</mtext><mo fence="false" id="S4.Ex2.m1.1.1.1.m1.1.1.cmml" stretchy="false" xref="S4.Ex2.m1.1.1.1.m1.1.1">|</mo><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1d.cmml" xref="S4.Ex2.m1.1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1e.cmml" xref="S4.Ex2.m1.1.1.1a">He</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1f.cmml" xref="S4.Ex2.m1.1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1g.cmml" xref="S4.Ex2.m1.1.1.1a">&nbsp;clean</mtext><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.1.1.1h.cmml" xref="S4.Ex2.m1.1.1.1a">&nbsp;</mtext></mrow></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m1.2c">S(\texttt{\,\definecolor{hlcolor}{HTML}{FFCFD2}\lx@texthl@color{ his}\,})=-%
\log_{2}p(\texttt{\,\definecolor{hlcolor}{HTML}{FFCFD2}\lx@texthl@color{ his}%
\,$|$\,\definecolor{hlcolor}{HTML}{FDFD95}\lx@texthl@color{He}\,\definecolor{%
hlcolor}{HTML}{FDE4CF}\lx@texthl@color{ clean}\,})</annotation><annotation encoding="application/x-llamapun" id="S4.Ex2.m1.2d">italic_S ( typewriter_his ) = - roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_p ( typewriter_his | typewriter_He typewriter_clean )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p5.2">We expect <math alttext="S(\texttt{\,\definecolor{hlcolor}{HTML}{FFCFD2}\lx@texthl@color{ his}\,})-S(%
\texttt{\,\definecolor{hlcolor}{HTML}{FF77E6}\lx@texthl@color{\framebox{{S}}}%
\,})" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p5.2.m1.2"><semantics id="S4.SS3.SSS0.Px1.p5.2.m1.2a"><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.2.3" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.cmml"><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.cmml"><mi id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.2" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.2.cmml">S</mi><mo id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.1" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.1.cmml">⁢</mo><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.3.2" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1d.cmml"><mo id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.3.2.1" stretchy="false" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1d.cmml">(</mo><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.1.1" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1d.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.1.1a" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.1.1b" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1a.cmml">&nbsp;his</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.1.1c" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1a.cmml">&nbsp;</mtext></mrow><mo id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.3.2.2" stretchy="false" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1d.cmml">)</mo></mrow></mrow><mo id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.1" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.1.cmml">−</mo><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.cmml"><mi id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.2" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.2.cmml">S</mi><mo id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.1" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.1.cmml">⁢</mo><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.3.2" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2e.cmml"><mo id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.3.2.1" stretchy="false" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2e.cmml">(</mo><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.2.2" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2e.cmml"><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.2.2a" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2a.cmml">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.2.2b" style="padding:1.0pt" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2e.cmml"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p5.2.m1.2.2.2.1nest" style="border-color: #000000;padding:1.0pt;">S</span></mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.2.2d" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2a.cmml">&nbsp;</mtext></mrow><mo id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.3.2.2" stretchy="false" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2e.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p5.2.m1.2b"><apply id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3"><minus id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.1.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.1"></minus><apply id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2"><times id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.1.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.1"></times><ci id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.2.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.2">𝑆</ci><ci id="S4.SS3.SSS0.Px1.p5.2.m1.1.1d.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.3.2"><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.2.3.2"><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.1.1a.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.1.1b.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1a">&nbsp;his</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.1.1c.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.1.1a">&nbsp;</mtext></mrow></ci></apply><apply id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3"><times id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.1.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.1"></times><ci id="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.2.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.2">𝑆</ci><ci id="S4.SS3.SSS0.Px1.p5.2.m1.2.2e.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.3.2"><mrow id="S4.SS3.SSS0.Px1.p5.2.m1.2.2.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.3.2"><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.2.2a.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2a">&nbsp;</mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.2.2b.cmml" style="padding:1.0pt" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.3.3.3.2"><span class="ltx_text ltx_framed ltx_framed_rectangle" id="S4.SS3.SSS0.Px1.p5.2.m1.2.2.2.1anest" style="border-color: #000000;padding:1.0pt;">S</span></mtext><mtext class="ltx_mathvariant_monospace" id="S4.SS3.SSS0.Px1.p5.2.m1.2.2d.cmml" xref="S4.SS3.SSS0.Px1.p5.2.m1.2.2a">&nbsp;</mtext></mrow></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p5.2.m1.2c">S(\texttt{\,\definecolor{hlcolor}{HTML}{FFCFD2}\lx@texthl@color{ his}\,})-S(%
\texttt{\,\definecolor{hlcolor}{HTML}{FF77E6}\lx@texthl@color{\framebox{{S}}}%
\,})</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p5.2.m1.2d">italic_S ( typewriter_his ) - italic_S ( typewriter_S )</annotation></semantics></math>
to be a large positive value.
We average such surprisal differences over instances of the marker tokens in the test sample and similarly define marker surprisals and minimal pair configurations for the other <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p5.2.1">*Hop</span> languages.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Hypothesis.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.1">For the first surprisal test, our hypothesis is that the mean surprisal of the marker tokens across test examples will be smaller for the control language than for the impossible languages.
For the second test, our hypothesis is that the mean surprisal difference across all test pairs will be larger for possible languages than for impossible ones.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p1.1">Our results are presented in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.F3" title="In 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>. The <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p1.1.1">NoHop</span> model, which has the verb marking pattern most similar to English, consistently has the lowest mean marker surprisal across training steps in test 1 (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.F3.sf1" title="In Figure 3 ‣ 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3(a)</span></a>). The <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p1.1.2">NoHop</span> model also has the highest mean surprisal difference across training steps in test 2 (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.F3.sf2" title="In Figure 3 ‣ 4.3 Experiment 2: Language Models Disprefer Counting Rules ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3(b)</span></a>). Both of these results indicate that GPT-2 has learned to expect the marker tokens when they follow a more natural grammatical pattern and was very surprised when they did not appear at the correct positions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p2.1">GPT-2 learns to expect marker tokens at the right locations in the other <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p2.1.1">*Hop</span> models, just not as well as the control. <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p2.1.2">TokenHop</span> tends to have a lower marker surprisal and a higher mean surprisal difference compared to <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p2.1.3">WordHop</span> across training steps, indicating that GPT-2 is better at learning the verb marking rule when the units being counted are tokens instead of words.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Experiment 3: Language Models Develop Natural Solutions to Unnatural Patterns</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.7">Experiment 2 demonstrates that, while GPT-2 favors natural grammar rules, it is also capable of acquiring count-based grammar rules like those seen in the verb marking patterns of our <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.p1.7.1">*Hop</span> languages. But what sorts of internal mechanisms does it implement to learn such grammar rules, and how do these mechanisms compare to the more natural control? To address this, we conduct a final experiment using <em class="ltx_emph ltx_font_italic" id="S4.SS4.p1.7.2">causal abstraction analysis</em>, which offers an interpretability framework for identifying and examining causal mechanisms within neural models <cite class="ltx_cite ltx_citemacro_cite">Geiger et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib23" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib22" title="">2021</a>); Wu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib69" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib67" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib68" title="">2023b</a>); Geiger et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib24" title="">2023</a>)</cite>. We employ the <em class="ltx_emph ltx_font_italic" id="S4.SS4.p1.7.3">interchange intervention</em> technique on our <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.p1.7.4">*Hop</span> models. To perform a basic interchange intervention on a neural model <math alttext="M" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mi id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">italic_M</annotation></semantics></math>, we create two instances of <math alttext="M" class="ltx_Math" display="inline" id="S4.SS4.p1.2.m2.1"><semantics id="S4.SS4.p1.2.m2.1a"><mi id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.2.m2.1d">italic_M</annotation></semantics></math> that are provided two different inputs, the base input <math alttext="b" class="ltx_Math" display="inline" id="S4.SS4.p1.3.m3.1"><semantics id="S4.SS4.p1.3.m3.1a"><mi id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><ci id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.3.m3.1d">italic_b</annotation></semantics></math> and the source input&nbsp;<math alttext="s" class="ltx_Math" display="inline" id="S4.SS4.p1.4.m4.1"><semantics id="S4.SS4.p1.4.m4.1a"><mi id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><ci id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">s</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.4.m4.1d">italic_s</annotation></semantics></math>. Then, we interchange representations created while processing&nbsp;<math alttext="b" class="ltx_Math" display="inline" id="S4.SS4.p1.5.m5.1"><semantics id="S4.SS4.p1.5.m5.1a"><mi id="S4.SS4.p1.5.m5.1.1" xref="S4.SS4.p1.5.m5.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><ci id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.5.m5.1d">italic_b</annotation></semantics></math> with representations created while processing&nbsp;<math alttext="s" class="ltx_Math" display="inline" id="S4.SS4.p1.6.m6.1"><semantics id="S4.SS4.p1.6.m6.1a"><mi id="S4.SS4.p1.6.m6.1.1" xref="S4.SS4.p1.6.m6.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.6.m6.1b"><ci id="S4.SS4.p1.6.m6.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.6.m6.1c">s</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.6.m6.1d">italic_s</annotation></semantics></math> and observe the effect on the output of&nbsp;<math alttext="M" class="ltx_Math" display="inline" id="S4.SS4.p1.7.m7.1"><semantics id="S4.SS4.p1.7.m7.1a"><mi id="S4.SS4.p1.7.m7.1.1" xref="S4.SS4.p1.7.m7.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.7.m7.1b"><ci id="S4.SS4.p1.7.m7.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.7.m7.1c">M</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.7.m7.1d">italic_M</annotation></semantics></math>. Such interventions allow us to piece together a causal understanding of how the model processes inputs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setup.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="317" id="S4.F4.g1" src="./Mission_ Impossible Language Models_files/x5.png" width="332">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An <em class="ltx_emph ltx_font_italic" id="S4.F4.9.1">interchange intervention</em> on the <span class="ltx_text ltx_font_smallcaps" id="S4.F4.10.2">NoHop</span> model with base input <math alttext="b=\texttt{The man be}" class="ltx_Math" display="inline" id="S4.F4.3.m1.1"><semantics id="S4.F4.3.m1.1b"><mrow id="S4.F4.3.m1.1.1" xref="S4.F4.3.m1.1.1.cmml"><mi id="S4.F4.3.m1.1.1.2" xref="S4.F4.3.m1.1.1.2.cmml">b</mi><mo id="S4.F4.3.m1.1.1.1" xref="S4.F4.3.m1.1.1.1.cmml">=</mo><mtext class="ltx_mathvariant_monospace" id="S4.F4.3.m1.1.1.3" xref="S4.F4.3.m1.1.1.3a.cmml">The man be</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.3.m1.1c"><apply id="S4.F4.3.m1.1.1.cmml" xref="S4.F4.3.m1.1.1"><eq id="S4.F4.3.m1.1.1.1.cmml" xref="S4.F4.3.m1.1.1.1"></eq><ci id="S4.F4.3.m1.1.1.2.cmml" xref="S4.F4.3.m1.1.1.2">𝑏</ci><ci id="S4.F4.3.m1.1.1.3a.cmml" xref="S4.F4.3.m1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S4.F4.3.m1.1.1.3.cmml" xref="S4.F4.3.m1.1.1.3">The man be</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.3.m1.1d">b=\texttt{The man be}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.3.m1.1e">italic_b = The man be</annotation></semantics></math> and source input <math alttext="s=\texttt{The men be}" class="ltx_Math" display="inline" id="S4.F4.4.m2.1"><semantics id="S4.F4.4.m2.1b"><mrow id="S4.F4.4.m2.1.1" xref="S4.F4.4.m2.1.1.cmml"><mi id="S4.F4.4.m2.1.1.2" xref="S4.F4.4.m2.1.1.2.cmml">s</mi><mo id="S4.F4.4.m2.1.1.1" xref="S4.F4.4.m2.1.1.1.cmml">=</mo><mtext class="ltx_mathvariant_monospace" id="S4.F4.4.m2.1.1.3" xref="S4.F4.4.m2.1.1.3a.cmml">The men be</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.4.m2.1c"><apply id="S4.F4.4.m2.1.1.cmml" xref="S4.F4.4.m2.1.1"><eq id="S4.F4.4.m2.1.1.1.cmml" xref="S4.F4.4.m2.1.1.1"></eq><ci id="S4.F4.4.m2.1.1.2.cmml" xref="S4.F4.4.m2.1.1.2">𝑠</ci><ci id="S4.F4.4.m2.1.1.3a.cmml" xref="S4.F4.4.m2.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S4.F4.4.m2.1.1.3.cmml" xref="S4.F4.4.m2.1.1.3">The men be</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.m2.1d">s=\texttt{The men be}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.4.m2.1e">italic_s = The men be</annotation></semantics></math>. The intervention is performed at the second layer and second token position, causing a change in prediction from <span class="ltx_text" id="S4.F4.11.3" style="background-color:#FF77E6;"><span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.F4.11.3.1" style="border-color: #000000;padding:1.0pt;">S</span></span> to <span class="ltx_text" id="S4.F4.12.4" style="background-color:#3EC8FF;"><span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.F4.12.4.1" style="border-color: #000000;padding:1.0pt;">P</span></span>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="208" id="S4.F5.g1" src="./Mission_ Impossible Language Models_files/x6.png" width="273"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="208" id="S4.F5.g2" src="./Mission_ Impossible Language Models_files/x7.png" width="273"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="208" id="S4.F5.g3" src="./Mission_ Impossible Language Models_files/x8.png" width="273"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Subject–verb agreement interchange intervention accuracies (IIA) for each
<span class="ltx_text ltx_font_smallcaps" id="S4.F5.12.1">*Hop</span> model over training steps. Vertical axes denote the GPT-2 layer of the intervention, and horizontal axes denote the token position of the intervention. <math alttext="t_{d}" class="ltx_Math" display="inline" id="S4.F5.5.m1.1"><semantics id="S4.F5.5.m1.1b"><msub id="S4.F5.5.m1.1.1" xref="S4.F5.5.m1.1.1.cmml"><mi id="S4.F5.5.m1.1.1.2" xref="S4.F5.5.m1.1.1.2.cmml">t</mi><mi id="S4.F5.5.m1.1.1.3" xref="S4.F5.5.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F5.5.m1.1c"><apply id="S4.F5.5.m1.1.1.cmml" xref="S4.F5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.F5.5.m1.1.1.1.cmml" xref="S4.F5.5.m1.1.1">subscript</csymbol><ci id="S4.F5.5.m1.1.1.2.cmml" xref="S4.F5.5.m1.1.1.2">𝑡</ci><ci id="S4.F5.5.m1.1.1.3.cmml" xref="S4.F5.5.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.5.m1.1d">t_{d}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.5.m1.1e">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="t_{s}" class="ltx_Math" display="inline" id="S4.F5.6.m2.1"><semantics id="S4.F5.6.m2.1b"><msub id="S4.F5.6.m2.1.1" xref="S4.F5.6.m2.1.1.cmml"><mi id="S4.F5.6.m2.1.1.2" xref="S4.F5.6.m2.1.1.2.cmml">t</mi><mi id="S4.F5.6.m2.1.1.3" xref="S4.F5.6.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F5.6.m2.1c"><apply id="S4.F5.6.m2.1.1.cmml" xref="S4.F5.6.m2.1.1"><csymbol cd="ambiguous" id="S4.F5.6.m2.1.1.1.cmml" xref="S4.F5.6.m2.1.1">subscript</csymbol><ci id="S4.F5.6.m2.1.1.2.cmml" xref="S4.F5.6.m2.1.1.2">𝑡</ci><ci id="S4.F5.6.m2.1.1.3.cmml" xref="S4.F5.6.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.6.m2.1d">t_{s}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.6.m2.1e">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="t_{v}" class="ltx_Math" display="inline" id="S4.F5.7.m3.1"><semantics id="S4.F5.7.m3.1b"><msub id="S4.F5.7.m3.1.1" xref="S4.F5.7.m3.1.1.cmml"><mi id="S4.F5.7.m3.1.1.2" xref="S4.F5.7.m3.1.1.2.cmml">t</mi><mi id="S4.F5.7.m3.1.1.3" xref="S4.F5.7.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F5.7.m3.1c"><apply id="S4.F5.7.m3.1.1.cmml" xref="S4.F5.7.m3.1.1"><csymbol cd="ambiguous" id="S4.F5.7.m3.1.1.1.cmml" xref="S4.F5.7.m3.1.1">subscript</csymbol><ci id="S4.F5.7.m3.1.1.2.cmml" xref="S4.F5.7.m3.1.1.2">𝑡</ci><ci id="S4.F5.7.m3.1.1.3.cmml" xref="S4.F5.7.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.7.m3.1d">t_{v}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.7.m3.1e">italic_t start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> represent the tokens for the determiner, subject, and verb, respectively. <math alttext="t_{1}\dots t_{4}" class="ltx_Math" display="inline" id="S4.F5.8.m4.1"><semantics id="S4.F5.8.m4.1b"><mrow id="S4.F5.8.m4.1.1" xref="S4.F5.8.m4.1.1.cmml"><msub id="S4.F5.8.m4.1.1.2" xref="S4.F5.8.m4.1.1.2.cmml"><mi id="S4.F5.8.m4.1.1.2.2" xref="S4.F5.8.m4.1.1.2.2.cmml">t</mi><mn id="S4.F5.8.m4.1.1.2.3" xref="S4.F5.8.m4.1.1.2.3.cmml">1</mn></msub><mo id="S4.F5.8.m4.1.1.1" xref="S4.F5.8.m4.1.1.1.cmml">⁢</mo><mi id="S4.F5.8.m4.1.1.3" mathvariant="normal" xref="S4.F5.8.m4.1.1.3.cmml">…</mi><mo id="S4.F5.8.m4.1.1.1b" xref="S4.F5.8.m4.1.1.1.cmml">⁢</mo><msub id="S4.F5.8.m4.1.1.4" xref="S4.F5.8.m4.1.1.4.cmml"><mi id="S4.F5.8.m4.1.1.4.2" xref="S4.F5.8.m4.1.1.4.2.cmml">t</mi><mn id="S4.F5.8.m4.1.1.4.3" xref="S4.F5.8.m4.1.1.4.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.8.m4.1c"><apply id="S4.F5.8.m4.1.1.cmml" xref="S4.F5.8.m4.1.1"><times id="S4.F5.8.m4.1.1.1.cmml" xref="S4.F5.8.m4.1.1.1"></times><apply id="S4.F5.8.m4.1.1.2.cmml" xref="S4.F5.8.m4.1.1.2"><csymbol cd="ambiguous" id="S4.F5.8.m4.1.1.2.1.cmml" xref="S4.F5.8.m4.1.1.2">subscript</csymbol><ci id="S4.F5.8.m4.1.1.2.2.cmml" xref="S4.F5.8.m4.1.1.2.2">𝑡</ci><cn id="S4.F5.8.m4.1.1.2.3.cmml" type="integer" xref="S4.F5.8.m4.1.1.2.3">1</cn></apply><ci id="S4.F5.8.m4.1.1.3.cmml" xref="S4.F5.8.m4.1.1.3">…</ci><apply id="S4.F5.8.m4.1.1.4.cmml" xref="S4.F5.8.m4.1.1.4"><csymbol cd="ambiguous" id="S4.F5.8.m4.1.1.4.1.cmml" xref="S4.F5.8.m4.1.1.4">subscript</csymbol><ci id="S4.F5.8.m4.1.1.4.2.cmml" xref="S4.F5.8.m4.1.1.4.2">𝑡</ci><cn id="S4.F5.8.m4.1.1.4.3.cmml" type="integer" xref="S4.F5.8.m4.1.1.4.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.8.m4.1d">t_{1}\dots t_{4}</annotation><annotation encoding="application/x-llamapun" id="S4.F5.8.m4.1e">italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT … italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT</annotation></semantics></math> represent the four tokens/words between the verb and its marker for <span class="ltx_text ltx_font_smallcaps" id="S4.F5.13.2">TokenHop</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.F5.14.3">WordHop</span>.
IIA values are averaged over results from 5 models initialized on different random seeds. See <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6" title="Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">F</span></a> for confidence intervals.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.4">We use interchange interventions to identify representations in our <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px1.p1.4.1">*Hop</span> models
that have causal effects on their output behaviors on a subject–verb agreement task. In
our experimental setup, <math alttext="b" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS4.SSS0.Px1.p1.1.m1.1a"><mi id="S4.SS4.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px1.p1.1.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS4.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px1.p1.1.m1.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px1.p1.1.m1.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS0.Px1.p1.1.m1.1d">italic_b</annotation></semantics></math> is a sentence prefix with a singular subject and <math alttext="s" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px1.p1.2.m2.1"><semantics id="S4.SS4.SSS0.Px1.p1.2.m2.1a"><mi id="S4.SS4.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS4.SSS0.Px1.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px1.p1.2.m2.1b"><ci id="S4.SS4.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS4.SSS0.Px1.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px1.p1.2.m2.1c">s</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS0.Px1.p1.2.m2.1d">italic_s</annotation></semantics></math> is
an identical prefix with the plural form of the subject. These prefixes include all
tokens up to but not including the markers (<span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS4.SSS0.Px1.p1.4.2" style="border-color: #000000;padding:1.0pt;">S</span> and <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS4.SSS0.Px1.p1.4.3" style="border-color: #000000;padding:1.0pt;">P</span>).
We interchange the GPT-2 block outputs from processing&nbsp;<math alttext="b" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px1.p1.3.m3.1"><semantics id="S4.SS4.SSS0.Px1.p1.3.m3.1a"><mi id="S4.SS4.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS4.SSS0.Px1.p1.3.m3.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px1.p1.3.m3.1b"><ci id="S4.SS4.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS4.SSS0.Px1.p1.3.m3.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px1.p1.3.m3.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS0.Px1.p1.3.m3.1d">italic_b</annotation></semantics></math> with GPT-2 block outputs
from processing&nbsp;<math alttext="s" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px1.p1.4.m4.1"><semantics id="S4.SS4.SSS0.Px1.p1.4.m4.1a"><mi id="S4.SS4.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS4.SSS0.Px1.p1.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px1.p1.4.m4.1b"><ci id="S4.SS4.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS4.SSS0.Px1.p1.4.m4.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px1.p1.4.m4.1c">s</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.SSS0.Px1.p1.4.m4.1d">italic_s</annotation></semantics></math> and observe whether the probability of plural marker&nbsp;<span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS4.SSS0.Px1.p1.4.4" style="border-color: #000000;padding:1.0pt;">P</span> is higher than the probability
of singular marker&nbsp;<span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="S4.SS4.SSS0.Px1.p1.4.5" style="border-color: #000000;padding:1.0pt;">S</span> after the intervention. This is
shown more concretely in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.F4" title="In Setup. ‣ 4.4 Experiment 3: Language Models Develop Natural Solutions to Unnatural Patterns ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p2.1">We run such interventions at each GPT-2 layer and token position to see which
parts of the model cause a change in the marker prediction. We run all of these
interventions over several test examples and report the <em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS0.Px1.p2.1.1">interchange intervention
accuracy</em> (IIA), a metric that represents the subject–verb agreement accuracy if the
counterfactual (i.e.&nbsp;plural) were the ground truth. The test examples for each <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px1.p2.1.2">*Hop</span> model are extracted from their respective versions of the BabyLM test set, and minimally-different counterfactual examples are created by changing the singular subjects to plural subjects.
To ensure that interventions on different examples are analogous, we use regular expressions to locate examples that follow the same structure (i.e.&nbsp;subjects and verbs at the same positions).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px2.p1.1">Our results are presented in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.F5" title="In Setup. ‣ 4.4 Experiment 3: Language Models Develop Natural Solutions to Unnatural Patterns ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>. The IIA graphs
demonstrate how information about the marker tokens flows through the models.
We can see that, in all three <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.1.1">*Hop</span> models, IIA is high at the token position
of the subject up until about layer 3; then there is a transition to the position of
the last token in the prefix, preceding the location where the marker should be predicted.
All models develop the same modular solution to the task by tracking
agreement through the representations at the relevant positions, but the
<span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.1.2">NoHop</span> model obtains nearly 100% IIA earlier during training, at about
1,500 training steps, supporting the previous surprisal results.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Contra claims by Chomsky and others that LLMs cannot possibly inform our understanding of human language, we argue there is great value in treating LLMs as a comparative system for human language and in understanding what systems like LLMs can and cannot learn.
Prior explorations of neural language models have already been fruitful for understanding the generalization of syntactic principles from data <cite class="ltx_cite ltx_citemacro_cite">Wilcox et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib65" title="">2018</a>); Marvin and Linzen (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib43" title="">2018</a>); Futrell et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib20" title="">2019</a>); Prasad et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib54" title="">2019</a>); Hu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib34" title="">2020</a>)</cite>. Our paper complements this line of work.
We have shown that GPT-2 models do not master our set of synthetic impossible languages as well as natural ones, challenging the unfounded assertions stated previously.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Even in the absence of a clear definition of what constitutes a possible or impossible language, we believe that our investigations advance this debate regarding LLMs. The lack of a definition does not hinder inquiry into this topic; in fact, it beckons further explorations of the boundary between the possible and impossible languages, as shown in our hypothesized continuum in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S1.F1" title="In 1 Introduction ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>. We believe that the <span class="ltx_text ltx_font_smallcaps" id="S5.p2.1.1">*Hop</span> languages we propose closely approach this boundary.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">At the same time, conclusions about LLMs’ linguistic competence and preferences for natural languages should be informed by an understanding of the ways that models fundamentally differ from humans. For instance, we saw that models can perform operations that involve counting tokens because LLMs rely on tokens as basic units. While humans are sensitive to morpheme boundaries and word boundaries, it is unlikely humans rely on atomic tokens in the way that LLMs do.
This does not mean that LLMs can fundamentally tell us nothing about human language.
Rather, as we did here, it is valuable to consider and control for this difference before making generalizations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">Since at least the 1950s, a major line of linguistic inquiry has focused on what aspects of syntactic structure can be learned just from data, without domain-specific innate priors (e.g.&nbsp;a <em class="ltx_emph ltx_font_italic" id="S5.p4.1.1">Universal Grammar</em>).
LLMs lack strong in-built linguistic priors, yet they can learn complex syntactic structures.
While many LLMs are trained with vastly more data than children see, there is increasing evidence that even systems trained on smaller amounts of data can learn interesting linguistic information <cite class="ltx_cite ltx_citemacro_citep">(Warstadt et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib63" title="">2023</a>)</cite>.
The current paper raises further questions along similar lines. Since we do find that real languages are more learnable by GPT-2, this leads us to wonder what inductive bias of GPT language models matches natural language.
We believe that this inductive bias is related to information locality, the tendency for statistical correlations in text to be short range.
Information locality arises in GPTs due to their autoregressive training objective and has been argued to arise in humans due to the incremental nature of real-time language processing <cite class="ltx_cite ltx_citemacro_citep">(Futrell, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib18" title="">2019</a>; Hahn et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib27" title="">2021</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">Since LLMs have been shown to learn the complex structures of human language and have a preference for learning such structures over unnatural counterfactuals, it follows that they are clearly relevant to investigations and claims about the necessary innate priors for language learning.
Arguments that they are “by design, unlimited in what they can ‘learn”’ and “incapable of distinguishing the possible from the impossible” <cite class="ltx_cite ltx_citemacro_citep">(Chomsky et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib10" title="">2023</a>)</cite> do not offer convincing evidence otherwise.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The authors would like to thank Aryaman Arora, Christiane Fellbaum, Roger Levy, Tristan Thrush, and Diyi Yang for helpful comments on the project. We would also like to thank the members of the Stanford NLP Group, the MIT Computational Psycholinguistics Lab, and the anonymous reviewers for useful discussions. Julie Kallini is supported by a National Science Foundation Graduate Research Fellowship under grant number DGE-2146755.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Due to resource constraints, we exclusively use the GPT-2 architecture to train models on our various synthetic impossible languages. Each of our experiments involves training a GPT-2 model from scratch on a different language dataset, and for every such language, we train multiple GPT-2 models to establish confidence intervals for our evaluation metrics. Applying this approach to several different model architectures would be quite resource-intensive, so we opted to choose a single architecture in this paper. Future work could apply our methodology to models trained with different architectures or training objectives.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Our impossible languages are derived by manipulating an English dataset. While we do not conduct experiments that use other natural languages as a starting point, our experimental choices (i.e.&nbsp;the synthetic languages we design) are informed by linguistic diversity and typology, distinguishing our impossible languages from those that are rare but attested. However, future work might involve deriving impossible languages from base languages other than English and include more morphological manipulations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Ethics Statement</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">While this work makes the case for language models as useful tools for cognitive science and linguistics research, these models learn and generate language through processes that are fundamentally different from those employed by humans. Making direct claims about human language learning based on the results of this paper could pose potential risks and harms. This research merely aims to explore the learnability of different languages (specifically, those languages that <em class="ltx_emph ltx_font_italic" id="S8.p1.1.1">cannot</em> be acquired by humans and are not representative of any known human language) through the lens of neural models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdou et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mostafa Abdou, Vinit Ravishankar, Artur Kulmizev, and Anders Søgaard. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.476" title="">Word order does matter and shuffled language models know it</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 6907–6919, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alleman et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Matteo Alleman, Jonathan Mamou, Miguel A&nbsp;Del&nbsp;Rio, Hanlin Tang, Yoon Kim, and SueYeon Chung. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.repl4nlp-1.27" title="">Syntactic perturbations reveal representational correlates of hierarchical phrase structure in pretrained language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</em>, pages 263–276, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bolhuis et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Johan&nbsp;J. Bolhuis, Stephen Crain, Sandiway Fong, and Andrea Moro. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1038/d41586-024-00824-z" title="">Three reasons why AI doesn’t model human language</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Nature</em>, 627(8004):489–489.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chomsky (1956)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam Chomsky. 1956.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/TIT.1956.1056813" title="">Three models for the description of language</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">IRE Transactions on Information Theory</em>, 2(3):113–124.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chomsky (1957)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam Chomsky. 1957.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/doi:10.1515/9783112316009" title=""><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1.1">Syntactic Structures</em></a>.

</span>
<span class="ltx_bibblock">De Gruyter Mouton, Berlin, Boston.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chomsky (1959)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam Chomsky. 1959.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/S0019-9958(59)90362-6" title="">On certain formal properties of grammars</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Information and Control</em>, 2(2):137–167.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chomsky (1965)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam Chomsky. 1965.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Aspects of the Theory of Syntax</em>.

</span>
<span class="ltx_bibblock">The MIT Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chomsky (2002)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam Chomsky. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1017/CBO9780511613876" title=""><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1.1">On Nature and Language</em></a>.

</span>
<span class="ltx_bibblock">Cambridge University Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chomsky (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam Chomsky. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://conversationswithtyler.com/episodes/noam-chomsky/" title="">Conversations with Tyler: Noam Chomsky</a>.

</span>
<span class="ltx_bibblock">Conversations with Tyler Podcast.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chomsky et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam Chomsky, Ian Roberts, and Jeffrey Watumull. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html" title="">Noam Chomsky: The false promise of ChatGPT</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">The New York Times</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Comrie (1989)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bernard Comrie. 1989.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Language universals and linguistic typology: Syntax and morphology</em>.

</span>
<span class="ltx_bibblock">University of Chicago press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deletang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gregoire Deletang, Anian Ruoss, Jordi Grau-Moya, Tim Genewein, Li&nbsp;Kevin Wenliang, Elliot Catt, Chris Cundy, Marcus Hutter, Shane Legg, Joel Veness, and Pedro&nbsp;A Ortega. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=WbxHAzkeQcn" title="">Neural networks and the Chomsky hierarchy</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1423" title="">BERT: Pre-training of deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ebrahimi et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Javid Ebrahimi, Dhruv Gelda, and Wei Zhang. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.findings-emnlp.384" title="">How can self-attention networks recognize Dyck-n languages?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Findings of the Association for Computational Linguistics: EMNLP 2020</em>, pages 4301–4306, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elman (1990)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jeffrey&nbsp;L. Elman. 1990.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/0364-0213(90)90002-E" title="">Finding structure in time</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Cognitive Science</em>, 14(2):179–211.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Evans and Levinson (2009)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nicholas Evans and Stephen&nbsp;C Levinson. 2009.

</span>
<span class="ltx_bibblock">The myth of language universals: Language diversity and its importance for cognitive science.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Behavioral and brain sciences</em>, 32(5):429–448.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Everett (2012)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daniel&nbsp;L. Everett. 2012.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1002/wcs.1195" title="">What does Pirahã grammar have to teach us about human language and the mind?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">WIREs Cognitive Science</em>, 3(6):555–563.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Futrell (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Richard Futrell. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W19-7902" title="">Information-theoretic locality properties of natural language</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the First Workshop on Quantitative Syntax (Quasy, SyntaxFest 2019)</em>, pages 2–15, Paris, France. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Futrell and Hahn (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Richard Futrell and Michael Hahn. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3389/fcomm.2022.657725" title="">Information theory as a bridge between language function and language form</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Frontiers in Communication</em>, 7.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Futrell et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Richard Futrell, Ethan Wilcox, Takashi Morita, Peng Qian, Miguel Ballesteros, and Roger Levy. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1004" title="">Neural language models as psycholinguistic subjects: Representations of syntactic state</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 32–42, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Galke et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lukas Galke, Yoav Ram, and Limor Raviv. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2302.12239" title="">What makes a language easy to deep-learn?</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiger et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Atticus Geiger, Hanson Lu, Thomas Icard, and Christopher Potts. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2021/file/4f5c422f4d49a5a807eda27434231040-Paper.pdf" title="">Causal abstractions of neural networks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Advances in Neural Information Processing Systems</em>, volume&nbsp;34, pages 9574–9586. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiger et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Atticus Geiger, Kyle Richardson, and Christopher Potts. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.blackboxnlp-1.16" title="">Neural natural language inference models partially embed theories of lexical entailment and negation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</em>, pages 163–173, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiger et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Atticus Geiger, Zhengxuan Wu, Christopher Potts, Thomas Icard, and Noah&nbsp;D. Goodman. 2023.

</span>
<span class="ltx_bibblock">Finding alignments between interpretable causal variables and distributed neural representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of Causal Learning and Reasoning 2024.</em>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Greenberg (1963)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joseph Greenberg. 1963.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1002/wcs.1195" title="">Some universals of grammar with particular reference to the order of meaningful elements</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Universals of Language</em>, pages 73–113.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hahn (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michael Hahn. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00306" title="">Theoretical limitations of self-attention in neural sequence models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Transactions of the Association for Computational Linguistics</em>, 8:156–171.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hahn et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michael Hahn, Judith Degen, and Richard Futrell. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1037/rev0000269" title="">Modeling word and morpheme order in natural language as an efficient trade-off of memory and surprisal.</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Psychological Review</em>, 128(4):726–756.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hahn et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michael Hahn, Dan Jurafsky, and Richard Futrell. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1073/pnas.1910923117" title="">Universals of word order reflect optimization of grammars for efficient communication</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the National Academy of Sciences</em>, 117(5):2347–2353.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hale (2001)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John Hale. 2001.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/N01-1021" title="">A probabilistic Earley parser as a psycholinguistic model</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Second Meeting of the North American Chapter of the Association for Computational Linguistics</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiding Hao, William Merrill, Dana Angluin, Robert Frank, Noah Amsel, Andrew Benz, and Simon Mendelsohn. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W18-5433" title="">Context-free transductions with neural stacks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</em>, pages 306–315, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hauser et&nbsp;al. (2002)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Marc&nbsp;D. Hauser, Noam Chomsky, and W.&nbsp;Tecumseh Fitch. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1126/science.298.5598.1569" title="">The faculty of language: What is it, who has it, and how did it evolve?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Science</em>, 298(5598):1569–1579.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hessel and Schofield (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jack Hessel and Alexandra Schofield. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-short.27" title="">How effective is BERT without word ordering? implications for language understanding and data privacy</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</em>, pages 204–211, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hewitt et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John Hewitt, Michael Hahn, Surya Ganguli, Percy Liang, and Christopher&nbsp;D. Manning. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.156" title="">RNNs can generate bounded hierarchical languages with optimal memory</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 1978–2010, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jennifer Hu, Jon Gauthier, Peng Qian, Ethan Wilcox, and Roger Levy. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.158" title="">A systematic assessment of syntactic generalization in neural language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 1725–1744, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qian Huang, Eric Zelikman, Sarah&nbsp;Li Chen, Yuhuai Wu, Gregory Valiant, and Percy Liang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.16349" title="">Lexinvariant language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lifeng Jin, Finale Doshi-Velez, Timothy Miller, William Schuler, and Lane Schwartz. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D18-1292" title="">Depth-bounding is effective: Improvements and evaluation of unsupervised PCFG induction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 2721–2731, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi (1985)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aravind&nbsp;K. Joshi. 1985.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1017/CBO9780511597855.007" title=""><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1.1">Tree adjoining grammars: How much context-sensitivity is required to provide reasonable structural descriptions?</em></a>, Studies in Natural Language Processing, page 206–250. Cambridge University Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karamcheti et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Siddharth* Karamcheti, Laurel* Orr, Jason Bolton, Tianyi Zhang, Karan Goel, Avanika Narayan, Rishi Bommasani, Deepak Narayanan, Tatsunori Hashimoto, Dan Jurafsky, Christopher&nbsp;D. Manning, Christopher Potts, Christopher Ré, and Percy Liang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/stanford-crfm/mistral" title="">Mistral - a journey towards reproducible language model training</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karlsson (2007)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fred Karlsson. 2007.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1017/S0022226707004616" title="">Constraints on multiple center-embedding of clauses</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Journal of Linguistics</em>, 43(2):365–392.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kazemnejad et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Amirhossein Kazemnejad, Inkit Padhi, Karthikeyan&nbsp;Natesan Ramamurthy, Payel Das, and Siva Reddy. 2023.

</span>
<span class="ltx_bibblock">The impact of positional encoding on length generalization in transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2305.19466</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levy (2008)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Roger Levy. 2008.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/j.cognition.2007.05.006" title="">Expectation-based syntactic comprehension</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Cognition</em>, 106(3):1126–1177.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mansfield and Kemp (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John Mansfield and Charles Kemp. 2023.

</span>
<span class="ltx_bibblock">The emergence of grammatical structure from inter-predictability.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marvin and Linzen (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rebecca Marvin and Tal Linzen. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D18-1151" title="">Targeted syntactic evaluation of language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 1192–1202, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merrill (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
William Merrill. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W19-3901" title="">Sequential neural networks as automata</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the Workshop on Deep Learning and Formal Languages: Building Bridges</em>, pages 1–13, Florence. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merrill et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
William Merrill, Gail Weiss, Yoav Goldberg, Roy Schwartz, Noah&nbsp;A. Smith, and Eran Yahav. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.43" title="">A formal hierarchy of RNN architectures</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 443–459, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell and Bowers (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jeff Mitchell and Jeffrey Bowers. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.coling-main.451" title="">Priorless recurrent networks learn curiously</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the 28th International Conference on Computational Linguistics</em>, pages 5147–5158, Barcelona, Spain (Online). International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moro et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andrea Moro, Matteo Greco, and Stefano&nbsp;F. Cappa. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/j.cortex.2023.07.003" title="">Large languages, impossible languages and human brains</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Cortex</em>, 167:82–85.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Murty et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shikhar Murty, Pratyusha Sharma, Jacob Andreas, and Christopher&nbsp;D. Manning. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.19089" title="">Pushdown layers: Encoding recursive structure in transformer language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Musso et&nbsp;al. (2003)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mariacristina Musso, Andrea Moro, Volkmar Glauche, Michel Rijntjes, Jürgen Reichenbach, Christian Büchel, and Cornelius Weiller. 2003.

</span>
<span class="ltx_bibblock">Broca’s area and the language instinct.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Nature Neuroscience</em>, 6(7):774–781.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nefdt (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ryan&nbsp;M. Nefdt. 2024.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">The Philosophy of Theoretical Linguistics: A Contemporary Outlook</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papadimitriou et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Isabel Papadimitriou, Richard Futrell, and Kyle Mahowald. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-short.71" title="">When classifying grammatical role, BERT doesn’t care about word order… except when it matters</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pages 636–643, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papadimitriou and Jurafsky (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Isabel Papadimitriou and Dan Jurafsky. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2304.13060" title="">Injecting structural hints: Using language models to study inductive biases in language learning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pham et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Thang Pham, Trung Bui, Long Mai, and Anh Nguyen. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.findings-acl.98" title="">Out of order: How important is the sequential order of words in a sentence in natural language understanding tasks?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</em>, pages 1145–1160, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prasad et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Grusha Prasad, Marten van Schijndel, and Tal Linzen. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/K19-1007" title="">Using priming to uncover the organization of syntactic representations in neural language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</em>, pages 66–76, Hong Kong, China. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pérez et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jorge Pérez, Pablo Barceló, and Javier Marinkovic. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v22/20-302.html" title="">Attention is Turing-complete</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Journal of Machine Learning Research</em>, 22(75):1–35.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, and Christopher&nbsp;D. Manning. 2020.

</span>
<span class="ltx_bibblock">Stanza: A Python natural language processing toolkit for many human languages.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openai.com/blog/language-unsupervised/" title="">Improving language understanding by generative pre-training</a>.

</span>
<span class="ltx_bibblock">Ms, OpenAI.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock">Ms, OpenAI.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shieber (1985)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Stuart&nbsp;M. Shieber. 1985.

</span>
<span class="ltx_bibblock">Evidence against the context-freeness of natural language.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Linguistics and Philosophy</em>, 8(3):333–343.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sinha et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Koustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle Pineau, Adina Williams, and Douwe Kiela. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.230" title="">Masked language modeling and the distributional hypothesis: Order word matters pre-training for little</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 2888–2913, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tenney et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R.&nbsp;Thomas McCoy, Najoung Kim, Benjamin&nbsp;Van Durme, Samuel&nbsp;R. Bowman, Dipanjan Das, and Ellie Pavlick. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=SJzSgnRcKX" title="">What do you learn from context? Probing for sentence structure in contextualized word representations</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan&nbsp;N Gomez, Ł&nbsp;ukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="">Attention is all you need</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">Advances in Neural Information Processing Systems</em>, volume&nbsp;30. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warstadt et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alex Warstadt, Leshem Choshen, Aaron Mueller, Adina Williams, Ethan Wilcox, and Chengxu Zhuang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2301.11796" title="">Call for papers – the BabyLM challenge: Sample-efficient pretraining on a developmentally plausible corpus</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weiss et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gail Weiss, Yoav Goldberg, and Eran Yahav. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P18-2117" title="">On the practical computational power of finite precision RNNs for language recognition</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pages 740–745, Melbourne, Australia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilcox et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ethan Wilcox, Roger Levy, Takashi Morita, and Richard Futrell. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W18-5423" title="">What do RNN language models learn about filler–gap dependencies?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</em>, pages 211–221, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilcox et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ethan&nbsp;Gotlieb Wilcox, Richard Futrell, and Roger Levy. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/ling_a_00491" title="">Using computational models to test syntactic learnability</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">Linguistic Inquiry</em>, pages 1–44.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhengxuan Wu, Karel D’Oosterlinck, Atticus Geiger, Amir Zur, and Christopher Potts. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v202/wu23b.html" title="">Causal proxy models for concept-based model explanations</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">Proceedings of the 40th International Conference on Machine Learning</em>, volume 202 of <em class="ltx_emph ltx_font_italic" id="bib.bib67.2.2">Proceedings of Machine Learning Research</em>, pages 37313–37334. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhengxuan Wu, Atticus Geiger, Thomas Icard, Christopher Potts, and Noah Goodman. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/f6a8b109d4d4fd64c75e94aaf85d9697-Paper-Conference.pdf" title="">Interpretability at scale: Identifying causal mechanisms in Alpaca</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">Advances in Neural Information Processing Systems</em>, volume&nbsp;36, pages 78205–78226. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhengxuan Wu, Atticus Geiger, Joshua Rozner, Elisa Kreiss, Hanson Lu, Thomas Icard, Christopher Potts, and Noah Goodman. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.318" title="">Causal distillation for language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 4288–4295, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Supplementary Materials</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dataset Filters</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">The BabyLM dataset <cite class="ltx_cite ltx_citemacro_cite">Warstadt et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib63" title="">2023</a>)</cite> is an English-language dataset of
about 100 million words intended to approximate the
amount of linguistic data available to an English-speaking child.
To create a dataset for an impossible language, we first pre-process the BabyLM dataset using Stanza <cite class="ltx_cite ltx_citemacro_cite">Qi et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib56" title="">2020</a>)</cite>. We perform sentence segmentation on each dataset file and then extract part-of-speech (POS) and morphological feature tags for all the sentences, which are required for the <span class="ltx_text ltx_font_smallcaps" id="A1.p1.1.1">*Hop</span> transformations. We transform each tagged sentence in the original BabyLM dataset using the impossible language’s rule-based perturbation function, as described in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S3" title="3 Impossible Languages ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>.
Depending on the class of the impossible language and the specific features of the input sentence, perturbed sentences may be included or excluded from the final dataset used for model training (see below for details on this filtering). Since we apply these filters, the language classes have datasets of slightly different sizes. The <span class="ltx_text ltx_font_smallcaps" id="A1.p1.1.2">*Shuffle</span> and <span class="ltx_text ltx_font_smallcaps" id="A1.p1.1.3">*Reverse</span> languages have training sets of about 9.69 million sentences, and the <span class="ltx_text ltx_font_smallcaps" id="A1.p1.1.4">*Hop</span> languages have training sets of about 8.43 million sentences.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_smallcaps ltx_title_paragraph">*Shuffle Filters</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.1">For the <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px1.p1.1.1">*Shuffle</span> languages, we filter sentences from the BabyLM dataset such that the set of token sequence lengths seen in the validation and test sets are also seen in the training set. This ensures that any shuffles for the <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px1.p1.1.2">DeterministicShuffle</span> perturbation (which are determined by the token sequence length) in the test set have also occurred at least once in the training set. We apply these filters for all <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px1.p1.1.3">*Shuffle</span> languages such that their datasets are comprised of the same subset of original sentences.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_font_smallcaps ltx_title_paragraph">*Reverse Filters</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p1.1">For the <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px2.p1.1.1">*Reverse</span> languages, we do not apply any sentence filtering, so their models are trained on the entire BabyLM dataset.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_font_smallcaps ltx_title_paragraph">*Hop Filters</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px3.p1.1">For the <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px3.p1.1.1">*Hop</span> languages, we filter out sentences from the BabyLM dataset that would not allow the special markers to fully complete 4 hops in the <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px3.p1.1.2">TokenHop</span> or <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px3.p1.1.3">WordHop</span> perturbations, i.e.&nbsp;sentences in which a 3rd-person present tense verb is too close to the end of the sentence. We again filter out these sentences from all perturbations, so <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px3.p1.1.4">TokenHop</span>, <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px3.p1.1.5">WordHop</span>, and <span class="ltx_text ltx_font_smallcaps" id="A1.SS0.SSS0.Px3.p1.1.6">NoHop</span> are comprised of the same subset of original sentences from the BabyLM dataset.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>GPT-2 Training Details and Hyperparameters</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">We train GPT-2 small models with a standard training regime <cite class="ltx_cite ltx_citemacro_cite">Radford et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib57" title="">2018</a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib58" title="">2019</a>)</cite> using the library of <cite class="ltx_cite ltx_citemacro_citet">Karamcheti et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib38" title="">2021</a>)</cite>. We mostly use the default GPT-2 small hyperparameters to train our models (context length of 1024, batch size of 512, etc.). We only change the total number of training steps and the number of warm-up steps. We train with a learning rate that linearly warms up from 0 to 6e-4 over 300 steps. While 10% of steps for warm-up is typical for LLM training, we acknowledge that the best warm-up may be different when using a small pretraining dataset, so we also tried 1,000 warm-up steps and 4,000 warm-up steps. (4,000 steps is the GPT-2 default. Since we only train for 3,000 steps, this effectively means we have a learning-rate that linearly warms up from 0 to <span class="ltx_text" id="A2.p1.1.1">4.5e-4</span>.) Using a different warm-up did not change the ranking of impossible language model perplexities.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.2">We train the models for 3,000 training steps, which equates to about 11.03 epochs for the <span class="ltx_text ltx_font_smallcaps" id="A2.p2.2.1">*Shuffle</span> languages, 10.05 epochs for the <span class="ltx_text ltx_font_smallcaps" id="A2.p2.2.2">*Reverse</span> languages, and 12.04 epochs for the <span class="ltx_text ltx_font_smallcaps" id="A2.p2.2.3">*Hop</span> languages. The vocabulary set also varies based on the language. The <span class="ltx_text ltx_font_smallcaps" id="A2.p2.2.4">*Shuffle</span> languages use the standard GPT-2 vocabulary containing 50,257 tokens; the <span class="ltx_text ltx_font_smallcaps" id="A2.p2.2.5">*Reverse</span> languages add one special token <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="A2.p2.2.6" style="border-color: #000000;padding:1.0pt;">R</span>, for a vocabulary size of 50,258; and the <span class="ltx_text ltx_font_smallcaps" id="A2.p2.2.7">*Hop</span> languages add two special tokens <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="A2.p2.2.8" style="border-color: #000000;padding:1.0pt;">S</span> and <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="A2.p2.2.9" style="border-color: #000000;padding:1.0pt;">P</span> for verb inflection, for a vocabulary size of 50,259. We train on NVIDIA RTX 3090 (24GB) GPUs and NVIDIA RTX A6000 (48GB) GPUs. The runtime for each pretraining experiment was <math alttext="\sim" class="ltx_Math" display="inline" id="A2.p2.1.m1.1"><semantics id="A2.p2.1.m1.1a"><mo id="A2.p2.1.m1.1.1" xref="A2.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A2.p2.1.m1.1b"><csymbol cd="latexml" id="A2.p2.1.m1.1.1.cmml" xref="A2.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="A2.p2.1.m1.1d">∼</annotation></semantics></math>24 hours (for one language and one random seed), for a total experiment runtime of <math alttext="\sim" class="ltx_Math" display="inline" id="A2.p2.2.m2.1"><semantics id="A2.p2.2.m2.1a"><mo id="A2.p2.2.m2.1.1" xref="A2.p2.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A2.p2.2.m2.1b"><csymbol cd="latexml" id="A2.p2.2.m2.1.1.cmml" xref="A2.p2.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.2.m2.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="A2.p2.2.m2.1d">∼</annotation></semantics></math>1800 hours.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Results for Models without Positional Encodings</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Here, we present results for each of our experiments using GPT-2 models we trained without positional encodings. All other aspects of the experiments are the same, including the impossible language datasets and training hyperparameters. We again train 5 sets of models initialized using different random seeds. <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A3.F8" title="In Appendix C Results for Models without Positional Encodings ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">8</span></a> presents the perplexity results; <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A3.F8" title="In Appendix C Results for Models without Positional Encodings ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">8</span></a> presents the surprisal results; and <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A3.F8" title="In Appendix C Results for Models without Positional Encodings ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">8</span></a> presents the causal intervention results.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A3.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="283" id="A3.F8.g1" src="./Mission_ Impossible Language Models_files/x9.png" width="788"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Perplexities on a sample of 10K test sentences for each
impossible language model trained <em class="ltx_emph ltx_font_italic" id="A3.F8.10.1">without positional encodings</em>. Error bars indicate 95% confidence intervals across 5 training runs initialized with different random seeds and evaluated on different test samples.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel" id="A3.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="565" id="A3.F6.sf1.g1" src="./Mission_ Impossible Language Models_files/x10.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Mean surprisals of the verb marker token (<span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="A3.F6.sf1.4.1" style="border-color: #000000;padding:1.0pt;">S</span> or <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="A3.F6.sf1.5.2" style="border-color: #000000;padding:1.0pt;">P</span>) for each <span class="ltx_text ltx_font_smallcaps" id="A3.F6.sf1.6.3">*Hop</span> model. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel" id="A3.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="565" id="A3.F6.sf2.g1" src="./Mission_ Impossible Language Models_files/x11.png" width="789">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Mean surprisal difference between the verb marker token (<span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="A3.F6.sf2.4.1" style="border-color: #000000;padding:1.0pt;">S</span> or <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="A3.F6.sf2.5.2" style="border-color: #000000;padding:1.0pt;">P</span>) and the following token for each <span class="ltx_text ltx_font_smallcaps" id="A3.F6.sf2.6.3">*Hop</span> model.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Surprisal tests for each <span class="ltx_text ltx_font_smallcaps" id="A3.F8.13.1">*Hop</span> model over training steps (trained <em class="ltx_emph ltx_font_italic" id="A3.F8.14.2">without positional encodings</em>). Error bars indicate 95% confidence intervals across 5 training runs initialized with different random seeds and evaluated on different test samples.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="208" id="A3.F8.g2" src="./Mission_ Impossible Language Models_files/x12.png" width="273"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="208" id="A3.F8.g3" src="./Mission_ Impossible Language Models_files/x13.png" width="273"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="208" id="A3.F8.g4" src="./Mission_ Impossible Language Models_files/x14.png" width="273"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Subject–verb agreement interchange intervention accuracies (IIA) for each
<span class="ltx_text ltx_font_smallcaps" id="A3.F8.19.1">*Hop</span> model trained <em class="ltx_emph ltx_font_italic" id="A3.F8.20.2">without positional encodings</em>. Vertical axes denote the GPT-2 layer of the intervention, and horizontal axes denote the token position of the intervention.
<math alttext="t_{d}" class="ltx_Math" display="inline" id="A3.F8.5.m1.1"><semantics id="A3.F8.5.m1.1a"><msub id="A3.F8.5.m1.1.1" xref="A3.F8.5.m1.1.1.cmml"><mi id="A3.F8.5.m1.1.1.2" xref="A3.F8.5.m1.1.1.2.cmml">t</mi><mi id="A3.F8.5.m1.1.1.3" xref="A3.F8.5.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="A3.F8.5.m1.1b"><apply id="A3.F8.5.m1.1.1.cmml" xref="A3.F8.5.m1.1.1"><csymbol cd="ambiguous" id="A3.F8.5.m1.1.1.1.cmml" xref="A3.F8.5.m1.1.1">subscript</csymbol><ci id="A3.F8.5.m1.1.1.2.cmml" xref="A3.F8.5.m1.1.1.2">𝑡</ci><ci id="A3.F8.5.m1.1.1.3.cmml" xref="A3.F8.5.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F8.5.m1.1c">t_{d}</annotation><annotation encoding="application/x-llamapun" id="A3.F8.5.m1.1d">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="t_{s}" class="ltx_Math" display="inline" id="A3.F8.6.m2.1"><semantics id="A3.F8.6.m2.1a"><msub id="A3.F8.6.m2.1.1" xref="A3.F8.6.m2.1.1.cmml"><mi id="A3.F8.6.m2.1.1.2" xref="A3.F8.6.m2.1.1.2.cmml">t</mi><mi id="A3.F8.6.m2.1.1.3" xref="A3.F8.6.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A3.F8.6.m2.1b"><apply id="A3.F8.6.m2.1.1.cmml" xref="A3.F8.6.m2.1.1"><csymbol cd="ambiguous" id="A3.F8.6.m2.1.1.1.cmml" xref="A3.F8.6.m2.1.1">subscript</csymbol><ci id="A3.F8.6.m2.1.1.2.cmml" xref="A3.F8.6.m2.1.1.2">𝑡</ci><ci id="A3.F8.6.m2.1.1.3.cmml" xref="A3.F8.6.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F8.6.m2.1c">t_{s}</annotation><annotation encoding="application/x-llamapun" id="A3.F8.6.m2.1d">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="t_{v}" class="ltx_Math" display="inline" id="A3.F8.7.m3.1"><semantics id="A3.F8.7.m3.1a"><msub id="A3.F8.7.m3.1.1" xref="A3.F8.7.m3.1.1.cmml"><mi id="A3.F8.7.m3.1.1.2" xref="A3.F8.7.m3.1.1.2.cmml">t</mi><mi id="A3.F8.7.m3.1.1.3" xref="A3.F8.7.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="A3.F8.7.m3.1b"><apply id="A3.F8.7.m3.1.1.cmml" xref="A3.F8.7.m3.1.1"><csymbol cd="ambiguous" id="A3.F8.7.m3.1.1.1.cmml" xref="A3.F8.7.m3.1.1">subscript</csymbol><ci id="A3.F8.7.m3.1.1.2.cmml" xref="A3.F8.7.m3.1.1.2">𝑡</ci><ci id="A3.F8.7.m3.1.1.3.cmml" xref="A3.F8.7.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F8.7.m3.1c">t_{v}</annotation><annotation encoding="application/x-llamapun" id="A3.F8.7.m3.1d">italic_t start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> represent the tokens for the determiner, subject, and
verb, respectively. <math alttext="t_{1}\dots t_{4}" class="ltx_Math" display="inline" id="A3.F8.8.m4.1"><semantics id="A3.F8.8.m4.1a"><mrow id="A3.F8.8.m4.1.1" xref="A3.F8.8.m4.1.1.cmml"><msub id="A3.F8.8.m4.1.1.2" xref="A3.F8.8.m4.1.1.2.cmml"><mi id="A3.F8.8.m4.1.1.2.2" xref="A3.F8.8.m4.1.1.2.2.cmml">t</mi><mn id="A3.F8.8.m4.1.1.2.3" xref="A3.F8.8.m4.1.1.2.3.cmml">1</mn></msub><mo id="A3.F8.8.m4.1.1.1" xref="A3.F8.8.m4.1.1.1.cmml">⁢</mo><mi id="A3.F8.8.m4.1.1.3" mathvariant="normal" xref="A3.F8.8.m4.1.1.3.cmml">…</mi><mo id="A3.F8.8.m4.1.1.1a" xref="A3.F8.8.m4.1.1.1.cmml">⁢</mo><msub id="A3.F8.8.m4.1.1.4" xref="A3.F8.8.m4.1.1.4.cmml"><mi id="A3.F8.8.m4.1.1.4.2" xref="A3.F8.8.m4.1.1.4.2.cmml">t</mi><mn id="A3.F8.8.m4.1.1.4.3" xref="A3.F8.8.m4.1.1.4.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A3.F8.8.m4.1b"><apply id="A3.F8.8.m4.1.1.cmml" xref="A3.F8.8.m4.1.1"><times id="A3.F8.8.m4.1.1.1.cmml" xref="A3.F8.8.m4.1.1.1"></times><apply id="A3.F8.8.m4.1.1.2.cmml" xref="A3.F8.8.m4.1.1.2"><csymbol cd="ambiguous" id="A3.F8.8.m4.1.1.2.1.cmml" xref="A3.F8.8.m4.1.1.2">subscript</csymbol><ci id="A3.F8.8.m4.1.1.2.2.cmml" xref="A3.F8.8.m4.1.1.2.2">𝑡</ci><cn id="A3.F8.8.m4.1.1.2.3.cmml" type="integer" xref="A3.F8.8.m4.1.1.2.3">1</cn></apply><ci id="A3.F8.8.m4.1.1.3.cmml" xref="A3.F8.8.m4.1.1.3">…</ci><apply id="A3.F8.8.m4.1.1.4.cmml" xref="A3.F8.8.m4.1.1.4"><csymbol cd="ambiguous" id="A3.F8.8.m4.1.1.4.1.cmml" xref="A3.F8.8.m4.1.1.4">subscript</csymbol><ci id="A3.F8.8.m4.1.1.4.2.cmml" xref="A3.F8.8.m4.1.1.4.2">𝑡</ci><cn id="A3.F8.8.m4.1.1.4.3.cmml" type="integer" xref="A3.F8.8.m4.1.1.4.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F8.8.m4.1c">t_{1}\dots t_{4}</annotation><annotation encoding="application/x-llamapun" id="A3.F8.8.m4.1d">italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT … italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT</annotation></semantics></math> represent the four tokens/words between the
verb and its marker for <span class="ltx_text ltx_font_smallcaps" id="A3.F8.21.3">TokenHop</span> and <span class="ltx_text ltx_font_smallcaps" id="A3.F8.22.4">WordHop</span>.
IIA values are averaged over results from 5 models initialized on different random seeds. See Figures&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F15" title="Figure 15 ‣ Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">15</span></a>,&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F16" title="Figure 16 ‣ Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">16</span></a>, and&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F17" title="Figure 17 ‣ Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">17</span></a> for confidence intervals.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Constituency Probing Evaluation</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">We also test how perturbations might influence latent linguistic properties in sentences that are seemingly <em class="ltx_emph ltx_font_italic" id="A4.p1.1.1">unaffected</em> by the perturbations. For this, we develop a constituency probing experiment to examine whether the contextual representations generated by different models are effective in classifying a sequence of tokens with an appropriate constituent label, similar to the edge probing experiments of <cite class="ltx_cite ltx_citemacro_citet">Tenney et&nbsp;al. <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#bib.bib61" title="">2019</a></cite>. For example, if the input sentence is “I enjoy strawberry ice cream” and the span of tokens in question represents the constituent “strawberry ice cream,” the span should be labeled as a noun phrase (NP).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="A4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setup.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A4.SS0.SSS0.Px1.p1.1">We conduct these experiments for <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px1.p1.1.1">*Reverse</span> and <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px1.p1.1.2">*Hop</span> languages, since these languages have constituents in contiguous token sequences. For <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px1.p1.1.3">NoReverse</span> and <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px1.p1.1.4">PartialReverse</span>, we take a sample of unaltered BabyLM test sentences and omit the reversal token <span class="ltx_text ltx_font_typewriter ltx_framed ltx_framed_rectangle" id="A4.SS0.SSS0.Px1.p1.1.5" style="border-color: #000000;padding:1.0pt;">R</span>. For <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px1.p1.1.6">FullReverse</span>, we use the same sample sentences, but reverse the tokens. For the <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px1.p1.1.7">*Hop</span> languages, we use a sample of BabyLM test sentences that are unaffected by the perturbation, which are sentences that do not contain 3rd-person present tense verbs. To extract constituents for testing, we parse the sample sentences using Stanza’s BERT-based consituency parser. We include noun phrases (NP), verb phrases (VP), adjective phrases (ADJP), adverb phrases (ADVP), and prepositional phrases (PP), and we stratify the samples so that there are equal numbers of example constituents for each phrasal category. We obtain a total of 10K examples for probe training and testing for each language class, where an example is comprised of a tokenized sentence, indices of the constituent span, and the constituent label.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A4.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A4.SS0.SSS0.Px1.p2.1">Our probes are L2-regularized logistic regression classifiers trained on the span representations of the tokens corresponding to constituents in the examples. To obtain span representations for training the probes, we mean-pool the representations of the tokens within the span. We try extracting representations from GPT-2 by averaging the last four hidden layers of the model or using different layers individually. We train each probe for a maximum of 10 iterations and hold out 20% of constituent examples for testing.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Hypothesis.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A4.SS0.SSS0.Px2.p1.1">Constituency probes will achieve higher accuracy for possible languages than impossible ones, in virtue of the fact that the impossible languages are defined by some rules that do not respect constituency boundaries.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A4.SS0.SSS0.Px3.p1.1">The results of the probing experiment using the average of the last four GPT-2 layers are presented in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A4.F9" title="In Results. ‣ Appendix D Constituency Probing Evaluation ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">9</span></a>. Across <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px3.p1.1.1">*Reverse</span> and <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px3.p1.1.2">*Hop</span> models trained <em class="ltx_emph ltx_font_italic" id="A4.SS0.SSS0.Px3.p1.1.3">with</em> positional encodings, there are not any clear trends indicating that certain models have better representations of constituents than others, as differences among probe accuracies are minimal and unstable across training steps. However, looking closely at the <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px3.p1.1.4">*Reverse</span> models <em class="ltx_emph ltx_font_italic" id="A4.SS0.SSS0.Px3.p1.1.5">without</em> positional encodings, we can see that <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px3.p1.1.6">PartialReverse</span> has significantly lower probe accuracy than the other models up until 2K training steps. We found similar results when using different layers for span representations, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A4.F10" title="In Results. ‣ Appendix D Constituency Probing Evaluation ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">10</span></a>. These results might indicate that the <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px3.p1.1.7">*Hop</span> perturbations were too weak to fundamentally affect the models’ representations of latent linguistic structure, but quite unnatural reversal rule of the <span class="ltx_text ltx_font_smallcaps" id="A4.SS0.SSS0.Px3.p1.1.8">PartialReverse</span> language disturbed consituency boundaries in a way that could not be recovered by GPT-2 models without positional encodings.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A4.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A4.F9.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="466" id="A4.F9.sf1.g1" src="./Mission_ Impossible Language Models_files/x15.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Probe accuracy for <span class="ltx_text ltx_font_smallcaps" id="A4.F9.sf1.3.1">*Reverse</span> and <span class="ltx_text ltx_font_smallcaps" id="A4.F9.sf1.4.2">*Hop</span> models.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A4.F9.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="466" id="A4.F9.sf2.g1" src="./Mission_ Impossible Language Models_files/x16.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Probe accuracy <em class="ltx_emph ltx_font_italic" id="A4.F9.sf2.2.1">without positional encodings</em>. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Constituency probe accuracy for <span class="ltx_text ltx_font_smallcaps" id="A4.F9.3.1">*Reverse</span> and <span class="ltx_text ltx_font_smallcaps" id="A4.F9.4.2">*Hop</span> models over training steps. Span representations were extracted by averaging the last four hidden layers of GPT-2. Error bars indicate 95% confidence intervals across 5 training runs initialized with different random seeds and evaluated on different test samples.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A4.F10.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="A4.F10.sf1.g1" src="./Mission_ Impossible Language Models_files/x17.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Probe accuracy for <span class="ltx_text ltx_font_smallcaps" id="A4.F10.sf1.2.1">*Reverse</span> models.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A4.F10.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="181" id="A4.F10.sf2.g1" src="./Mission_ Impossible Language Models_files/x18.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Probe accuracy for <span class="ltx_text ltx_font_smallcaps" id="A4.F10.sf2.2.1">*Hop</span> models.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A4.F10.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="A4.F10.sf3.g1" src="./Mission_ Impossible Language Models_files/x19.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Probe accuracy for <span class="ltx_text ltx_font_smallcaps" id="A4.F10.sf3.3.1">*Reverse</span> models <em class="ltx_emph ltx_font_italic" id="A4.F10.sf3.4.2">without positional encodings</em>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A4.F10.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="A4.F10.sf4.g1" src="./Mission_ Impossible Language Models_files/x20.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Probe accuracy for <span class="ltx_text ltx_font_smallcaps" id="A4.F10.sf4.3.1">*Hop</span> models <em class="ltx_emph ltx_font_italic" id="A4.F10.sf4.4.2">without positional encodings</em>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Constituency probe accuracy for <span class="ltx_text ltx_font_smallcaps" id="A4.F10.3.1">*Reverse</span> and <span class="ltx_text ltx_font_smallcaps" id="A4.F10.4.2">*Hop</span> models using span representations extracted from different GPT-2 layers (1, 3, 6, 9, 12) over training steps. Error bars indicate 95% confidence intervals across 5 training runs initialized with different random seeds and evaluated on different test samples.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Additional <span class="ltx_text ltx_font_smallcaps" id="A5.1.1">DeterministicShuffle</span> Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p" id="A5.p1.3">In addition to perplexities of each impossible language model on its own test data, we also obtain perplexities for each <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A5.p1.3.1">DeterministicShuffle</span> model on the <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A5.p1.3.2">NondeterministicShuffle</span> test sample and all other <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A5.p1.3.3">DeterministicShuffle</span> test samples. This measures whether these models have learned to distinguish their own shuffles from other shuffles. We found that this was indeed the case, as shown in the results in <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A5.F11" title="In Appendix E Additional DeterministicShuffle Results ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">11</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A5.F11">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A5.F11.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="298" id="A5.F11.sf1.g1" src="./Mission_ Impossible Language Models_files/x21.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Test perplexities for models <em class="ltx_emph ltx_font_italic" id="A5.F11.sf1.2.1">with</em> positional encodings.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A5.F11.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="298" id="A5.F11.sf2.g1" src="./Mission_ Impossible Language Models_files/x22.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Test perplexities for models <em class="ltx_emph ltx_font_italic" id="A5.F11.sf2.2.1">without</em> positional encodings.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Test perplexities for each <span class="ltx_text ltx_font_smallcaps" id="A5.F11.14.1">DeterministicShuffle</span> model (<math alttext="s=21" class="ltx_Math" display="inline" id="A5.F11.6.m1.1"><semantics id="A5.F11.6.m1.1b"><mrow id="A5.F11.6.m1.1.1" xref="A5.F11.6.m1.1.1.cmml"><mi id="A5.F11.6.m1.1.1.2" xref="A5.F11.6.m1.1.1.2.cmml">s</mi><mo id="A5.F11.6.m1.1.1.1" xref="A5.F11.6.m1.1.1.1.cmml">=</mo><mn id="A5.F11.6.m1.1.1.3" xref="A5.F11.6.m1.1.1.3.cmml">21</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.F11.6.m1.1c"><apply id="A5.F11.6.m1.1.1.cmml" xref="A5.F11.6.m1.1.1"><eq id="A5.F11.6.m1.1.1.1.cmml" xref="A5.F11.6.m1.1.1.1"></eq><ci id="A5.F11.6.m1.1.1.2.cmml" xref="A5.F11.6.m1.1.1.2">𝑠</ci><cn id="A5.F11.6.m1.1.1.3.cmml" type="integer" xref="A5.F11.6.m1.1.1.3">21</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F11.6.m1.1d">s=21</annotation><annotation encoding="application/x-llamapun" id="A5.F11.6.m1.1e">italic_s = 21</annotation></semantics></math> left, <math alttext="s=57" class="ltx_Math" display="inline" id="A5.F11.7.m2.1"><semantics id="A5.F11.7.m2.1b"><mrow id="A5.F11.7.m2.1.1" xref="A5.F11.7.m2.1.1.cmml"><mi id="A5.F11.7.m2.1.1.2" xref="A5.F11.7.m2.1.1.2.cmml">s</mi><mo id="A5.F11.7.m2.1.1.1" xref="A5.F11.7.m2.1.1.1.cmml">=</mo><mn id="A5.F11.7.m2.1.1.3" xref="A5.F11.7.m2.1.1.3.cmml">57</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.F11.7.m2.1c"><apply id="A5.F11.7.m2.1.1.cmml" xref="A5.F11.7.m2.1.1"><eq id="A5.F11.7.m2.1.1.1.cmml" xref="A5.F11.7.m2.1.1.1"></eq><ci id="A5.F11.7.m2.1.1.2.cmml" xref="A5.F11.7.m2.1.1.2">𝑠</ci><cn id="A5.F11.7.m2.1.1.3.cmml" type="integer" xref="A5.F11.7.m2.1.1.3">57</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F11.7.m2.1d">s=57</annotation><annotation encoding="application/x-llamapun" id="A5.F11.7.m2.1e">italic_s = 57</annotation></semantics></math> middle, <math alttext="s=84" class="ltx_Math" display="inline" id="A5.F11.8.m3.1"><semantics id="A5.F11.8.m3.1b"><mrow id="A5.F11.8.m3.1.1" xref="A5.F11.8.m3.1.1.cmml"><mi id="A5.F11.8.m3.1.1.2" xref="A5.F11.8.m3.1.1.2.cmml">s</mi><mo id="A5.F11.8.m3.1.1.1" xref="A5.F11.8.m3.1.1.1.cmml">=</mo><mn id="A5.F11.8.m3.1.1.3" xref="A5.F11.8.m3.1.1.3.cmml">84</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.F11.8.m3.1c"><apply id="A5.F11.8.m3.1.1.cmml" xref="A5.F11.8.m3.1.1"><eq id="A5.F11.8.m3.1.1.1.cmml" xref="A5.F11.8.m3.1.1.1"></eq><ci id="A5.F11.8.m3.1.1.2.cmml" xref="A5.F11.8.m3.1.1.2">𝑠</ci><cn id="A5.F11.8.m3.1.1.3.cmml" type="integer" xref="A5.F11.8.m3.1.1.3">84</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.F11.8.m3.1d">s=84</annotation><annotation encoding="application/x-llamapun" id="A5.F11.8.m3.1e">italic_s = 84</annotation></semantics></math> right) on the <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A5.F11.15.2">NondeterministicShuffle</span> test sample and all other <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A5.F11.16.3">DeterministicShuffle</span> test samples. Perplexities were taken on a sample of 10K test sentences from each shuffled test set. Error bars indicate 95% confidence intervals across 5 training runs initialized with different random seeds and evaluated on different test samples.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Confidence Intervals for Interchange Intervention Accuracies</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">We present the same results of our causal abstraction experiments from <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#S4.SS4" title="4.4 Experiment 3: Language Models Develop Natural Solutions to Unnatural Patterns ‣ 4 Experiments ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.4</span></a>, but include confidence intervals for results across models initialized on different random seeds. <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F12" title="In Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">12</span></a> presents the results for <span class="ltx_text ltx_font_smallcaps" id="A6.p1.1.1">NoHop</span>; <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F13" title="In Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">13</span></a> presents the results for <span class="ltx_text ltx_font_smallcaps" id="A6.p1.1.2">TokenHop</span>; and <a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F14" title="In Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">14</span></a> presents the results for <span class="ltx_text ltx_font_smallcaps" id="A6.p1.1.3">WordHop</span>. Figures&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F15" title="Figure 15 ‣ Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">15</span></a>,&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F16" title="Figure 16 ‣ Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">16</span></a>, and&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.06416v2#A6.F17" title="Figure 17 ‣ Appendix F Confidence Intervals for Interchange Intervention Accuracies ‣ Mission: Impossible Language Models"><span class="ltx_text ltx_ref_tag">17</span></a> show the same plots for each <span class="ltx_text ltx_font_smallcaps" id="A6.p1.1.4">*Hop</span> model trained without positional encodings, respectively.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A6.F12">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F12.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F12.sf1.g1" src="./Mission_ Impossible Language Models_files/x23.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>300 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F12.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F12.sf2.g1" src="./Mission_ Impossible Language Models_files/x24.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>600 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F12.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F12.sf3.g1" src="./Mission_ Impossible Language Models_files/x25.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>900 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F12.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F12.sf4.g1" src="./Mission_ Impossible Language Models_files/x26.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>1200 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F12.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F12.sf5.g1" src="./Mission_ Impossible Language Models_files/x27.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>1500 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F12.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F12.sf6.g1" src="./Mission_ Impossible Language Models_files/x28.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>3000 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Subject–verb agreement interchange intervention accuracies (IIA) for
<span class="ltx_text ltx_font_smallcaps" id="A6.F12.8.1">NoHop</span>, with confidence intervals across models trained on 5 different random seeds. Vertical axes denote the GPT-2 layer of the intervention, and horizontal axes denote the token position of the intervention. <math alttext="t_{d}" class="ltx_Math" display="inline" id="A6.F12.4.m1.1"><semantics id="A6.F12.4.m1.1b"><msub id="A6.F12.4.m1.1.1" xref="A6.F12.4.m1.1.1.cmml"><mi id="A6.F12.4.m1.1.1.2" xref="A6.F12.4.m1.1.1.2.cmml">t</mi><mi id="A6.F12.4.m1.1.1.3" xref="A6.F12.4.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F12.4.m1.1c"><apply id="A6.F12.4.m1.1.1.cmml" xref="A6.F12.4.m1.1.1"><csymbol cd="ambiguous" id="A6.F12.4.m1.1.1.1.cmml" xref="A6.F12.4.m1.1.1">subscript</csymbol><ci id="A6.F12.4.m1.1.1.2.cmml" xref="A6.F12.4.m1.1.1.2">𝑡</ci><ci id="A6.F12.4.m1.1.1.3.cmml" xref="A6.F12.4.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F12.4.m1.1d">t_{d}</annotation><annotation encoding="application/x-llamapun" id="A6.F12.4.m1.1e">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="t_{s}" class="ltx_Math" display="inline" id="A6.F12.5.m2.1"><semantics id="A6.F12.5.m2.1b"><msub id="A6.F12.5.m2.1.1" xref="A6.F12.5.m2.1.1.cmml"><mi id="A6.F12.5.m2.1.1.2" xref="A6.F12.5.m2.1.1.2.cmml">t</mi><mi id="A6.F12.5.m2.1.1.3" xref="A6.F12.5.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F12.5.m2.1c"><apply id="A6.F12.5.m2.1.1.cmml" xref="A6.F12.5.m2.1.1"><csymbol cd="ambiguous" id="A6.F12.5.m2.1.1.1.cmml" xref="A6.F12.5.m2.1.1">subscript</csymbol><ci id="A6.F12.5.m2.1.1.2.cmml" xref="A6.F12.5.m2.1.1.2">𝑡</ci><ci id="A6.F12.5.m2.1.1.3.cmml" xref="A6.F12.5.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F12.5.m2.1d">t_{s}</annotation><annotation encoding="application/x-llamapun" id="A6.F12.5.m2.1e">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="t_{v}" class="ltx_Math" display="inline" id="A6.F12.6.m3.1"><semantics id="A6.F12.6.m3.1b"><msub id="A6.F12.6.m3.1.1" xref="A6.F12.6.m3.1.1.cmml"><mi id="A6.F12.6.m3.1.1.2" xref="A6.F12.6.m3.1.1.2.cmml">t</mi><mi id="A6.F12.6.m3.1.1.3" xref="A6.F12.6.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F12.6.m3.1c"><apply id="A6.F12.6.m3.1.1.cmml" xref="A6.F12.6.m3.1.1"><csymbol cd="ambiguous" id="A6.F12.6.m3.1.1.1.cmml" xref="A6.F12.6.m3.1.1">subscript</csymbol><ci id="A6.F12.6.m3.1.1.2.cmml" xref="A6.F12.6.m3.1.1.2">𝑡</ci><ci id="A6.F12.6.m3.1.1.3.cmml" xref="A6.F12.6.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F12.6.m3.1d">t_{v}</annotation><annotation encoding="application/x-llamapun" id="A6.F12.6.m3.1e">italic_t start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> represent the tokens for the determiner, subject, and verb, respectively.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A6.F13">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F13.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F13.sf1.g1" src="./Mission_ Impossible Language Models_files/x29.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>300 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F13.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F13.sf2.g1" src="./Mission_ Impossible Language Models_files/x30.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>600 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F13.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F13.sf3.g1" src="./Mission_ Impossible Language Models_files/x31.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>900 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F13.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F13.sf4.g1" src="./Mission_ Impossible Language Models_files/x32.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>1200 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F13.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F13.sf5.g1" src="./Mission_ Impossible Language Models_files/x33.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>1500 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F13.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F13.sf6.g1" src="./Mission_ Impossible Language Models_files/x34.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>3000 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Subject–verb agreement interchange intervention accuracies (IIA) for
<span class="ltx_text ltx_font_smallcaps" id="A6.F13.10.1">TokenHop</span>, with confidence intervals across models trained on 5 different random seeds. Vertical axes denote the GPT-2 layer of the intervention, and horizontal axes denote the token position of the intervention. <math alttext="t_{d}" class="ltx_Math" display="inline" id="A6.F13.5.m1.1"><semantics id="A6.F13.5.m1.1b"><msub id="A6.F13.5.m1.1.1" xref="A6.F13.5.m1.1.1.cmml"><mi id="A6.F13.5.m1.1.1.2" xref="A6.F13.5.m1.1.1.2.cmml">t</mi><mi id="A6.F13.5.m1.1.1.3" xref="A6.F13.5.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F13.5.m1.1c"><apply id="A6.F13.5.m1.1.1.cmml" xref="A6.F13.5.m1.1.1"><csymbol cd="ambiguous" id="A6.F13.5.m1.1.1.1.cmml" xref="A6.F13.5.m1.1.1">subscript</csymbol><ci id="A6.F13.5.m1.1.1.2.cmml" xref="A6.F13.5.m1.1.1.2">𝑡</ci><ci id="A6.F13.5.m1.1.1.3.cmml" xref="A6.F13.5.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F13.5.m1.1d">t_{d}</annotation><annotation encoding="application/x-llamapun" id="A6.F13.5.m1.1e">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="t_{s}" class="ltx_Math" display="inline" id="A6.F13.6.m2.1"><semantics id="A6.F13.6.m2.1b"><msub id="A6.F13.6.m2.1.1" xref="A6.F13.6.m2.1.1.cmml"><mi id="A6.F13.6.m2.1.1.2" xref="A6.F13.6.m2.1.1.2.cmml">t</mi><mi id="A6.F13.6.m2.1.1.3" xref="A6.F13.6.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F13.6.m2.1c"><apply id="A6.F13.6.m2.1.1.cmml" xref="A6.F13.6.m2.1.1"><csymbol cd="ambiguous" id="A6.F13.6.m2.1.1.1.cmml" xref="A6.F13.6.m2.1.1">subscript</csymbol><ci id="A6.F13.6.m2.1.1.2.cmml" xref="A6.F13.6.m2.1.1.2">𝑡</ci><ci id="A6.F13.6.m2.1.1.3.cmml" xref="A6.F13.6.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F13.6.m2.1d">t_{s}</annotation><annotation encoding="application/x-llamapun" id="A6.F13.6.m2.1e">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="t_{v}" class="ltx_Math" display="inline" id="A6.F13.7.m3.1"><semantics id="A6.F13.7.m3.1b"><msub id="A6.F13.7.m3.1.1" xref="A6.F13.7.m3.1.1.cmml"><mi id="A6.F13.7.m3.1.1.2" xref="A6.F13.7.m3.1.1.2.cmml">t</mi><mi id="A6.F13.7.m3.1.1.3" xref="A6.F13.7.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F13.7.m3.1c"><apply id="A6.F13.7.m3.1.1.cmml" xref="A6.F13.7.m3.1.1"><csymbol cd="ambiguous" id="A6.F13.7.m3.1.1.1.cmml" xref="A6.F13.7.m3.1.1">subscript</csymbol><ci id="A6.F13.7.m3.1.1.2.cmml" xref="A6.F13.7.m3.1.1.2">𝑡</ci><ci id="A6.F13.7.m3.1.1.3.cmml" xref="A6.F13.7.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F13.7.m3.1d">t_{v}</annotation><annotation encoding="application/x-llamapun" id="A6.F13.7.m3.1e">italic_t start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> represent the tokens for the determiner, subject, and verb. <math alttext="t_{1}\dots t_{4}" class="ltx_Math" display="inline" id="A6.F13.8.m4.1"><semantics id="A6.F13.8.m4.1b"><mrow id="A6.F13.8.m4.1.1" xref="A6.F13.8.m4.1.1.cmml"><msub id="A6.F13.8.m4.1.1.2" xref="A6.F13.8.m4.1.1.2.cmml"><mi id="A6.F13.8.m4.1.1.2.2" xref="A6.F13.8.m4.1.1.2.2.cmml">t</mi><mn id="A6.F13.8.m4.1.1.2.3" xref="A6.F13.8.m4.1.1.2.3.cmml">1</mn></msub><mo id="A6.F13.8.m4.1.1.1" xref="A6.F13.8.m4.1.1.1.cmml">⁢</mo><mi id="A6.F13.8.m4.1.1.3" mathvariant="normal" xref="A6.F13.8.m4.1.1.3.cmml">…</mi><mo id="A6.F13.8.m4.1.1.1b" xref="A6.F13.8.m4.1.1.1.cmml">⁢</mo><msub id="A6.F13.8.m4.1.1.4" xref="A6.F13.8.m4.1.1.4.cmml"><mi id="A6.F13.8.m4.1.1.4.2" xref="A6.F13.8.m4.1.1.4.2.cmml">t</mi><mn id="A6.F13.8.m4.1.1.4.3" xref="A6.F13.8.m4.1.1.4.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A6.F13.8.m4.1c"><apply id="A6.F13.8.m4.1.1.cmml" xref="A6.F13.8.m4.1.1"><times id="A6.F13.8.m4.1.1.1.cmml" xref="A6.F13.8.m4.1.1.1"></times><apply id="A6.F13.8.m4.1.1.2.cmml" xref="A6.F13.8.m4.1.1.2"><csymbol cd="ambiguous" id="A6.F13.8.m4.1.1.2.1.cmml" xref="A6.F13.8.m4.1.1.2">subscript</csymbol><ci id="A6.F13.8.m4.1.1.2.2.cmml" xref="A6.F13.8.m4.1.1.2.2">𝑡</ci><cn id="A6.F13.8.m4.1.1.2.3.cmml" type="integer" xref="A6.F13.8.m4.1.1.2.3">1</cn></apply><ci id="A6.F13.8.m4.1.1.3.cmml" xref="A6.F13.8.m4.1.1.3">…</ci><apply id="A6.F13.8.m4.1.1.4.cmml" xref="A6.F13.8.m4.1.1.4"><csymbol cd="ambiguous" id="A6.F13.8.m4.1.1.4.1.cmml" xref="A6.F13.8.m4.1.1.4">subscript</csymbol><ci id="A6.F13.8.m4.1.1.4.2.cmml" xref="A6.F13.8.m4.1.1.4.2">𝑡</ci><cn id="A6.F13.8.m4.1.1.4.3.cmml" type="integer" xref="A6.F13.8.m4.1.1.4.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F13.8.m4.1d">t_{1}\dots t_{4}</annotation><annotation encoding="application/x-llamapun" id="A6.F13.8.m4.1e">italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT … italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT</annotation></semantics></math> represent the four tokens/words between the verb.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A6.F14">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F14.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F14.sf1.g1" src="./Mission_ Impossible Language Models_files/x35.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>300 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F14.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F14.sf2.g1" src="./Mission_ Impossible Language Models_files/x36.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>600 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F14.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F14.sf3.g1" src="./Mission_ Impossible Language Models_files/x37.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>900 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F14.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F14.sf4.g1" src="./Mission_ Impossible Language Models_files/x38.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>1200 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F14.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F14.sf5.g1" src="./Mission_ Impossible Language Models_files/x39.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>1500 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F14.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F14.sf6.g1" src="./Mission_ Impossible Language Models_files/x40.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>3000 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Subject–verb agreement interchange intervention accuracies (IIA) for
<span class="ltx_text ltx_font_smallcaps" id="A6.F14.10.1">WordHop</span>, with confidence intervals across models trained on 5 different random seeds. Vertical axes denote the GPT-2 layer of the intervention, and horizontal axes denote the token position of the intervention. <math alttext="t_{d}" class="ltx_Math" display="inline" id="A6.F14.5.m1.1"><semantics id="A6.F14.5.m1.1b"><msub id="A6.F14.5.m1.1.1" xref="A6.F14.5.m1.1.1.cmml"><mi id="A6.F14.5.m1.1.1.2" xref="A6.F14.5.m1.1.1.2.cmml">t</mi><mi id="A6.F14.5.m1.1.1.3" xref="A6.F14.5.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F14.5.m1.1c"><apply id="A6.F14.5.m1.1.1.cmml" xref="A6.F14.5.m1.1.1"><csymbol cd="ambiguous" id="A6.F14.5.m1.1.1.1.cmml" xref="A6.F14.5.m1.1.1">subscript</csymbol><ci id="A6.F14.5.m1.1.1.2.cmml" xref="A6.F14.5.m1.1.1.2">𝑡</ci><ci id="A6.F14.5.m1.1.1.3.cmml" xref="A6.F14.5.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F14.5.m1.1d">t_{d}</annotation><annotation encoding="application/x-llamapun" id="A6.F14.5.m1.1e">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="t_{s}" class="ltx_Math" display="inline" id="A6.F14.6.m2.1"><semantics id="A6.F14.6.m2.1b"><msub id="A6.F14.6.m2.1.1" xref="A6.F14.6.m2.1.1.cmml"><mi id="A6.F14.6.m2.1.1.2" xref="A6.F14.6.m2.1.1.2.cmml">t</mi><mi id="A6.F14.6.m2.1.1.3" xref="A6.F14.6.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F14.6.m2.1c"><apply id="A6.F14.6.m2.1.1.cmml" xref="A6.F14.6.m2.1.1"><csymbol cd="ambiguous" id="A6.F14.6.m2.1.1.1.cmml" xref="A6.F14.6.m2.1.1">subscript</csymbol><ci id="A6.F14.6.m2.1.1.2.cmml" xref="A6.F14.6.m2.1.1.2">𝑡</ci><ci id="A6.F14.6.m2.1.1.3.cmml" xref="A6.F14.6.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F14.6.m2.1d">t_{s}</annotation><annotation encoding="application/x-llamapun" id="A6.F14.6.m2.1e">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="t_{v}" class="ltx_Math" display="inline" id="A6.F14.7.m3.1"><semantics id="A6.F14.7.m3.1b"><msub id="A6.F14.7.m3.1.1" xref="A6.F14.7.m3.1.1.cmml"><mi id="A6.F14.7.m3.1.1.2" xref="A6.F14.7.m3.1.1.2.cmml">t</mi><mi id="A6.F14.7.m3.1.1.3" xref="A6.F14.7.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F14.7.m3.1c"><apply id="A6.F14.7.m3.1.1.cmml" xref="A6.F14.7.m3.1.1"><csymbol cd="ambiguous" id="A6.F14.7.m3.1.1.1.cmml" xref="A6.F14.7.m3.1.1">subscript</csymbol><ci id="A6.F14.7.m3.1.1.2.cmml" xref="A6.F14.7.m3.1.1.2">𝑡</ci><ci id="A6.F14.7.m3.1.1.3.cmml" xref="A6.F14.7.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F14.7.m3.1d">t_{v}</annotation><annotation encoding="application/x-llamapun" id="A6.F14.7.m3.1e">italic_t start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> represent the tokens for the determiner, subject, and verb. <math alttext="t_{1}\dots t_{4}" class="ltx_Math" display="inline" id="A6.F14.8.m4.1"><semantics id="A6.F14.8.m4.1b"><mrow id="A6.F14.8.m4.1.1" xref="A6.F14.8.m4.1.1.cmml"><msub id="A6.F14.8.m4.1.1.2" xref="A6.F14.8.m4.1.1.2.cmml"><mi id="A6.F14.8.m4.1.1.2.2" xref="A6.F14.8.m4.1.1.2.2.cmml">t</mi><mn id="A6.F14.8.m4.1.1.2.3" xref="A6.F14.8.m4.1.1.2.3.cmml">1</mn></msub><mo id="A6.F14.8.m4.1.1.1" xref="A6.F14.8.m4.1.1.1.cmml">⁢</mo><mi id="A6.F14.8.m4.1.1.3" mathvariant="normal" xref="A6.F14.8.m4.1.1.3.cmml">…</mi><mo id="A6.F14.8.m4.1.1.1b" xref="A6.F14.8.m4.1.1.1.cmml">⁢</mo><msub id="A6.F14.8.m4.1.1.4" xref="A6.F14.8.m4.1.1.4.cmml"><mi id="A6.F14.8.m4.1.1.4.2" xref="A6.F14.8.m4.1.1.4.2.cmml">t</mi><mn id="A6.F14.8.m4.1.1.4.3" xref="A6.F14.8.m4.1.1.4.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A6.F14.8.m4.1c"><apply id="A6.F14.8.m4.1.1.cmml" xref="A6.F14.8.m4.1.1"><times id="A6.F14.8.m4.1.1.1.cmml" xref="A6.F14.8.m4.1.1.1"></times><apply id="A6.F14.8.m4.1.1.2.cmml" xref="A6.F14.8.m4.1.1.2"><csymbol cd="ambiguous" id="A6.F14.8.m4.1.1.2.1.cmml" xref="A6.F14.8.m4.1.1.2">subscript</csymbol><ci id="A6.F14.8.m4.1.1.2.2.cmml" xref="A6.F14.8.m4.1.1.2.2">𝑡</ci><cn id="A6.F14.8.m4.1.1.2.3.cmml" type="integer" xref="A6.F14.8.m4.1.1.2.3">1</cn></apply><ci id="A6.F14.8.m4.1.1.3.cmml" xref="A6.F14.8.m4.1.1.3">…</ci><apply id="A6.F14.8.m4.1.1.4.cmml" xref="A6.F14.8.m4.1.1.4"><csymbol cd="ambiguous" id="A6.F14.8.m4.1.1.4.1.cmml" xref="A6.F14.8.m4.1.1.4">subscript</csymbol><ci id="A6.F14.8.m4.1.1.4.2.cmml" xref="A6.F14.8.m4.1.1.4.2">𝑡</ci><cn id="A6.F14.8.m4.1.1.4.3.cmml" type="integer" xref="A6.F14.8.m4.1.1.4.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F14.8.m4.1d">t_{1}\dots t_{4}</annotation><annotation encoding="application/x-llamapun" id="A6.F14.8.m4.1e">italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT … italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT</annotation></semantics></math> represent the four tokens/words between the verb.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A6.F15">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F15.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F15.sf1.g1" src="./Mission_ Impossible Language Models_files/x41.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>300 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F15.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F15.sf2.g1" src="./Mission_ Impossible Language Models_files/x42.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>600 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F15.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F15.sf3.g1" src="./Mission_ Impossible Language Models_files/x43.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>900 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F15.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F15.sf4.g1" src="./Mission_ Impossible Language Models_files/x44.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>1200 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F15.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F15.sf5.g1" src="./Mission_ Impossible Language Models_files/x45.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>1500 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F15.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="827" id="A6.F15.sf6.g1" src="./Mission_ Impossible Language Models_files/x46.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>3000 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Subject–verb agreement interchange intervention accuracies (IIA) for the <span class="ltx_text ltx_font_smallcaps" id="A6.F15.9.1">NoHop</span> model trained <em class="ltx_emph ltx_font_italic" id="A6.F15.10.2">without positional encodings</em>, with confidence intervals across models trained on 5 different random seeds. Vertical axes denote the GPT-2 layer of the intervention, and horizontal axes denote the token position of the intervention. <math alttext="t_{d}" class="ltx_Math" display="inline" id="A6.F15.4.m1.1"><semantics id="A6.F15.4.m1.1b"><msub id="A6.F15.4.m1.1.1" xref="A6.F15.4.m1.1.1.cmml"><mi id="A6.F15.4.m1.1.1.2" xref="A6.F15.4.m1.1.1.2.cmml">t</mi><mi id="A6.F15.4.m1.1.1.3" xref="A6.F15.4.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F15.4.m1.1c"><apply id="A6.F15.4.m1.1.1.cmml" xref="A6.F15.4.m1.1.1"><csymbol cd="ambiguous" id="A6.F15.4.m1.1.1.1.cmml" xref="A6.F15.4.m1.1.1">subscript</csymbol><ci id="A6.F15.4.m1.1.1.2.cmml" xref="A6.F15.4.m1.1.1.2">𝑡</ci><ci id="A6.F15.4.m1.1.1.3.cmml" xref="A6.F15.4.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F15.4.m1.1d">t_{d}</annotation><annotation encoding="application/x-llamapun" id="A6.F15.4.m1.1e">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="t_{s}" class="ltx_Math" display="inline" id="A6.F15.5.m2.1"><semantics id="A6.F15.5.m2.1b"><msub id="A6.F15.5.m2.1.1" xref="A6.F15.5.m2.1.1.cmml"><mi id="A6.F15.5.m2.1.1.2" xref="A6.F15.5.m2.1.1.2.cmml">t</mi><mi id="A6.F15.5.m2.1.1.3" xref="A6.F15.5.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F15.5.m2.1c"><apply id="A6.F15.5.m2.1.1.cmml" xref="A6.F15.5.m2.1.1"><csymbol cd="ambiguous" id="A6.F15.5.m2.1.1.1.cmml" xref="A6.F15.5.m2.1.1">subscript</csymbol><ci id="A6.F15.5.m2.1.1.2.cmml" xref="A6.F15.5.m2.1.1.2">𝑡</ci><ci id="A6.F15.5.m2.1.1.3.cmml" xref="A6.F15.5.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F15.5.m2.1d">t_{s}</annotation><annotation encoding="application/x-llamapun" id="A6.F15.5.m2.1e">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="t_{v}" class="ltx_Math" display="inline" id="A6.F15.6.m3.1"><semantics id="A6.F15.6.m3.1b"><msub id="A6.F15.6.m3.1.1" xref="A6.F15.6.m3.1.1.cmml"><mi id="A6.F15.6.m3.1.1.2" xref="A6.F15.6.m3.1.1.2.cmml">t</mi><mi id="A6.F15.6.m3.1.1.3" xref="A6.F15.6.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F15.6.m3.1c"><apply id="A6.F15.6.m3.1.1.cmml" xref="A6.F15.6.m3.1.1"><csymbol cd="ambiguous" id="A6.F15.6.m3.1.1.1.cmml" xref="A6.F15.6.m3.1.1">subscript</csymbol><ci id="A6.F15.6.m3.1.1.2.cmml" xref="A6.F15.6.m3.1.1.2">𝑡</ci><ci id="A6.F15.6.m3.1.1.3.cmml" xref="A6.F15.6.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F15.6.m3.1d">t_{v}</annotation><annotation encoding="application/x-llamapun" id="A6.F15.6.m3.1e">italic_t start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> represent the tokens for the determiner, subject, and verb, respectively.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A6.F16">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F16.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F16.sf1.g1" src="./Mission_ Impossible Language Models_files/x47.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>300 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F16.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F16.sf2.g1" src="./Mission_ Impossible Language Models_files/x48.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>600 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F16.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F16.sf3.g1" src="./Mission_ Impossible Language Models_files/x49.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>900 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F16.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F16.sf4.g1" src="./Mission_ Impossible Language Models_files/x50.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>1200 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F16.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F16.sf5.g1" src="./Mission_ Impossible Language Models_files/x51.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>1500 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F16.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F16.sf6.g1" src="./Mission_ Impossible Language Models_files/x52.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>3000 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>Subject–verb agreement interchange intervention accuracies (IIA) for the <span class="ltx_text ltx_font_smallcaps" id="A6.F16.11.1">TokenHop</span> model trained <em class="ltx_emph ltx_font_italic" id="A6.F16.12.2">without positional encodings</em>, with confidence intervals across models trained on 5 different random seeds. Vertical axes denote the GPT-2 layer of the intervention, and horizontal axes denote the token position of the intervention. <math alttext="t_{d}" class="ltx_Math" display="inline" id="A6.F16.5.m1.1"><semantics id="A6.F16.5.m1.1b"><msub id="A6.F16.5.m1.1.1" xref="A6.F16.5.m1.1.1.cmml"><mi id="A6.F16.5.m1.1.1.2" xref="A6.F16.5.m1.1.1.2.cmml">t</mi><mi id="A6.F16.5.m1.1.1.3" xref="A6.F16.5.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F16.5.m1.1c"><apply id="A6.F16.5.m1.1.1.cmml" xref="A6.F16.5.m1.1.1"><csymbol cd="ambiguous" id="A6.F16.5.m1.1.1.1.cmml" xref="A6.F16.5.m1.1.1">subscript</csymbol><ci id="A6.F16.5.m1.1.1.2.cmml" xref="A6.F16.5.m1.1.1.2">𝑡</ci><ci id="A6.F16.5.m1.1.1.3.cmml" xref="A6.F16.5.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F16.5.m1.1d">t_{d}</annotation><annotation encoding="application/x-llamapun" id="A6.F16.5.m1.1e">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="t_{s}" class="ltx_Math" display="inline" id="A6.F16.6.m2.1"><semantics id="A6.F16.6.m2.1b"><msub id="A6.F16.6.m2.1.1" xref="A6.F16.6.m2.1.1.cmml"><mi id="A6.F16.6.m2.1.1.2" xref="A6.F16.6.m2.1.1.2.cmml">t</mi><mi id="A6.F16.6.m2.1.1.3" xref="A6.F16.6.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F16.6.m2.1c"><apply id="A6.F16.6.m2.1.1.cmml" xref="A6.F16.6.m2.1.1"><csymbol cd="ambiguous" id="A6.F16.6.m2.1.1.1.cmml" xref="A6.F16.6.m2.1.1">subscript</csymbol><ci id="A6.F16.6.m2.1.1.2.cmml" xref="A6.F16.6.m2.1.1.2">𝑡</ci><ci id="A6.F16.6.m2.1.1.3.cmml" xref="A6.F16.6.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F16.6.m2.1d">t_{s}</annotation><annotation encoding="application/x-llamapun" id="A6.F16.6.m2.1e">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="t_{v}" class="ltx_Math" display="inline" id="A6.F16.7.m3.1"><semantics id="A6.F16.7.m3.1b"><msub id="A6.F16.7.m3.1.1" xref="A6.F16.7.m3.1.1.cmml"><mi id="A6.F16.7.m3.1.1.2" xref="A6.F16.7.m3.1.1.2.cmml">t</mi><mi id="A6.F16.7.m3.1.1.3" xref="A6.F16.7.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F16.7.m3.1c"><apply id="A6.F16.7.m3.1.1.cmml" xref="A6.F16.7.m3.1.1"><csymbol cd="ambiguous" id="A6.F16.7.m3.1.1.1.cmml" xref="A6.F16.7.m3.1.1">subscript</csymbol><ci id="A6.F16.7.m3.1.1.2.cmml" xref="A6.F16.7.m3.1.1.2">𝑡</ci><ci id="A6.F16.7.m3.1.1.3.cmml" xref="A6.F16.7.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F16.7.m3.1d">t_{v}</annotation><annotation encoding="application/x-llamapun" id="A6.F16.7.m3.1e">italic_t start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> represent the tokens for the determiner, subject, and verb. <math alttext="t_{1}\dots t_{4}" class="ltx_Math" display="inline" id="A6.F16.8.m4.1"><semantics id="A6.F16.8.m4.1b"><mrow id="A6.F16.8.m4.1.1" xref="A6.F16.8.m4.1.1.cmml"><msub id="A6.F16.8.m4.1.1.2" xref="A6.F16.8.m4.1.1.2.cmml"><mi id="A6.F16.8.m4.1.1.2.2" xref="A6.F16.8.m4.1.1.2.2.cmml">t</mi><mn id="A6.F16.8.m4.1.1.2.3" xref="A6.F16.8.m4.1.1.2.3.cmml">1</mn></msub><mo id="A6.F16.8.m4.1.1.1" xref="A6.F16.8.m4.1.1.1.cmml">⁢</mo><mi id="A6.F16.8.m4.1.1.3" mathvariant="normal" xref="A6.F16.8.m4.1.1.3.cmml">…</mi><mo id="A6.F16.8.m4.1.1.1b" xref="A6.F16.8.m4.1.1.1.cmml">⁢</mo><msub id="A6.F16.8.m4.1.1.4" xref="A6.F16.8.m4.1.1.4.cmml"><mi id="A6.F16.8.m4.1.1.4.2" xref="A6.F16.8.m4.1.1.4.2.cmml">t</mi><mn id="A6.F16.8.m4.1.1.4.3" xref="A6.F16.8.m4.1.1.4.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A6.F16.8.m4.1c"><apply id="A6.F16.8.m4.1.1.cmml" xref="A6.F16.8.m4.1.1"><times id="A6.F16.8.m4.1.1.1.cmml" xref="A6.F16.8.m4.1.1.1"></times><apply id="A6.F16.8.m4.1.1.2.cmml" xref="A6.F16.8.m4.1.1.2"><csymbol cd="ambiguous" id="A6.F16.8.m4.1.1.2.1.cmml" xref="A6.F16.8.m4.1.1.2">subscript</csymbol><ci id="A6.F16.8.m4.1.1.2.2.cmml" xref="A6.F16.8.m4.1.1.2.2">𝑡</ci><cn id="A6.F16.8.m4.1.1.2.3.cmml" type="integer" xref="A6.F16.8.m4.1.1.2.3">1</cn></apply><ci id="A6.F16.8.m4.1.1.3.cmml" xref="A6.F16.8.m4.1.1.3">…</ci><apply id="A6.F16.8.m4.1.1.4.cmml" xref="A6.F16.8.m4.1.1.4"><csymbol cd="ambiguous" id="A6.F16.8.m4.1.1.4.1.cmml" xref="A6.F16.8.m4.1.1.4">subscript</csymbol><ci id="A6.F16.8.m4.1.1.4.2.cmml" xref="A6.F16.8.m4.1.1.4.2">𝑡</ci><cn id="A6.F16.8.m4.1.1.4.3.cmml" type="integer" xref="A6.F16.8.m4.1.1.4.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F16.8.m4.1d">t_{1}\dots t_{4}</annotation><annotation encoding="application/x-llamapun" id="A6.F16.8.m4.1e">italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT … italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT</annotation></semantics></math> represent the four tokens/words between the verb.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A6.F17">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F17.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F17.sf1.g1" src="./Mission_ Impossible Language Models_files/x53.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>300 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F17.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F17.sf2.g1" src="./Mission_ Impossible Language Models_files/x54.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>600 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F17.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F17.sf3.g1" src="./Mission_ Impossible Language Models_files/x55.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>900 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F17.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F17.sf4.g1" src="./Mission_ Impossible Language Models_files/x56.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>1200 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F17.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F17.sf5.g1" src="./Mission_ Impossible Language Models_files/x57.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>1500 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F17.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="441" id="A6.F17.sf6.g1" src="./Mission_ Impossible Language Models_files/x58.png" width="831">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>3000 Training Steps.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Subject–verb agreement interchange intervention accuracies (IIA) for the <span class="ltx_text ltx_font_smallcaps" id="A6.F17.11.1">WordHop</span> model trained <em class="ltx_emph ltx_font_italic" id="A6.F17.12.2">without positional encodings</em>, with confidence intervals across models trained on 5 different random seeds. Vertical axes denote the GPT-2 layer of the intervention, and horizontal axes denote the token position of the intervention. <math alttext="t_{d}" class="ltx_Math" display="inline" id="A6.F17.5.m1.1"><semantics id="A6.F17.5.m1.1b"><msub id="A6.F17.5.m1.1.1" xref="A6.F17.5.m1.1.1.cmml"><mi id="A6.F17.5.m1.1.1.2" xref="A6.F17.5.m1.1.1.2.cmml">t</mi><mi id="A6.F17.5.m1.1.1.3" xref="A6.F17.5.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F17.5.m1.1c"><apply id="A6.F17.5.m1.1.1.cmml" xref="A6.F17.5.m1.1.1"><csymbol cd="ambiguous" id="A6.F17.5.m1.1.1.1.cmml" xref="A6.F17.5.m1.1.1">subscript</csymbol><ci id="A6.F17.5.m1.1.1.2.cmml" xref="A6.F17.5.m1.1.1.2">𝑡</ci><ci id="A6.F17.5.m1.1.1.3.cmml" xref="A6.F17.5.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F17.5.m1.1d">t_{d}</annotation><annotation encoding="application/x-llamapun" id="A6.F17.5.m1.1e">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="t_{s}" class="ltx_Math" display="inline" id="A6.F17.6.m2.1"><semantics id="A6.F17.6.m2.1b"><msub id="A6.F17.6.m2.1.1" xref="A6.F17.6.m2.1.1.cmml"><mi id="A6.F17.6.m2.1.1.2" xref="A6.F17.6.m2.1.1.2.cmml">t</mi><mi id="A6.F17.6.m2.1.1.3" xref="A6.F17.6.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F17.6.m2.1c"><apply id="A6.F17.6.m2.1.1.cmml" xref="A6.F17.6.m2.1.1"><csymbol cd="ambiguous" id="A6.F17.6.m2.1.1.1.cmml" xref="A6.F17.6.m2.1.1">subscript</csymbol><ci id="A6.F17.6.m2.1.1.2.cmml" xref="A6.F17.6.m2.1.1.2">𝑡</ci><ci id="A6.F17.6.m2.1.1.3.cmml" xref="A6.F17.6.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F17.6.m2.1d">t_{s}</annotation><annotation encoding="application/x-llamapun" id="A6.F17.6.m2.1e">italic_t start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="t_{v}" class="ltx_Math" display="inline" id="A6.F17.7.m3.1"><semantics id="A6.F17.7.m3.1b"><msub id="A6.F17.7.m3.1.1" xref="A6.F17.7.m3.1.1.cmml"><mi id="A6.F17.7.m3.1.1.2" xref="A6.F17.7.m3.1.1.2.cmml">t</mi><mi id="A6.F17.7.m3.1.1.3" xref="A6.F17.7.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="A6.F17.7.m3.1c"><apply id="A6.F17.7.m3.1.1.cmml" xref="A6.F17.7.m3.1.1"><csymbol cd="ambiguous" id="A6.F17.7.m3.1.1.1.cmml" xref="A6.F17.7.m3.1.1">subscript</csymbol><ci id="A6.F17.7.m3.1.1.2.cmml" xref="A6.F17.7.m3.1.1.2">𝑡</ci><ci id="A6.F17.7.m3.1.1.3.cmml" xref="A6.F17.7.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F17.7.m3.1d">t_{v}</annotation><annotation encoding="application/x-llamapun" id="A6.F17.7.m3.1e">italic_t start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math> represent the tokens for the determiner, subject, and verb. <math alttext="t_{1}\dots t_{4}" class="ltx_Math" display="inline" id="A6.F17.8.m4.1"><semantics id="A6.F17.8.m4.1b"><mrow id="A6.F17.8.m4.1.1" xref="A6.F17.8.m4.1.1.cmml"><msub id="A6.F17.8.m4.1.1.2" xref="A6.F17.8.m4.1.1.2.cmml"><mi id="A6.F17.8.m4.1.1.2.2" xref="A6.F17.8.m4.1.1.2.2.cmml">t</mi><mn id="A6.F17.8.m4.1.1.2.3" xref="A6.F17.8.m4.1.1.2.3.cmml">1</mn></msub><mo id="A6.F17.8.m4.1.1.1" xref="A6.F17.8.m4.1.1.1.cmml">⁢</mo><mi id="A6.F17.8.m4.1.1.3" mathvariant="normal" xref="A6.F17.8.m4.1.1.3.cmml">…</mi><mo id="A6.F17.8.m4.1.1.1b" xref="A6.F17.8.m4.1.1.1.cmml">⁢</mo><msub id="A6.F17.8.m4.1.1.4" xref="A6.F17.8.m4.1.1.4.cmml"><mi id="A6.F17.8.m4.1.1.4.2" xref="A6.F17.8.m4.1.1.4.2.cmml">t</mi><mn id="A6.F17.8.m4.1.1.4.3" xref="A6.F17.8.m4.1.1.4.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A6.F17.8.m4.1c"><apply id="A6.F17.8.m4.1.1.cmml" xref="A6.F17.8.m4.1.1"><times id="A6.F17.8.m4.1.1.1.cmml" xref="A6.F17.8.m4.1.1.1"></times><apply id="A6.F17.8.m4.1.1.2.cmml" xref="A6.F17.8.m4.1.1.2"><csymbol cd="ambiguous" id="A6.F17.8.m4.1.1.2.1.cmml" xref="A6.F17.8.m4.1.1.2">subscript</csymbol><ci id="A6.F17.8.m4.1.1.2.2.cmml" xref="A6.F17.8.m4.1.1.2.2">𝑡</ci><cn id="A6.F17.8.m4.1.1.2.3.cmml" type="integer" xref="A6.F17.8.m4.1.1.2.3">1</cn></apply><ci id="A6.F17.8.m4.1.1.3.cmml" xref="A6.F17.8.m4.1.1.3">…</ci><apply id="A6.F17.8.m4.1.1.4.cmml" xref="A6.F17.8.m4.1.1.4"><csymbol cd="ambiguous" id="A6.F17.8.m4.1.1.4.1.cmml" xref="A6.F17.8.m4.1.1.4">subscript</csymbol><ci id="A6.F17.8.m4.1.1.4.2.cmml" xref="A6.F17.8.m4.1.1.4.2">𝑡</ci><cn id="A6.F17.8.m4.1.1.4.3.cmml" type="integer" xref="A6.F17.8.m4.1.1.4.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.F17.8.m4.1d">t_{1}\dots t_{4}</annotation><annotation encoding="application/x-llamapun" id="A6.F17.8.m4.1e">italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT … italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT</annotation></semantics></math> represent the four tokens/words between the verb.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>@charset "UTF-8";
/*!
 * Pico.css v1.5.6 (https://picocss.com)
 * Copyright 2019-2022 - Licensed under MIT
 */
/**
 * Theme: default
 */
#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 0.25rem;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 1rem;
  --typography-spacing-vertical: 1.5rem;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 0.75rem;
  --form-element-spacing-horizontal: 1rem;
  --nav-element-spacing-vertical: 1rem;
  --nav-element-spacing-horizontal: 0.5rem;
  --nav-link-spacing-vertical: 0.5rem;
  --nav-link-spacing-horizontal: 0.5rem;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(0.25rem);
}
@media (min-width: 576px) {
  #mount {
    --font-size: 17px;
  }
}
@media (min-width: 768px) {
  #mount {
    --font-size: 18px;
  }
}
@media (min-width: 992px) {
  #mount {
    --font-size: 19px;
  }
}
@media (min-width: 1200px) {
  #mount {
    --font-size: 20px;
  }
}

@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
  }
}
@media (min-width: 768px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3);
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3.5);
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 4);
  }
}

@media (min-width: 576px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}
@media (min-width: 992px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.75);
  }
}
@media (min-width: 1200px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 2);
  }
}

dialog > article {
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
}
@media (min-width: 576px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 3);
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}

a {
  --text-decoration: none;
}
a.secondary,
a.contrast {
  --text-decoration: underline;
}

small {
  --font-size: 0.875em;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  --font-weight: 700;
}

h1 {
  --font-size: 2rem;
  --typography-spacing-vertical: 3rem;
}

h2 {
  --font-size: 1.75rem;
  --typography-spacing-vertical: 2.625rem;
}

h3 {
  --font-size: 1.5rem;
  --typography-spacing-vertical: 2.25rem;
}

h4 {
  --font-size: 1.25rem;
  --typography-spacing-vertical: 1.874rem;
}

h5 {
  --font-size: 1.125rem;
  --typography-spacing-vertical: 1.6875rem;
}

[type="checkbox"],
[type="radio"] {
  --border-width: 2px;
}

[type="checkbox"][role="switch"] {
  --border-width: 3px;
}

thead th,
thead td,
tfoot th,
tfoot td {
  --border-width: 3px;
}

:not(thead, tfoot) > * > td {
  --font-size: 0.875em;
}

pre,
code,
kbd,
samp {
  --font-family: "Menlo", "Consolas", "Roboto Mono", "Ubuntu Monospace",
    "Noto Mono", "Oxygen Mono", "Liberation Mono", monospace,
    "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
}

kbd {
  --font-weight: bolder;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --background-color: #fff;
  --background-light-green: #F5F7F9;
  --color: hsl(205deg, 20%, 32%);
  --h1-color: hsl(205deg, 30%, 15%);
  --h2-color: #24333e;
  --h3-color: hsl(205deg, 25%, 23%);
  --h4-color: #374956;
  --h5-color: hsl(205deg, 20%, 32%);
  --h6-color: #4d606d;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: hsl(205deg, 20%, 94%);
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 90%, 32%);
  --primary-focus: rgba(16, 149, 193, 0.125);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 20%, 32%);
  --secondary-focus: rgba(89, 107, 120, 0.125);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 30%, 15%);
  --contrast-hover: #000;
  --contrast-focus: rgba(89, 107, 120, 0.125);
  --contrast-inverse: #fff;
  --mark-background-color: #fff2ca;
  --mark-color: #543a26;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: transparent;
  --form-element-border-color: hsl(205deg, 14%, 68%);
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: transparent;
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 18%, 86%);
  --form-element-disabled-border-color: hsl(205deg, 14%, 68%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #c62828;
  --form-element-invalid-active-border-color: #d32f2f;
  --form-element-invalid-focus-color: rgba(211, 47, 47, 0.125);
  --form-element-valid-border-color: #388e3c;
  --form-element-valid-active-border-color: #43a047;
  --form-element-valid-focus-color: rgba(67, 160, 71, 0.125);
  --switch-background-color: hsl(205deg, 16%, 77%);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: hsl(205deg, 18%, 86%);
  --range-active-border-color: hsl(205deg, 16%, 77%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: #f6f8f9;
  --code-background-color: hsl(205deg, 20%, 94%);
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 40%, 50%);
  --code-property-color: hsl(185deg, 40%, 40%);
  --code-value-color: hsl(40deg, 20%, 50%);
  --code-comment-color: hsl(205deg, 14%, 68%);
  --accordion-border-color: var(--muted-border-color);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: var(--background-color);
  --card-border-color: var(--muted-border-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(27, 40, 50, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(27, 40, 50, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(27, 40, 50, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(27, 40, 50, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(27, 40, 50, 0.04302),
    0.5rem 1rem 6rem rgba(27, 40, 50, 0.06),
    0 0 0 0.0625rem rgba(27, 40, 50, 0.015);
  --card-sectionning-background-color: #fbfbfc;
  --dropdown-background-color: #fbfbfc;
  --dropdown-border-color: #e1e6eb;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: hsl(205deg, 20%, 94%);
  --modal-overlay-background-color: rgba(213, 220, 226, 0.7);
  --progress-background-color: hsl(205deg, 18%, 86%);
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(198, 40, 40)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(56, 142, 60)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  --float-ball-more-button-border-color: #F6F6F6;
  --float-ball-more-button-background-color: #FFFFFF;
  --float-ball-more-button-svg-color: #6C6F73;
  color-scheme: light;
  --service-bg-hover:#F7FAFF;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --background-color: #11191f;
    --float-ball-more-button-background-color: #191919;
    --background-light-green: #141e26;
    --color: hsl(205deg, 16%, 77%);
    --h1-color: hsl(205deg, 20%, 94%);
    --h2-color: #e1e6eb;
    --h3-color: hsl(205deg, 18%, 86%);
    --h4-color: #c8d1d8;
    --h5-color: hsl(205deg, 16%, 77%);
    --h6-color: #afbbc4;
    --muted-color: hsl(205deg, 10%, 50%);
    --muted-border-color: #1f2d38;
    --primary: hsl(195deg, 85%, 41%);
    --primary-hover: hsl(195deg, 80%, 50%);
    --primary-focus: rgba(16, 149, 193, 0.25);
    --primary-inverse: #fff;
    --secondary: hsl(205deg, 15%, 41%);
    --secondary-hover: hsl(205deg, 10%, 50%);
    --secondary-focus: rgba(115, 130, 140, 0.25);
    --secondary-inverse: #fff;
    --contrast: hsl(205deg, 20%, 94%);
    --contrast-hover: #fff;
    --contrast-focus: rgba(115, 130, 140, 0.25);
    --contrast-inverse: #000;
    --mark-background-color: #d1c284;
    --mark-color: #11191f;
    --ins-color: #388e3c;
    --del-color: #c62828;
    --blockquote-border-color: var(--muted-border-color);
    --blockquote-footer-color: var(--muted-color);
    --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --form-element-background-color: #11191f;
    --form-element-border-color: #374956;
    --form-element-color: var(--color);
    --form-element-placeholder-color: var(--muted-color);
    --form-element-active-background-color: var(
      --form-element-background-color
    );
    --form-element-active-border-color: var(--primary);
    --form-element-focus-color: var(--primary-focus);
    --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
    --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
    --form-element-disabled-opacity: 0.5;
    --form-element-invalid-border-color: #b71c1c;
    --form-element-invalid-active-border-color: #c62828;
    --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
    --form-element-valid-border-color: #2e7d32;
    --form-element-valid-active-border-color: #388e3c;
    --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
    --switch-background-color: #374956;
    --switch-color: var(--primary-inverse);
    --switch-checked-background-color: var(--primary);
    --range-border-color: #24333e;
    --range-active-border-color: hsl(205deg, 25%, 23%);
    --range-thumb-border-color: var(--background-color);
    --range-thumb-color: var(--secondary);
    --range-thumb-hover-color: var(--secondary-hover);
    --range-thumb-active-color: var(--primary);
    --table-border-color: var(--muted-border-color);
    --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
    --code-background-color: #18232c;
    --code-color: var(--muted-color);
    --code-kbd-background-color: var(--contrast);
    --code-kbd-color: var(--contrast-inverse);
    --code-tag-color: hsl(330deg, 30%, 50%);
    --code-property-color: hsl(185deg, 30%, 50%);
    --code-value-color: hsl(40deg, 10%, 50%);
    --code-comment-color: #4d606d;
    --accordion-border-color: var(--muted-border-color);
    --accordion-active-summary-color: var(--primary);
    --accordion-close-summary-color: var(--color);
    --accordion-open-summary-color: var(--muted-color);
    --card-background-color: #141e26;
    --card-border-color: var(--card-background-color);
    --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
      0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
      0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
      0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
      0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
      0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
    --card-sectionning-background-color: #18232c;
    --dropdown-background-color: hsl(205deg, 30%, 15%);
    --dropdown-border-color: #24333e;
    --dropdown-box-shadow: var(--card-box-shadow);
    --dropdown-color: var(--color);
    --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
    --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
    --progress-background-color: #24333e;
    --progress-color: var(--primary);
    --loading-spinner-opacity: 0.5;
    --tooltip-background-color: var(--contrast);
    --tooltip-color: var(--contrast-inverse);
    --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
    --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
    --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
    --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
    --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
    --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
    color-scheme: dark;
    --service-bg-hover:#22292F;
  }
}
[data-theme="dark"] {
  --background-color: #11191f;
  --float-ball-more-button-background-color: #191919;
  --background-light-green: #141e26;
  --color: hsl(205deg, 16%, 77%);
  --h1-color: hsl(205deg, 20%, 94%);
  --h2-color: #e1e6eb;
  --h3-color: hsl(205deg, 18%, 86%);
  --h4-color: #c8d1d8;
  --h5-color: hsl(205deg, 16%, 77%);
  --h6-color: #afbbc4;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: #1f2d38;
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 80%, 50%);
  --primary-focus: rgba(16, 149, 193, 0.25);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 10%, 50%);
  --secondary-focus: rgba(115, 130, 140, 0.25);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 20%, 94%);
  --contrast-hover: #fff;
  --contrast-focus: rgba(115, 130, 140, 0.25);
  --contrast-inverse: #000;
  --mark-background-color: #d1c284;
  --mark-color: #11191f;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: #11191f;
  --form-element-border-color: #374956;
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: var(--form-element-background-color);
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
  --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #b71c1c;
  --form-element-invalid-active-border-color: #c62828;
  --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
  --form-element-valid-border-color: #2e7d32;
  --form-element-valid-active-border-color: #388e3c;
  --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
  --switch-background-color: #374956;
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: #24333e;
  --range-active-border-color: hsl(205deg, 25%, 23%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
  --code-background-color: #18232c;
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 30%, 50%);
  --code-property-color: hsl(185deg, 30%, 50%);
  --code-value-color: hsl(40deg, 10%, 50%);
  --code-comment-color: #4d606d;
  --accordion-border-color: var(--muted-border-color);
  --accordion-active-summary-color: var(--primary);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: #141e26;
  --card-border-color: var(--card-background-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
    0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
  --card-sectionning-background-color: #18232c;
  --dropdown-background-color: hsl(205deg, 30%, 15%);
  --dropdown-border-color: #24333e;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
  --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
  --progress-background-color: #24333e;
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  color-scheme: dark;
}

progress,
[type="checkbox"],
[type="radio"],
[type="range"] {
  accent-color: var(--primary);
}

/**
 * Document
 * Content-box & Responsive typography
 */
*,
*::before,
*::after {
  box-sizing: border-box;
  background-repeat: no-repeat;
}

::before,
::after {
  text-decoration: inherit;
  vertical-align: inherit;
}

:where(#mount) {
  -webkit-tap-highlight-color: transparent;
  -webkit-text-size-adjust: 100%;
  -moz-text-size-adjust: 100%;
  text-size-adjust: 100%;
  background-color: var(--background-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  line-height: var(--line-height);
  font-family: var(--font-family);
  text-rendering: optimizeLegibility;
  overflow-wrap: break-word;
  cursor: default;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
}

/**
 * Sectioning
 * Container and responsive spacings for header, main, footer
 */
main {
  display: block;
}

#mount {
  width: 100%;
  margin: 0;
}
#mount > header,
#mount > main,
#mount > footer {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
}
@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    max-width: 510px;
    padding-right: 0;
    padding-left: 0;
  }
}
@media (min-width: 768px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    max-width: 700px;
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    max-width: 920px;
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    max-width: 1130px;
  }
}

/**
* Container
*/
.container,
.container-fluid {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding-right: var(--spacing);
  padding-left: var(--spacing);
}

@media (min-width: 576px) {
  .container {
    max-width: 510px;
    padding-right: 0;
    padding-left: 0;
  }
}
@media (min-width: 768px) {
  .container {
    max-width: 700px;
  }
}
@media (min-width: 992px) {
  .container {
    max-width: 920px;
  }
}
@media (min-width: 1200px) {
  .container {
    max-width: 1130px;
  }
}

/**
 * Section
 * Responsive spacings for section
 */
section {
  margin-bottom: var(--block-spacing-vertical);
}

/**
* Grid
* Minimal grid system with auto-layout columns
*/
.grid {
  grid-column-gap: var(--grid-spacing-horizontal);
  grid-row-gap: var(--grid-spacing-vertical);
  display: grid;
  grid-template-columns: 1fr;
  margin: 0;
}
@media (min-width: 992px) {
  .grid {
    grid-template-columns: repeat(auto-fit, minmax(0%, 1fr));
  }
}
.grid > * {
  min-width: 0;
}

/**
 * Horizontal scroller (<figure>)
 */
figure {
  display: block;
  margin: 0;
  padding: 0;
  overflow-x: auto;
}
figure figcaption {
  padding: calc(var(--spacing) * 0.5) 0;
  color: var(--muted-color);
}

/**
 * Typography
 */
b,
strong {
  font-weight: bolder;
}

sub,
sup {
  position: relative;
  font-size: 0.75em;
  line-height: 0;
  vertical-align: baseline;
}

sub {
  bottom: -0.25em;
}

sup {
  top: -0.5em;
}

address,
blockquote,
dl,
figure,
form,
ol,
p,
pre,
table,
ul {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: var(--font-size);
}

a,
[role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
a:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}
a:focus,
[role="link"]:focus {
  --background-color: var(--primary-focus);
}
a.secondary,
[role="link"].secondary {
  --color: var(--secondary);
}
a.secondary:is([aria-current], :hover, :active, :focus),
[role="link"].secondary:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}
a.secondary:focus,
[role="link"].secondary:focus {
  --background-color: var(--secondary-focus);
}
a.contrast,
[role="link"].contrast {
  --color: var(--contrast);
}
a.contrast:is([aria-current], :hover, :active, :focus),
[role="link"].contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}
a.contrast:focus,
[role="link"].contrast:focus {
  --background-color: var(--contrast-focus);
}

h1,
h2,
h3,
h4,
h5,
h6 {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  font-family: var(--font-family);
}

h1 {
  --color: var(--h1-color);
}

h2 {
  --color: var(--h2-color);
}

h3 {
  --color: var(--h3-color);
}

h4 {
  --color: var(--h4-color);
}

h5 {
  --color: var(--h5-color);
}

h6 {
  --color: var(--h6-color);
}

:where(address, blockquote, dl, figure, form, ol, p, pre, table, ul)
  ~ :is(h1, h2, h3, h4, h5, h6) {
  margin-top: var(--typography-spacing-vertical);
}

hgroup,
.headings {
  margin-bottom: var(--typography-spacing-vertical);
}
hgroup > *,
.headings > * {
  margin-bottom: 0;
}
hgroup > *:last-child,
.headings > *:last-child {
  --color: var(--muted-color);
  --font-weight: unset;
  font-size: 1rem;
  font-family: unset;
}

p {
  margin-bottom: var(--typography-spacing-vertical);
}

small {
  font-size: var(--font-size);
}

:where(dl, ol, ul) {
  padding-right: 0;
  padding-left: var(--spacing);
  -webkit-padding-start: var(--spacing);
  padding-inline-start: var(--spacing);
  -webkit-padding-end: 0;
  padding-inline-end: 0;
}
:where(dl, ol, ul) li {
  margin-bottom: calc(var(--typography-spacing-vertical) * 0.25);
}

:where(dl, ol, ul) :is(dl, ol, ul) {
  margin: 0;
  margin-top: calc(var(--typography-spacing-vertical) * 0.25);
}

ul li {
  list-style: square;
}

mark {
  padding: 0.125rem 0.25rem;
  background-color: var(--mark-background-color);
  color: var(--mark-color);
  vertical-align: baseline;
}

blockquote {
  display: block;
  margin: var(--typography-spacing-vertical) 0;
  padding: var(--spacing);
  border-right: none;
  border-left: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-start: 0.25rem solid var(--blockquote-border-color);
  border-inline-start: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-end: none;
  border-inline-end: none;
}
blockquote footer {
  margin-top: calc(var(--typography-spacing-vertical) * 0.5);
  color: var(--blockquote-footer-color);
}

abbr[title] {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}

ins {
  color: var(--ins-color);
  text-decoration: none;
}

del {
  color: var(--del-color);
}

::-moz-selection {
  background-color: var(--primary-focus);
}

::selection {
  background-color: var(--primary-focus);
}

/**
 * Embedded content
 */
:where(audio, canvas, iframe, img, svg, video) {
  vertical-align: middle;
}

audio,
video {
  display: inline-block;
}

audio:not([controls]) {
  display: none;
  height: 0;
}

:where(iframe) {
  border-style: none;
}

img {
  max-width: 100%;
  height: auto;
  border-style: none;
}

:where(svg:not([fill])) {
  fill: currentColor;
}

svg:not(#mount) {
  overflow: hidden;
}

/**
 * Button
 */
button {
  margin: 0;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

button,
[type="button"],
[type="reset"],
[type="submit"] {
  -webkit-appearance: button;
}

button {
  display: block;
  width: 100%;
  margin-bottom: var(--spacing);
}

[role="button"] {
  display: inline-block;
  text-decoration: none;
}

button,
input[type="submit"],
input[type="button"],
input[type="reset"],
[role="button"] {
  --background-color: var(--primary);
  --border-color: var(--primary);
  --color: var(--primary-inverse);
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
button:is([aria-current], :hover, :active, :focus),
input[type="submit"]:is([aria-current], :hover, :active, :focus),
input[type="button"]:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus),
[role="button"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--primary-hover);
  --border-color: var(--primary-hover);
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  --color: var(--primary-inverse);
}
button:focus,
input[type="submit"]:focus,
input[type="button"]:focus,
input[type="reset"]:focus,
[role="button"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--primary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary,
input[type="reset"] {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  cursor: pointer;
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:focus,
input[type="reset"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--secondary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast {
  --background-color: var(--contrast);
  --border-color: var(--contrast);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--contrast-hover);
  --border-color: var(--contrast-hover);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--contrast-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline,
input[type="reset"].outline {
  --background-color: transparent;
  --color: var(--primary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --background-color: transparent;
  --color: var(--primary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary,
input[type="reset"].outline {
  --color: var(--secondary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast {
  --color: var(--contrast);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}

:where(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  )[disabled],
:where(fieldset[disabled])
  :is(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  ),
a[role="button"]:not([href]) {
  opacity: 0.5;
  pointer-events: none;
}

/**
 * Form elements
 */
input,
optgroup,
select,
textarea {
  margin: 0;
  font-size: 1rem;
  line-height: var(--line-height);
  font-family: inherit;
  letter-spacing: inherit;
}

input {
  overflow: visible;
}

select {
  text-transform: none;
}

legend {
  max-width: 100%;
  padding: 0;
  color: inherit;
  white-space: normal;
}

textarea {
  overflow: auto;
}

[type="checkbox"],
[type="radio"] {
  padding: 0;
}

::-webkit-inner-spin-button,
::-webkit-outer-spin-button {
  height: auto;
}

[type="search"] {
  -webkit-appearance: textfield;
  outline-offset: -2px;
}

[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}

::-webkit-file-upload-button {
  -webkit-appearance: button;
  font: inherit;
}

::-moz-focus-inner {
  padding: 0;
  border-style: none;
}

:-moz-focusring {
  outline: none;
}

:-moz-ui-invalid {
  box-shadow: none;
}

::-ms-expand {
  display: none;
}

[type="file"],
[type="range"] {
  padding: 0;
  border-width: 0;
}

input:not([type="checkbox"], [type="radio"], [type="range"]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
}

fieldset {
  margin: 0;
  margin-bottom: var(--spacing);
  padding: 0;
  border: 0;
}

label,
fieldset legend {
  display: block;
  margin-bottom: calc(var(--spacing) * 0.25);
  font-weight: var(--form-label-font-weight, var(--font-weight));
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  width: 100%;
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]),
select,
textarea {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
}

input,
select,
textarea {
  --background-color: var(--form-element-background-color);
  --border-color: var(--form-element-border-color);
  --color: var(--form-element-color);
  --box-shadow: none;
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="checkbox"],
    [type="radio"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --background-color: var(--form-element-active-background-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="switch"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --border-color: var(--form-element-active-border-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="range"],
    [type="file"],
    [readonly]
  ):focus,
select:focus,
textarea:focus {
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}

input:not([type="submit"], [type="button"], [type="reset"])[disabled],
select[disabled],
textarea[disabled],
:where(fieldset[disabled])
  :is(
    input:not([type="submit"], [type="button"], [type="reset"]),
    select,
    textarea
  ) {
  --background-color: var(--form-element-disabled-background-color);
  --border-color: var(--form-element-disabled-border-color);
  opacity: var(--form-element-disabled-opacity);
  pointer-events: none;
}

:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid] {
  padding-right: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal) !important;
  padding-inline-start: var(--form-element-spacing-horizontal) !important;
  -webkit-padding-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-inline-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="false"] {
  background-image: var(--icon-valid);
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="true"] {
  background-image: var(--icon-invalid);
}
:where(input, select, textarea)[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(input, select, textarea)[aria-invalid="false"]:is(:active, :focus) {
  --border-color: var(--form-element-valid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-valid-focus-color) !important;
}
:where(input, select, textarea)[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}
:where(input, select, textarea)[aria-invalid="true"]:is(:active, :focus) {
  --border-color: var(--form-element-invalid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width)
    var(--form-element-invalid-focus-color) !important;
}

[dir="rtl"]
  :where(input, select, textarea):not([type="checkbox"], [type="radio"]):is(
    [aria-invalid],
    [aria-invalid="true"],
    [aria-invalid="false"]
  ) {
  background-position: center left 0.75rem;
}

input::placeholder,
input::-webkit-input-placeholder,
textarea::placeholder,
textarea::-webkit-input-placeholder,
select:invalid {
  color: var(--form-element-placeholder-color);
  opacity: 1;
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  margin-bottom: var(--spacing);
}

select::-ms-expand {
  border: 0;
  background-color: transparent;
}
select:not([multiple], [size]) {
  padding-right: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal);
  padding-inline-start: var(--form-element-spacing-horizontal);
  -webkit-padding-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-inline-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  background-image: var(--icon-chevron);
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}

[dir="rtl"] select:not([multiple], [size]) {
  background-position: center left 0.75rem;
}

:where(input, select, textarea) + small {
  display: block;
  width: 100%;
  margin-top: calc(var(--spacing) * -0.75);
  margin-bottom: var(--spacing);
  color: var(--muted-color);
}

label > :where(input, select, textarea) {
  margin-top: calc(var(--spacing) * 0.25);
}

/**
 * Form elements
 * Checkboxes & Radios
 */
[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

[type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
[type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
[type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
[type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
[type="checkbox"][role="switch"]:checked {
  background-image: none;
}
[type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

[type="checkbox"][aria-invalid="false"],
[type="checkbox"]:checked[aria-invalid="false"],
[type="radio"][aria-invalid="false"],
[type="radio"]:checked[aria-invalid="false"],
[type="checkbox"][role="switch"][aria-invalid="false"],
[type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
[type="checkbox"][aria-invalid="true"],
[type="checkbox"]:checked[aria-invalid="true"],
[type="radio"][aria-invalid="true"],
[type="radio"]:checked[aria-invalid="true"],
[type="checkbox"][role="switch"][aria-invalid="true"],
[type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

/**
 * Form elements
 * Alternatives input types (Not Checkboxes & Radios)
 */
[type="color"]::-webkit-color-swatch-wrapper {
  padding: 0;
}
[type="color"]::-moz-focus-inner {
  padding: 0;
}
[type="color"]::-webkit-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}
[type="color"]::-moz-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]):is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  --icon-position: 0.75rem;
  --icon-width: 1rem;
  padding-right: calc(var(--icon-width) + var(--icon-position));
  background-image: var(--icon-date);
  background-position: center right var(--icon-position);
  background-size: var(--icon-width) auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="time"] {
  background-image: var(--icon-time);
}

[type="date"]::-webkit-calendar-picker-indicator,
[type="datetime-local"]::-webkit-calendar-picker-indicator,
[type="month"]::-webkit-calendar-picker-indicator,
[type="time"]::-webkit-calendar-picker-indicator,
[type="week"]::-webkit-calendar-picker-indicator {
  width: var(--icon-width);
  margin-right: calc(var(--icon-width) * -1);
  margin-left: var(--icon-position);
  opacity: 0;
}

[dir="rtl"]
  :is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  text-align: right;
}

[type="file"] {
  --color: var(--muted-color);
  padding: calc(var(--form-element-spacing-vertical) * 0.5) 0;
  border: 0;
  border-radius: 0;
  background: none;
}
[type="file"]::file-selector-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::file-selector-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-webkit-file-upload-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-webkit-file-upload-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-ms-browse {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  margin-inline-start: 0;
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-ms-browse:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}

[type="range"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 100%;
  height: 1.25rem;
  background: none;
}
[type="range"]::-webkit-slider-runnable-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -webkit-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-moz-range-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -moz-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-ms-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -ms-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-webkit-slider-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-moz-range-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -moz-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-ms-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]:hover,
[type="range"]:focus {
  --range-border-color: var(--range-active-border-color);
  --range-thumb-color: var(--range-thumb-hover-color);
}
[type="range"]:active {
  --range-thumb-color: var(--range-thumb-active-color);
}
[type="range"]:active::-webkit-slider-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-moz-range-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-ms-thumb {
  transform: scale(1.25);
}

input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  -webkit-padding-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  padding-inline-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  border-radius: 5rem;
  background-image: var(--icon-search);
  background-position: center left 1.125rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  -webkit-padding-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  padding-inline-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  background-position: center left 1.125rem, center right 0.75rem;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="false"] {
  background-image: var(--icon-search), var(--icon-valid);
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="true"] {
  background-image: var(--icon-search), var(--icon-invalid);
}

[type="search"]::-webkit-search-cancel-button {
  -webkit-appearance: none;
  display: none;
}

[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  background-position: center right 1.125rem;
}
[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  background-position: center right 1.125rem, center left 0.75rem;
}

/**
 * Table
 */
:where(table) {
  width: 100%;
  border-collapse: collapse;
  border-spacing: 0;
  text-indent: 0;
}

th,
td {
  padding: calc(var(--spacing) / 2) var(--spacing);
  border-bottom: var(--border-width) solid var(--table-border-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  text-align: left;
  text-align: start;
}

tfoot th,
tfoot td {
  border-top: var(--border-width) solid var(--table-border-color);
  border-bottom: 0;
}

table[role="grid"] tbody tr:nth-child(odd) {
  background-color: var(--table-row-stripped-background-color);
}

/**
 * Code
 */
pre,
code,
kbd,
samp {
  font-size: 0.875em;
  font-family: var(--font-family);
}

pre {
  -ms-overflow-style: scrollbar;
  overflow: auto;
}

pre,
code,
kbd {
  border-radius: var(--border-radius);
  background: var(--code-background-color);
  color: var(--code-color);
  font-weight: var(--font-weight);
  line-height: initial;
}

code,
kbd {
  display: inline-block;
  padding: 0.375rem 0.5rem;
}

pre {
  display: block;
  margin-bottom: var(--spacing);
  overflow-x: auto;
}
pre > code {
  display: block;
  padding: var(--spacing);
  background: none;
  font-size: 14px;
  line-height: var(--line-height);
}

code b {
  color: var(--code-tag-color);
  font-weight: var(--font-weight);
}
code i {
  color: var(--code-property-color);
  font-style: normal;
}
code u {
  color: var(--code-value-color);
  text-decoration: none;
}
code em {
  color: var(--code-comment-color);
  font-style: normal;
}

kbd {
  background-color: var(--code-kbd-background-color);
  color: var(--code-kbd-color);
  vertical-align: baseline;
}

/**
 * Miscs
 */
hr {
  height: 0;
  border: 0;
  border-top: 1px solid var(--muted-border-color);
  color: inherit;
}

[hidden],
template {
  display: none !important;
}

canvas {
  display: inline-block;
}

/**
 * Accordion (<details>)
 */
details {
  display: block;
  margin-bottom: var(--spacing);
  padding-bottom: var(--spacing);
  border-bottom: var(--border-width) solid var(--accordion-border-color);
}
details summary {
  line-height: 1rem;
  list-style-type: none;
  cursor: pointer;
  transition: color var(--transition);
}
details summary:not([role]) {
  color: var(--accordion-close-summary-color);
}
details summary::-webkit-details-marker {
  display: none;
}
details summary::marker {
  display: none;
}
details summary::-moz-list-bullet {
  list-style-type: none;
}
details summary::after {
  display: block;
  width: 1rem;
  height: 1rem;
  -webkit-margin-start: calc(var(--spacing, 1rem) * 0.5);
  margin-inline-start: calc(var(--spacing, 1rem) * 0.5);
  float: right;
  transform: rotate(-90deg);
  background-image: var(--icon-chevron);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
  transition: transform var(--transition);
}
details summary:focus {
  outline: none;
}
details summary:focus:not([role="button"]) {
  color: var(--accordion-active-summary-color);
}
details summary[role="button"] {
  width: 100%;
  text-align: left;
}
details summary[role="button"]::after {
  height: calc(1rem * var(--line-height, 1.5));
  background-image: var(--icon-chevron-button);
}
details summary[role="button"]:not(.outline).contrast::after {
  background-image: var(--icon-chevron-button-inverse);
}
details[open] > summary {
  margin-bottom: calc(var(--spacing));
}
details[open] > summary:not([role]):not(:focus) {
  color: var(--accordion-open-summary-color);
}
details[open] > summary::after {
  transform: rotate(0);
}

[dir="rtl"] details summary {
  text-align: right;
}
[dir="rtl"] details summary::after {
  float: left;
  background-position: left center;
}

/**
 * Card (<article>)
 */
article {
  margin: var(--block-spacing-vertical) 0;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
  border-radius: var(--border-radius);
  background: var(--card-background-color);
  box-shadow: var(--card-box-shadow);
}
article > header,
article > footer {
  margin-right: calc(var(--block-spacing-horizontal) * -1);
  margin-left: calc(var(--block-spacing-horizontal) * -1);
  padding: calc(var(--block-spacing-vertical) * 0.66)
    var(--block-spacing-horizontal);
  background-color: var(--card-sectionning-background-color);
}
article > header {
  margin-top: calc(var(--block-spacing-vertical) * -1);
  margin-bottom: var(--block-spacing-vertical);
  border-bottom: var(--border-width) solid var(--card-border-color);
  border-top-right-radius: var(--border-radius);
  border-top-left-radius: var(--border-radius);
}
article > footer {
  margin-top: var(--block-spacing-vertical);
  margin-bottom: calc(var(--block-spacing-vertical) * -1);
  border-top: var(--border-width) solid var(--card-border-color);
  border-bottom-right-radius: var(--border-radius);
  border-bottom-left-radius: var(--border-radius);
}

/**
 * Modal (<dialog>)
 */
#mount {
  --scrollbar-width: 0px;
}

dialog {
  display: flex;
  z-index: 999;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  align-items: center;
  justify-content: center;
  width: inherit;
  min-width: 100%;
  height: inherit;
  min-height: 100%;
  padding: var(--spacing);
  border: 0;
  -webkit-backdrop-filter: var(--modal-overlay-backdrop-filter);
  backdrop-filter: var(--modal-overlay-backdrop-filter);
  background-color: var(--modal-overlay-background-color);
  color: var(--color);
}
dialog article {
  max-height: calc(100vh - var(--spacing) * 2);
  overflow: auto;
}
@media (min-width: 576px) {
  dialog article {
    max-width: 510px;
  }
}
@media (min-width: 768px) {
  dialog article {
    max-width: 700px;
  }
}
dialog article > header,
dialog article > footer {
  padding: calc(var(--block-spacing-vertical) * 0.5)
    var(--block-spacing-horizontal);
}
dialog article > header .close {
  margin: 0;
  margin-left: var(--spacing);
  float: right;
}
dialog article > footer {
  text-align: right;
}
dialog article > footer [role="button"] {
  margin-bottom: 0;
}
dialog article > footer [role="button"]:not(:first-of-type) {
  margin-left: calc(var(--spacing) * 0.5);
}
dialog article p:last-of-type {
  margin: 0;
}
dialog article .close {
  display: block;
  width: 1rem;
  height: 1rem;
  margin-top: calc(var(--block-spacing-vertical) * -0.5);
  margin-bottom: var(--typography-spacing-vertical);
  margin-left: auto;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}
dialog article .close:is([aria-current], :hover, :active, :focus) {
  opacity: 1;
}
dialog:not([open]),
dialog[open="false"] {
  display: none;
}

.modal-is-open {
  padding-right: var(--scrollbar-width, 0px);
  overflow: hidden;
  pointer-events: none;
}
.modal-is-open dialog {
  pointer-events: auto;
}

:where(.modal-is-opening, .modal-is-closing) dialog,
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-duration: 0.2s;
  animation-timing-function: ease-in-out;
  animation-fill-mode: both;
}
:where(.modal-is-opening, .modal-is-closing) dialog {
  animation-duration: 0.8s;
  animation-name: modal-overlay;
}
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-delay: 0.2s;
  animation-name: modal;
}

.modal-is-closing dialog,
.modal-is-closing dialog > article {
  animation-delay: 0s;
  animation-direction: reverse;
}

@keyframes modal-overlay {
  from {
    -webkit-backdrop-filter: none;
    backdrop-filter: none;
    background-color: transparent;
  }
}
@keyframes modal {
  from {
    transform: translateY(-100%);
    opacity: 0;
  }
}
/**
 * Nav
 */
:where(nav li)::before {
  float: left;
  content: "​";
}

nav,
nav ul {
  display: flex;
}

nav {
  justify-content: space-between;
}
nav ol,
nav ul {
  align-items: center;
  margin-bottom: 0;
  padding: 0;
  list-style: none;
}
nav ol:first-of-type,
nav ul:first-of-type {
  margin-left: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav ol:last-of-type,
nav ul:last-of-type {
  margin-right: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav li {
  display: inline-block;
  margin: 0;
  padding: var(--nav-element-spacing-vertical)
    var(--nav-element-spacing-horizontal);
}
nav li > * {
  --spacing: 0;
}
nav :where(a, [role="link"]) {
  display: inline-block;
  margin: calc(var(--nav-link-spacing-vertical) * -1)
    calc(var(--nav-link-spacing-horizontal) * -1);
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
  border-radius: var(--border-radius);
  text-decoration: none;
}
nav :where(a, [role="link"]):is([aria-current], :hover, :active, :focus) {
  text-decoration: none;
}
nav[aria-label="breadcrumb"] {
  align-items: center;
  justify-content: start;
}
nav[aria-label="breadcrumb"] ul li:not(:first-child) {
  -webkit-margin-start: var(--nav-link-spacing-horizontal);
  margin-inline-start: var(--nav-link-spacing-horizontal);
}
nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  position: absolute;
  width: calc(var(--nav-link-spacing-horizontal) * 2);
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) / 2);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) / 2);
  content: "/";
  color: var(--muted-color);
  text-align: center;
}
nav[aria-label="breadcrumb"] a[aria-current] {
  background-color: transparent;
  color: inherit;
  text-decoration: none;
  pointer-events: none;
}
nav [role="button"] {
  margin-right: inherit;
  margin-left: inherit;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}

aside nav,
aside ol,
aside ul,
aside li {
  display: block;
}
aside li {
  padding: calc(var(--nav-element-spacing-vertical) * 0.5)
    var(--nav-element-spacing-horizontal);
}
aside li a {
  display: block;
}
aside li [role="button"] {
  margin: inherit;
}

[dir="rtl"] nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  content: "\\";
}

/**
 * Progress
 */
progress {
  display: inline-block;
  vertical-align: baseline;
}

progress {
  -webkit-appearance: none;
  -moz-appearance: none;
  display: inline-block;
  appearance: none;
  width: 100%;
  height: 0.5rem;
  margin-bottom: calc(var(--spacing) * 0.5);
  overflow: hidden;
  border: 0;
  border-radius: var(--border-radius);
  background-color: var(--progress-background-color);
  color: var(--progress-color);
}
progress::-webkit-progress-bar {
  border-radius: var(--border-radius);
  background: none;
}
progress[value]::-webkit-progress-value {
  background-color: var(--progress-color);
}
progress::-moz-progress-bar {
  background-color: var(--progress-color);
}
@media (prefers-reduced-motion: no-preference) {
  progress:indeterminate {
    background: var(--progress-background-color)
      linear-gradient(
        to right,
        var(--progress-color) 30%,
        var(--progress-background-color) 30%
      )
      top left/150% 150% no-repeat;
    animation: progress-indeterminate 1s linear infinite;
  }
  progress:indeterminate[value]::-webkit-progress-value {
    background-color: transparent;
  }
  progress:indeterminate::-moz-progress-bar {
    background-color: transparent;
  }
}

@media (prefers-reduced-motion: no-preference) {
  [dir="rtl"] progress:indeterminate {
    animation-direction: reverse;
  }
}

@keyframes progress-indeterminate {
  0% {
    background-position: 200% 0;
  }
  100% {
    background-position: -200% 0;
  }
}
/**
 * Dropdown ([role="list"])
 */
details[role="list"],
li[role="list"] {
  position: relative;
}

details[role="list"] summary + ul,
li[role="list"] > ul {
  display: flex;
  z-index: 99;
  position: absolute;
  top: auto;
  right: 0;
  left: 0;
  flex-direction: column;
  margin: 0;
  padding: 0;
  border: var(--border-width) solid var(--dropdown-border-color);
  border-radius: var(--border-radius);
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  background-color: var(--dropdown-background-color);
  box-shadow: var(--card-box-shadow);
  color: var(--dropdown-color);
  white-space: nowrap;
}
details[role="list"] summary + ul li,
li[role="list"] > ul li {
  width: 100%;
  margin-bottom: 0;
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  list-style: none;
}
details[role="list"] summary + ul li:first-of-type,
li[role="list"] > ul li:first-of-type {
  margin-top: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li:last-of-type,
li[role="list"] > ul li:last-of-type {
  margin-bottom: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li a,
li[role="list"] > ul li a {
  display: block;
  margin: calc(var(--form-element-spacing-vertical) * -0.5)
    calc(var(--form-element-spacing-horizontal) * -1);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  overflow: hidden;
  color: var(--dropdown-color);
  text-decoration: none;
  text-overflow: ellipsis;
}
details[role="list"] summary + ul li a:hover,
li[role="list"] > ul li a:hover {
  background-color: var(--dropdown-hover-background-color);
}

details[role="list"] summary::after,
li[role="list"] > a::after {
  display: block;
  width: 1rem;
  height: calc(1rem * var(--line-height, 1.5));
  -webkit-margin-start: 0.5rem;
  margin-inline-start: 0.5rem;
  float: right;
  transform: rotate(0deg);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
}

details[role="list"] {
  padding: 0;
  border-bottom: none;
}
details[role="list"] summary {
  margin-bottom: 0;
}
details[role="list"] summary:not([role]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--form-element-border-color);
  border-radius: var(--border-radius);
  background-color: var(--form-element-background-color);
  color: var(--form-element-placeholder-color);
  line-height: inherit;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
details[role="list"] summary:not([role]):active,
details[role="list"] summary:not([role]):focus {
  border-color: var(--form-element-active-border-color);
  background-color: var(--form-element-active-background-color);
}
details[role="list"] summary:not([role]):focus {
  box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}
details[role="list"][open] summary {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
details[role="list"][open] summary::before {
  display: block;
  z-index: 1;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  background: none;
  content: "";
  cursor: default;
}

nav details[role="list"] summary,
nav li[role="list"] a {
  display: flex;
  direction: ltr;
}

nav details[role="list"] summary + ul,
nav li[role="list"] > ul {
  min-width: -moz-fit-content;
  min-width: fit-content;
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul li a,
nav li[role="list"] > ul li a {
  border-radius: 0;
}

nav details[role="list"] summary,
nav details[role="list"] summary:not([role]) {
  height: auto;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}
nav details[role="list"][open] summary {
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul {
  margin-top: var(--outline-width);
  -webkit-margin-start: 0;
  margin-inline-start: 0;
}
nav details[role="list"] summary[role="link"] {
  margin-bottom: calc(var(--nav-link-spacing-vertical) * -1);
  line-height: var(--line-height);
}
nav details[role="list"] summary[role="link"] + ul {
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) * -1);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) * -1);
}

li[role="list"]:hover > ul,
li[role="list"] a:active ~ ul,
li[role="list"] a:focus ~ ul {
  display: flex;
}
li[role="list"] > ul {
  display: none;
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
  margin-inline-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
}
li[role="list"] > a::after {
  background-image: var(--icon-chevron);
}

/**
 * Loading ([aria-busy=true])
 */
[aria-busy="true"] {
  cursor: progress;
}

[aria-busy="true"]:not(input, select, textarea)::before {
  display: inline-block;
  width: 1em;
  height: 1em;
  border: 0.1875em solid currentColor;
  border-radius: 1em;
  border-right-color: transparent;
  content: "";
  vertical-align: text-bottom;
  vertical-align: -0.125em;
  animation: spinner 0.75s linear infinite;
  opacity: var(--loading-spinner-opacity);
}
[aria-busy="true"]:not(input, select, textarea):not(:empty)::before {
  margin-right: calc(var(--spacing) * 0.5);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) * 0.5);
  margin-inline-end: calc(var(--spacing) * 0.5);
}
[aria-busy="true"]:not(input, select, textarea):empty {
  text-align: center;
}

button[aria-busy="true"],
input[type="submit"][aria-busy="true"],
input[type="button"][aria-busy="true"],
input[type="reset"][aria-busy="true"],
a[aria-busy="true"] {
  pointer-events: none;
}

@keyframes spinner {
  to {
    transform: rotate(360deg);
  }
}
/**
 * Tooltip ([data-tooltip])
 */
[data-tooltip] {
  position: relative;
}
[data-tooltip]:not(a, button, input) {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}
[data-tooltip][data-placement="top"]::before,
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::before,
[data-tooltip]::after {
  display: block;
  z-index: 99;
  position: absolute;
  bottom: 100%;
  left: 50%;
  padding: 0.25rem 0.5rem;
  overflow: hidden;
  transform: translate(-50%, -0.25rem);
  border-radius: var(--border-radius);
  background: var(--tooltip-background-color);
  content: attr(data-tooltip);
  color: var(--tooltip-color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: 0.875rem;
  text-decoration: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  opacity: 0;
  pointer-events: none;
}
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::after {
  padding: 0;
  transform: translate(-50%, 0rem);
  border-top: 0.3rem solid;
  border-right: 0.3rem solid transparent;
  border-left: 0.3rem solid transparent;
  border-radius: 0;
  background-color: transparent;
  content: "";
  color: var(--tooltip-background-color);
}
[data-tooltip][data-placement="bottom"]::before,
[data-tooltip][data-placement="bottom"]::after {
  top: 100%;
  bottom: auto;
  transform: translate(-50%, 0.25rem);
}
[data-tooltip][data-placement="bottom"]:after {
  transform: translate(-50%, -0.3rem);
  border: 0.3rem solid transparent;
  border-bottom: 0.3rem solid;
}
[data-tooltip][data-placement="left"]::before,
[data-tooltip][data-placement="left"]::after {
  top: 50%;
  right: 100%;
  bottom: auto;
  left: auto;
  transform: translate(-0.25rem, -50%);
}
[data-tooltip][data-placement="left"]:after {
  transform: translate(0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-left: 0.3rem solid;
}
[data-tooltip][data-placement="right"]::before,
[data-tooltip][data-placement="right"]::after {
  top: 50%;
  right: auto;
  bottom: auto;
  left: 100%;
  transform: translate(0.25rem, -50%);
}
[data-tooltip][data-placement="right"]:after {
  transform: translate(-0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-right: 0.3rem solid;
}
[data-tooltip]:focus::before,
[data-tooltip]:focus::after,
[data-tooltip]:hover::before,
[data-tooltip]:hover::after {
  opacity: 1;
}
@media (hover: hover) and (pointer: fine) {
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::before,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::before,
  [data-tooltip]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::after {
    animation-name: tooltip-caret-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::before,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-bottom;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-name: tooltip-caret-slide-bottom;
  }
  [data-tooltip][data-placement="left"]:focus::before,
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::before,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-left;
  }
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-name: tooltip-caret-slide-left;
  }
  [data-tooltip][data-placement="right"]:focus::before,
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::before,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-right;
  }
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-name: tooltip-caret-slide-right;
  }
}
@keyframes tooltip-slide-top {
  from {
    transform: translate(-50%, 0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-top {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.25rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-bottom {
  from {
    transform: translate(-50%, -0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-bottom {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.5rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.3rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-left {
  from {
    transform: translate(0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-left {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.3rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-slide-right {
  from {
    transform: translate(-0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-right {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.3rem, -50%);
    opacity: 1;
  }
}

/**
 * Accessibility & User interaction
 */
[aria-controls] {
  cursor: pointer;
}

[aria-disabled="true"],
[disabled] {
  cursor: not-allowed;
}

[aria-hidden="false"][hidden] {
  display: initial;
}

[aria-hidden="false"][hidden]:not(:focus) {
  clip: rect(0, 0, 0, 0);
  position: absolute;
}

a,
area,
button,
input,
label,
select,
summary,
textarea,
[tabindex] {
  -ms-touch-action: manipulation;
}

[dir="rtl"] {
  direction: rtl;
}

/**
* Reduce Motion Features
*/
@media (prefers-reduced-motion: reduce) {
  *:not([aria-busy="true"]),
  :not([aria-busy="true"])::before,
  :not([aria-busy="true"])::after {
    background-attachment: initial !important;
    animation-duration: 1ms !important;
    animation-delay: -1ms !important;
    animation-iteration-count: 1 !important;
    scroll-behavior: auto !important;
    transition-delay: 0s !important;
    transition-duration: 0s !important;
  }
}

#mount#mount {
  /* --primary: rgb(227, 59, 126); */
  --primary: #ea4c89;
  --primary-hover: #f082ac;
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  --switch-checked-background-color: var(--primary);
}

li.select-link.select-link:hover > ul {
  display: none;
}
li.select-link.select-link > ul {
  display: none;
}
li.select-link.select-link a:focus ~ ul {
  display: none;
}

li.select-link.select-link a:active ~ ul {
  display: none;
}
li.select-link-active.select-link-active > ul {
  display: flex;
}
li.select-link-active.select-link-active:hover > ul {
  display: flex;
}

li.select-link-active.select-link-active a:focus ~ ul {
  display: flex;
}

li.select-link-active.select-link-active a:active ~ ul {
  display: flex;
}
ul.select-link-ul.select-link-ul {
  right: 0px;
  left: auto;
}

a.select-link-selected {
  background-color: var(--primary-focus);
}
.immersive-translate-no-select {
  -webkit-touch-callout: none; /* iOS Safari */
  -webkit-user-select: none; /* Safari */
  -khtml-user-select: none; /* Konqueror HTML */
  -moz-user-select: none; /* Old versions of Firefox */
  -ms-user-select: none; /* Internet Explorer/Edge */
  user-select: none;
}

/* li[role="list"].no-arrow > a::after { */
/*   background-image: none; */
/*   width: 0; */
/*   color: var(--color); */
/* } */
li[role="list"].no-arrow {
  margin-left: 8px;
  padding-right: 0;
}
li[role="list"] > a::after {
  -webkit-margin-start: 0.2rem;
  margin-inline-start: 0.2rem;
}

li[role="list"].no-arrow > a,
li[role="list"].no-arrow > a:link,
li[role="list"].no-arrow > a:visited {
  color: var(--secondary);
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  padding-left: 8px;
  text-overflow: ellipsis;
  color: var(--color);

}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}
select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.muted {
  color: var(--muted-color);
}

.select.button-select {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
  cursor: pointer;
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 16px;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
  -webkit-appearance: button;
  margin: 0;
  margin-bottom: 0px;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

#mount#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --text-black-2: #222222;
  --text-gray-2: #222222;
  --text-gray-6: #666666;
  --text-gray-9: #999999;
  --text-gray-c2: #c2c2c2;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --popup-footer-background-color: #0d0d0d;
    --popup-content-background-color: #191919;
    --popup-item-background-color: #272727;
    --popup-item-hover-background-color: #333333;
    --popup-trial-pro-background-color: #222222;
    --text-black-2: #ffffff;
    --text-gray-2: #dbdbdb;
    --text-gray-6: #b3b3b3;
    --text-gray-9: #777777;
    --text-gray-c2: #5b5b5b;
    --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
    --service-select-border-color: #2c2c2c;
    --service-select-selected-background-color: #333333;
  }
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --text-black-2: #ffffff;
  --text-gray-2: #dbdbdb;
  --text-gray-6: #b3b3b3;
  --text-gray-9: #777777;
  --text-gray-c2: #5b5b5b;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
}

.text-balck {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

#mount {
  min-width: 268px;
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.translate-service {
  color: var(--text-black-2);
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

select.min-select-secondary {
  color: var(--color);
}

select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

.widget-item {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 59px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-container {
  display: flex;
  align-items: center;
  justify-content: center;
  height: 30px;
  width: 100%;
  margin-bottom: 4px;
}

.widget-title-container {
  display: flex;
  align-items: flex-start;
  justify-content: center;
  height: 24px;
  width: 100%;
  padding-bottom: 4px;
}

.widget-icon {
  margin-bottom: 4px;
  display: flex;
  justify-content: center;
}

.widget-title {
  color: var(--text-gray-6);
  font-size: 12px;
  text-align: center;
  width: 100%;
  font-weight: 400;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  padding: 0 2px 2px;
}

.widget-item svg {
  fill: var(--text-gray-2);
}

.setting svg {
  fill: var(--text-gray-6);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: 0;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: 100%;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
}
.more-container {
  position: relative;
}
.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  z-index: 2147483647;
  top: 335px;
  width: 56px;
  display: flex;
  flex-direction: column;
  display: none;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ED6D8F;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-50%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 16px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-right: 8px;
}

.imt-fb-more-button {
  width: 36px;
  height: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}

/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 12px 0 0 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
}

.imt-manga-feedback {
  cursor: pointer;
  margin: 9px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 372px;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 16px auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " dir="ltr" style="z-index: 2147483647; pointer-events: none; top: 911px; display: flex;"><div title="关闭悬浮球" class="btn-animate" style="transform: translateX(100%); padding: 4px; cursor: pointer;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div><div style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg hidden="true" class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#68CD52"></circle><path d="M1.40857 5.87858L2.24148 5.18962L4.15344 6.64214C4.15344 6.64214 6.33547 4.15566 9.00658 2.48145L9.32541 2.87514C9.32541 2.87514 6.28665 5.55844 4.71735 9.07881L1.40857 5.87858Z" fill="white"></path></svg></div></div></div></div><div hidden="" class="imt-manga-button imt-no-events btn-animate " id="manga-button" style="transform: translateX(8px);"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg><svg hidden="true" class="imt-manga-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#68CD52"></circle><path d="M1.40857 5.87858L2.24148 5.18962L4.15344 6.64214C4.15344 6.64214 6.33547 4.15566 9.00658 2.48145L9.32541 2.87514C9.32541 2.87514 6.28665 5.55844 4.71735 9.07881L1.40857 5.87858Z" fill="white"></path></svg><svg class="imt-float-ball-loading" hidden="true" width="19" height="19" viewBox="0 0 19 19" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin: 9px;"><path d="M9.42859 0C9.84288 0 10.1929 0.387143 10.1929 0.847143V3.99429C10.1929 4.45429 9.84431 4.84143 9.42859 4.84143C9.01431 4.84143 8.66431 4.45571 8.66431 3.99429V0.847143C8.66431 0.387143 9.01288 0 9.42859 0Z" fill="#E9E9E9"></path><path d="M14.1301 1.38877C14.5158 1.62591 14.6301 2.12163 14.4258 2.52305L12.9515 5.19448C12.901 5.28714 12.8325 5.36876 12.75 5.43455C12.6675 5.50035 12.5727 5.54898 12.4712 5.5776C12.3696 5.60621 12.2634 5.61424 12.1586 5.60119C12.0539 5.58814 11.9529 5.55429 11.8615 5.50163C11.6787 5.38432 11.5468 5.20237 11.4923 4.9921C11.4377 4.78184 11.4645 4.55874 11.5672 4.36734L13.0415 1.69591C13.2686 1.29448 13.7443 1.15305 14.1301 1.38877Z" fill="#989697"></path><path d="M17.4685 4.75707C17.5813 4.95451 17.6123 5.18824 17.5549 5.40825C17.4975 5.62826 17.3563 5.81705 17.1614 5.93422L14.4971 7.52564C14.0971 7.76993 13.6014 7.62422 13.3657 7.20707C13.2532 7.00994 13.2222 6.77667 13.2793 6.55702C13.3365 6.33737 13.4771 6.14874 13.6714 6.03136L16.3357 4.43993C16.7371 4.21993 17.2557 4.34136 17.4685 4.7585V4.75707Z" fill="#9B999A"></path><path d="M18.8572 9.42835C18.8572 9.84263 18.47 10.1926 18.01 10.1926H14.8629C14.4029 10.1926 14.0157 9.84406 14.0157 9.42835C14.0157 9.01406 14.4029 8.66406 14.8629 8.66406H18.01C18.47 8.66406 18.8572 9.01263 18.8572 9.42835Z" fill="#A3A1A2"></path><path d="M17.4686 14.1303C17.3515 14.3134 17.1697 14.4455 16.9594 14.5003C16.7491 14.5552 16.5259 14.5286 16.3343 14.426L13.6629 12.9517C13.5702 12.9012 13.4886 12.8327 13.4228 12.7503C13.357 12.6678 13.3084 12.573 13.2798 12.4714C13.2512 12.3698 13.2431 12.2636 13.2562 12.1589C13.2692 12.0542 13.3031 11.9532 13.3558 11.8617C13.4731 11.6789 13.655 11.547 13.8653 11.4925C14.0755 11.4379 14.2986 11.4647 14.49 11.5674L17.1615 13.0417C17.5629 13.2689 17.7043 13.7446 17.4686 14.1303Z" fill="#ABA9AA"></path><path opacity="0.7" d="M14.1 17.4686C13.9026 17.5814 13.6689 17.6124 13.4489 17.555C13.2288 17.4976 13.04 17.3564 12.9229 17.1615L11.3315 14.4972C11.0872 14.0972 11.2329 13.6015 11.65 13.3658C11.8472 13.2533 12.0804 13.2224 12.3001 13.2795C12.5197 13.3366 12.7084 13.4773 12.8257 13.6715L14.4172 16.3358C14.6372 16.7372 14.5157 17.2558 14.0986 17.4686H14.1Z" fill="#B2B2B2"></path><path opacity="0.6" d="M9.42859 18.8571C9.01431 18.8571 8.66431 18.4699 8.66431 18.0099V14.8628C8.66431 14.4028 9.01288 14.0156 9.42859 14.0156C9.84288 14.0156 10.1929 14.4028 10.1929 14.8628V18.0099C10.1929 18.4699 9.84431 18.8571 9.42859 18.8571Z" fill="#BAB8B9"></path><path opacity="0.5" d="M4.72717 17.4685C4.5441 17.3514 4.41195 17.1696 4.35713 16.9593C4.30231 16.749 4.32885 16.5258 4.43145 16.3342L5.90574 13.6628C5.95622 13.5701 6.02472 13.4885 6.1072 13.4227C6.18969 13.3569 6.2845 13.3083 6.38606 13.2797C6.48762 13.251 6.59387 13.243 6.69857 13.2561C6.80327 13.2691 6.90431 13.303 6.99574 13.3556C7.38145 13.5914 7.49431 14.0885 7.29002 14.4899L5.81574 17.1614C5.5886 17.5628 5.11288 17.7042 4.72717 17.4685Z" fill="#C2C0C1"></path><path opacity="0.4" d="M1.38862 14.1002C1.27584 13.9027 1.24483 13.669 1.30223 13.449C1.35964 13.229 1.50089 13.0402 1.69576 12.923L4.36004 11.3316C4.76004 11.0873 5.25576 11.233 5.49147 11.6502C5.60393 11.8473 5.63491 12.0806 5.5778 12.3002C5.52069 12.5199 5.38 12.7085 5.18576 12.8259L2.52004 14.4173C2.12004 14.6373 1.60004 14.5159 1.38862 14.0987V14.1002Z" fill="#CBCBCB"></path><path d="M0 9.42835C0 9.01406 0.387143 8.66406 0.847143 8.66406H3.99429C4.45429 8.66406 4.84143 9.01263 4.84143 9.42835C4.84143 9.84263 4.45571 10.1926 3.99429 10.1926H0.847143C0.387143 10.1926 0 9.84406 0 9.42835Z" fill="#D2D2D2"></path><path opacity="0.2" d="M1.38852 4.72705C1.50561 4.54398 1.68746 4.41183 1.89774 4.35701C2.10803 4.30219 2.33125 4.32873 2.52281 4.43133L5.19424 5.90562C5.28689 5.9561 5.36851 6.0246 5.43431 6.10708C5.5001 6.18957 5.54874 6.28438 5.57735 6.38594C5.60597 6.48749 5.61399 6.59375 5.60094 6.69845C5.5879 6.80315 5.55405 6.90419 5.50138 6.99562C5.38407 7.17844 5.20212 7.31029 4.99186 7.36484C4.78159 7.4194 4.55849 7.39263 4.3671 7.2899L1.69567 5.81562C1.29424 5.58847 1.15281 5.11276 1.38852 4.72705Z" fill="#DADADA"></path><path d="M4.75719 1.38849C4.95463 1.27571 5.18837 1.24471 5.40838 1.30211C5.62838 1.35952 5.81718 1.50077 5.93434 1.69564L7.52577 4.35992C7.77005 4.75992 7.62434 5.25564 7.20719 5.49135C7.01006 5.60381 6.77679 5.63479 6.55714 5.57768C6.33749 5.52056 6.14886 5.37988 6.03148 5.18564L4.44005 2.51992C4.22005 2.11992 4.34148 1.59992 4.75862 1.38849H4.75719Z" fill="#E2E2E2"></path></svg><div style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><svg class="imt-manga-feedback" width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9996 3C15.1684 3 15.3356 3.03326 15.4916 3.09787C15.6476 3.16248 15.7893 3.25719 15.9087 3.37658C16.0281 3.49597 16.1228 3.6377 16.1874 3.79369C16.252 3.94968 16.2853 4.11687 16.2853 4.28571V12.8571C16.2853 13.026 16.252 13.1932 16.1874 13.3492C16.1228 13.5052 16.0281 13.6469 15.9087 13.7663C15.7893 13.8857 15.6476 13.9804 15.4916 14.045C15.3356 14.1096 15.1684 14.1429 14.9996 14.1429H8.3233L5.3773 16.0736C5.31264 16.1159 5.23773 16.14 5.1605 16.1433C5.08327 16.1465 5.00659 16.1288 4.9386 16.0921C4.8706 16.0553 4.81382 16.0008 4.77426 15.9344C4.73469 15.868 4.71383 15.7922 4.71387 15.7149V14.1429H2.99958C2.83074 14.1429 2.66355 14.1096 2.50756 14.045C2.35157 13.9804 2.20983 13.8857 2.09044 13.7663C1.97105 13.6469 1.87635 13.5052 1.81174 13.3492C1.74712 13.1932 1.71387 13.026 1.71387 12.8571V4.28571C1.71387 3.94472 1.84933 3.61769 2.09044 3.37658C2.33156 3.13546 2.65859 3 2.99958 3H14.9996ZM14.9996 4.28571H2.99958V12.8571H5.99958V14.1287L7.93972 12.8571H14.9996V4.28571ZM9.54815 8.57143V9.85714H5.99958V8.57143H9.54815ZM11.9996 6V7.28571H5.99958V6H11.9996Z" fill="#6C6F73"></path></svg></div></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 12px; transform: translateX(60px);"><div class="btn-animate" style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><div class="imt-fb-more-button"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.6861 1L15.2353 4.54635V7.11765V14.6471V15.5882C15.2353 15.9627 15.0866 16.3217 14.8218 16.5865C14.557 16.8513 14.198 17 13.8235 17H4.41176C4.03734 17 3.67825 16.8513 3.4135 16.5865C3.14874 16.3217 3 15.9627 3 15.5882V14.6471V7.11765V2.41176C3 2.03734 3.14874 1.67825 3.4135 1.4135C3.67825 1.14874 4.03734 1 4.41176 1H11.6861ZM11.8692 3.17882V4.74212H13.4334L11.8692 3.17882ZM4.41171 15.5882V14.647V2.41176H10.4574L10.4578 6.15341H13.8235V14.647V15.5882H4.41171ZM12.7739 7.51746H5.46094V8.6155H12.7739V7.51746ZM5.46094 9.98805H12.7739V11.0861H5.46094V9.98805ZM9.5127 12.36H5.46094V13.458H9.5127V12.36Z" fill="#666666"></path></svg></div></div></div><div class="btn-animate" style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><div class="imt-fb-more-button"><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M7.55741 1L10.0685 1.00329C10.8482 1.00471 11.4802 1.63624 11.4812 2.41647L11.4821 2.82588C11.9687 3.0278 12.4297 3.28671 12.8553 3.59718L13.1913 3.40329C13.516 3.21676 13.9013 3.1665 14.2629 3.26352C14.6246 3.36055 14.933 3.59695 15.1207 3.92094L16.3795 6.09365C16.5601 6.40546 16.6149 6.7744 16.5328 7.12523C16.4507 7.47606 16.2378 7.78235 15.9376 7.98165L15.8609 8.02871L15.5235 8.22353C15.5819 8.76273 15.5736 9.30708 15.4986 9.84424L15.7372 9.98259C16.0496 10.1631 16.2812 10.4561 16.3848 10.8017C16.4884 11.1472 16.456 11.5193 16.2944 11.8419L16.2553 11.9153L15.076 13.9576C14.8955 14.27 14.6025 14.5017 14.2569 14.6053C13.9113 14.7088 13.5392 14.6765 13.2167 14.5148L13.1433 14.4753L12.8172 14.2871C12.4074 14.5817 11.9651 14.8283 11.4991 15.0221L11.4995 15.5831C11.5 15.9434 11.3629 16.2904 11.1163 16.5532C10.8697 16.816 10.5321 16.9748 10.1725 16.9972L10.0831 17L7.57153 16.9967C7.19697 16.9961 6.83793 16.847 6.57312 16.5821C6.30831 16.3172 6.15932 15.9581 6.15883 15.5835L6.15788 14.9073C5.76852 14.7244 5.39771 14.5044 5.05059 14.2504L4.44918 14.5967C4.12448 14.7834 3.73902 14.8337 3.37726 14.7367C3.01551 14.6397 2.70698 14.4032 2.5193 14.0791L1.26047 11.9064C1.07996 11.5945 1.02522 11.2255 1.10742 10.8747C1.18962 10.5238 1.40257 10.2176 1.70283 10.0184L1.77906 9.97129L2.3913 9.61835C2.34424 9.17129 2.34188 8.71765 2.38706 8.26494L1.70753 7.87247C1.39506 7.69207 1.16331 7.39911 1.05965 7.05351C0.955998 6.70791 0.988275 6.33577 1.14989 6.01318L1.18941 5.93976L2.36871 3.89741C2.54919 3.58502 2.84218 3.35337 3.18777 3.2498C3.53336 3.14624 3.90547 3.17859 4.228 3.34023L4.30141 3.37976L4.89436 3.72188C5.28027 3.42082 5.69854 3.1637 6.14141 2.95529L6.14047 2.41694C6.14001 2.05657 6.27707 1.7096 6.52367 1.44681C6.77028 1.18403 7.10786 1.02523 7.46753 1.00282L7.55741 1ZM7.55553 2.41506L7.55694 3.85271L6.74377 4.23576C6.39553 4.39906 6.06706 4.60094 5.764 4.83718L5.01247 5.424L3.62941 4.62494L3.59365 4.60518L2.41483 6.64753L3.88636 7.49694L3.79506 8.40612C3.75968 8.7598 3.76078 9.11619 3.79836 9.46965L3.8953 10.3854L2.48494 11.1976L3.7433 13.3704L5.14377 12.5647L5.88636 13.1087C6.15997 13.309 6.45231 13.4823 6.7593 13.6264L7.57106 14.008L7.57388 15.5816L10.0845 15.5849L10.0831 14.0791L10.9555 13.7158C11.3216 13.5635 11.6689 13.3698 11.9908 13.1384L12.7329 12.6047L13.8506 13.2499L15.0289 11.2075L13.9654 10.592L14.0972 9.64847C14.1561 9.22659 14.1628 8.79904 14.1169 8.37553L14.0181 7.45882L15.1555 6.80235L13.8967 4.62965L12.7645 5.28235L12.0214 4.74024C11.686 4.4956 11.3229 4.29152 10.9395 4.13224L10.0689 3.77082L10.0666 2.41835L7.55553 2.41506ZM10.3715 6.47624C11.0214 6.85201 11.4955 7.47036 11.6898 8.19547C11.8841 8.92058 11.7827 9.69316 11.4078 10.3435C11.2223 10.6654 10.9752 10.9476 10.6805 11.1739C10.3859 11.4002 10.0495 11.5662 9.69068 11.6623C9.33183 11.7585 8.95754 11.7829 8.58923 11.7343C8.22092 11.6856 7.86582 11.5648 7.54424 11.3788C6.89445 11.003 6.4204 10.3846 6.2262 9.65948C6.032 8.93438 6.13352 8.16184 6.50847 7.51153C6.69395 7.18963 6.94107 6.90746 7.23571 6.68117C7.53034 6.45488 7.86671 6.28891 8.22556 6.19275C8.58441 6.09659 8.9587 6.07213 9.32701 6.12077C9.69532 6.16942 10.0504 6.29021 10.372 6.47624H10.3715ZM7.73388 8.21835C7.54638 8.54388 7.49567 8.9305 7.5929 9.29336C7.69012 9.65623 7.92733 9.96571 8.25247 10.1539C8.41305 10.2468 8.59037 10.3071 8.77429 10.3314C8.9582 10.3557 9.14511 10.3435 9.32431 10.2956C9.50351 10.2476 9.67149 10.1647 9.81864 10.0517C9.96579 9.93877 10.0892 9.7979 10.1819 9.63718C10.5588 8.98353 10.356 8.15435 9.73435 7.74494L9.66377 7.70118L9.59035 7.66165C9.26834 7.49988 8.89663 7.46742 8.55145 7.57093C8.20626 7.67444 7.91375 7.90608 7.73388 8.21835Z" fill="#666666"></path></svg></div></div></div></div><div hidden="" class="imt-fb-more-buttons btn-animate" style="margin-top: 12px; transform: translateX(60px);"><div class="btn-animate" style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><svg class="imt-manga-feedback" width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M14.9996 3C15.1684 3 15.3356 3.03326 15.4916 3.09787C15.6476 3.16248 15.7893 3.25719 15.9087 3.37658C16.0281 3.49597 16.1228 3.6377 16.1874 3.79369C16.252 3.94968 16.2853 4.11687 16.2853 4.28571V12.8571C16.2853 13.026 16.252 13.1932 16.1874 13.3492C16.1228 13.5052 16.0281 13.6469 15.9087 13.7663C15.7893 13.8857 15.6476 13.9804 15.4916 14.045C15.3356 14.1096 15.1684 14.1429 14.9996 14.1429H8.3233L5.3773 16.0736C5.31264 16.1159 5.23773 16.14 5.1605 16.1433C5.08327 16.1465 5.00659 16.1288 4.9386 16.0921C4.8706 16.0553 4.81382 16.0008 4.77426 15.9344C4.73469 15.868 4.71383 15.7922 4.71387 15.7149V14.1429H2.99958C2.83074 14.1429 2.66355 14.1096 2.50756 14.045C2.35157 13.9804 2.20983 13.8857 2.09044 13.7663C1.97105 13.6469 1.87635 13.5052 1.81174 13.3492C1.74712 13.1932 1.71387 13.026 1.71387 12.8571V4.28571C1.71387 3.94472 1.84933 3.61769 2.09044 3.37658C2.33156 3.13546 2.65859 3 2.99958 3H14.9996ZM14.9996 4.28571H2.99958V12.8571H5.99958V14.1287L7.93972 12.8571H14.9996V4.28571ZM9.54815 8.57143V9.85714H5.99958V8.57143H9.54815ZM11.9996 6V7.28571H5.99958V6H11.9996Z" fill="#6C6F73"></path></svg></div></div></div></div></div></template></div><grammarly-desktop-integration data-grammarly-shadow-root="true"><template shadowrootmode="open"><style>
      div.grammarly-desktop-integration {
        position: absolute;
        width: 1px;
        height: 1px;
        padding: 0;
        margin: -1px;
        overflow: hidden;
        clip: rect(0, 0, 0, 0);
        white-space: nowrap;
        border: 0;
        -moz-user-select: none;
        -webkit-user-select: none;
        -ms-user-select:none;
        user-select:none;
      }

      div.grammarly-desktop-integration:before {
        content: attr(data-content);
      }
    </style><div aria-label="grammarly-integration" role="group" tabindex="-1" class="grammarly-desktop-integration" data-content="{&quot;mode&quot;:&quot;full&quot;,&quot;isActive&quot;:true,&quot;isUserDisabled&quot;:false}"></div></template></grammarly-desktop-integration></html>