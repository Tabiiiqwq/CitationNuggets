{
  "paper_id": "3dmvp",
  "pred_citations": [],
  "gt_citations": [
    [
      "Unsupervised learning of In Euro- visual representations by solving jigsaw puzzles"
    ],
    [
      "A simple framework for contrastive learning of visual representations",
      "Momentum contrast for unsupervised visual rep- resentation learning"
    ],
    [
      "Masked siamese networks for label-efficient learning",
      "Self-supervised learning from images with a joint-embedding predictive architecture",
      "Unsupervised learning of visual features by contrasting cluster assignments",
      "Emerg- ing properties in self-supervised vision transformers",
      "Bootstrap your own latent-a new approach to self-supervised learning",
      "ibot: Image bert pre-training arXiv preprint arXiv:2111.07832, with online tokenizer"
    ],
    [
      "Masked autoencoders are scalable vision learners"
    ],
    [
      "Multimae: Multi-modal multi-task masked autoen- coders"
    ],
    [
      "Scaling egocentric vision: The epic-kitchens dataset",
      "Ego4d: Around the world in 3,000 hours of egocentric video",
      "Understanding human hands in contact at internet scale"
    ],
    [
      "An unbiased look at datasets for visuo-motor pre-training",
      "Vip: Towards universal visual reward and representation via value-implicit pre-training",
      "Where are we in the search for an artificial visual cortex for embodied intelli- gence? Advances in Neural Information Processing Systems, 36, 2024.",
      "representation for robot manipulation",
      "Real-world robot learn- ing with masked visual pre-training",
      "Multi-view masked world In International models for visual robotic manipulation",
      "Masked visual pre-training for motor control"
    ],
    [
      "Deep residual learning for image recognition"
    ],
    [
      "An image is worth 16x16 words: Trans- arXiv preprint formers for image recognition at scale"
    ],
    [
      "Rvt: Robotic view transformer for 3d object manipulation"
    ],
    [
      "Act3d: Infinite resolution action detec- tion transformer for robotic manipulation"
    ],
    [
      "Instruction-driven history-aware policies for robotic manip- ulations",
      "Instruction-following agents with jointly pre-trained vision- language models",
      "Behavior transformers: Cloning k modes with one stone",
      "Perceiver- actor: A multi-task transformer for robotic manipulation",
      "Shelving, stacking, hanging: Relational pose arXiv preprint diffusion for multi-modal rearrangement"
    ],
    [
      "Rt-1: Robotics transformer for real-world control at scale"
    ],
    [
      "A generalist agent"
    ],
    [
      "Instruction-following agents with jointly pre-trained vision- language models"
    ],
    [
      "Perceiver- actor: A multi-task transformer for robotic manipulation"
    ],
    [
      "Coarse-to-fine q-attention: Efficient learn- ing for visual robotic manipulation via discretisation"
    ],
    [
      "Rvt: Robotic view transformer for 3d object manipulation"
    ],
    [
      "Act3d: Infinite resolution action detec- tion transformer for robotic manipulation"
    ],
    [
      "Gnfactor: Multi-task real robot learning In Conference on with generalizable neural feature fields"
    ]
  ]
}