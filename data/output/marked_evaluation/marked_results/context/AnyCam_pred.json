{
  "paper_id": "AnyCam",
  "pred_citations": [],
  "gt_citations": [
    [
      "Flownet: Learning optical flow with convolutional networks",
      "Unsupervised monocular depth estimation with left- In Proceedings of the IEEE conference right consistency",
      "Digging into self-supervised monocular In Proceedings of the IEEE/CVF inter- depth estimation"
    ],
    [
      "Depth anything: Unleashing the power of large-scale unlabeled data"
    ],
    [
      "Depth any- thing v2"
    ],
    [
      "Metric3d: Towards zero-shot metric 3d prediction from a single image"
    ],
    [
      "Metric3d v2: A versatile monocular geomet- ric foundation model for zero-shot metric depth and surface normal estimation"
    ],
    [
      "Depth pro: Sharp monocular metric depth in less than a second"
    ],
    [
      "Depthcrafter: Generating consistent long depth sequences for open-world videos"
    ],
    [
      "Unidepth: Universal monocular metric depth estimation"
    ],
    [
      "Raft: Recurrent all-pairs field In Computer Vision\u2013ECCV transforms for optical flow"
    ],
    [
      "Gmflow: Learning optical flow via global matching"
    ],
    [
      "Unifying flow, stereo and depth estimation"
    ],
    [
      "Multiple view ge- ometry in computer vision",
      "A critique of structure-from-motion algo- rithms",
      "A survey of structure from motion*"
    ],
    [
      "Structure- In Proceedings of the IEEE con- from-motion revisited"
    ],
    [
      "Lsd- slam: Large-scale direct monocular slam",
      "Direct sparse odometry",
      "Orb-slam2: An open- source slam system for monocular, stereo, and rgb-d cam- eras",
      "5"
    ],
    [
      "Dsac-differentiable ransac for camera localization",
      "Superpoint: Self-supervised interest point detection and description",
      "Ground- arXiv preprint ing image matching in 3d with mast3r",
      "Learning correspondence uncer- tainty via differentiable nonlinear least squares",
      "Deep fundamental matrix estimation",
      "In Proceedings of matching with graph neural networks",
      "Back to the feature: Learning robust camera localization from pixels to pose",
      "Deep virtual stereo odometry: Leveraging deep depth predic- tion for monocular direct sparse odometry"
    ],
    [
      "In defense of the eight-point algorithm"
    ],
    [
      "Direct sparse odometry"
    ],
    [
      "nuscenes: A multi- In Proceedings of modal dataset for autonomous driving",
      "Vision meets robotics: The kitti dataset",
      "Scalability in perception for autonomous driving: Waymo open dataset"
    ],
    [
      "Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras"
    ],
    [
      "Raft: Recurrent all-pairs field In Computer Vision\u2013ECCV transforms for optical flow"
    ],
    [
      "Particlesfm: Exploiting dense point trajecto- ries for localizing moving cameras in the wild"
    ],
    [
      "Structure and motion from casual videos"
    ],
    [
      "Dust3r: Geometric 3d vi- sion made easy"
    ],
    [
      "Flowmap: High-quality camera poses, in- arXiv preprint trinsics, and depth via gradient descent"
    ],
    [
      "Leap-vo: Long-term effective any point tracking for visual In Proceedings of the IEEE/CVF Conference odometry"
    ],
    [
      "Monst3r: A simple approach for estimat- arXiv preprint ing geometry in the presence of motion"
    ]
  ]
}