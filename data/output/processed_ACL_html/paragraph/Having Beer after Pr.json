{
  "S1.p1": {
    "text": "We live in a multicultural world, where the diversity of cultures enriches our global community. In light of the global deployment of LMs, it is crucial to ensure these models grasp the cultural distinctions of diverse communities. Despite progress to bridge the language barrier gap Ahuja et\u00a0al. ( 2023 ); Yong et\u00a0al. ( 2022 ) , LMs still struggle at capturing cultural nuances and adapting to specific cultural contexts Hershcovich et\u00a0al. ( 2022 ) . Truly multicultural LMs should not only communicate across languages but do so with an awareness of cultural sensitivities, fostering a deeper global connection. Report issue for preceding element",
    "masked_text": "We live in a multicultural world, where the diversity of cultures enriches our global community. In light of the global deployment of LMs, it is crucial to ensure these models grasp the cultural distinctions of diverse communities. Despite progress to bridge the language barrier gap [CITATION], LMs still struggle at capturing cultural nuances and adapting to specific cultural contexts [CITATION]. Truly multicultural LMs should not only communicate across languages but do so with an awareness of cultural sensitivities, fostering a deeper global connection.Report issue for preceding element",
    "citations": [
      {
        "tag": "Hershcovich et\u00a0al. (2022)",
        "title": "Challenges and strategies in cross-cultural nlp.",
        "authors": "Daniel Hershcovich, Stella Frank, Heather Lent, Miryam de\u00a0Lhoneux, Mostafa\nAbdou, Stephanie Brandl, Emanuele Bugliarello, Laura\u00a0Cabello Piqueras, Ilias\nChalkidis, Ruixiang Cui, et\u00a0al. 2022.",
        "journal": "In60th Annual Meeting of the\nAssociation-for-Computational-Linguistics (ACL), MAY 22-27, 2022, Dublin,\nIRELAND, pages 6997\u20137013. Association for Computational Linguistics."
      },
      {
        "tag": "Yong et\u00a0al. (2022)",
        "title": "Bloom+1: Adding language support to bloom for zero-shot prompting.",
        "authors": "Zheng-Xin Yong, Hailey Schoelkopf, Niklas Muennighoff, Alham\u00a0Fikri Aji,\nDavid\u00a0Ifeoluwa Adelani, Khalid Almubarak, M\u00a0Saiful Bari, Lintang Sutawika,\nJungo Kasai, Ahmed Baruwa, et\u00a0al. 2022.",
        "journal": "arXiv preprint arXiv:2212.09535."
      },
      {
        "tag": "Ahuja et\u00a0al. (2023)",
        "title": "Mega: Multilingual evaluation of generative ai.",
        "authors": "Kabir Ahuja, Rishav Hada, Millicent Ochieng, Prachi Jain, Harshita Diddee,\nSamuel Maina, Tanuja Ganu, Sameer Segal, Maxamed Axmed, Kalika Bali, et\u00a0al.\n2023.",
        "journal": "arXiv preprint arXiv:2303.12528."
      }
    ]
  },
  "S1.p2": {
    "text": "As we show in Figure 1 , LMs fail at appropriate cultural adaptation in Arabic when asked to provide completions to various prompts, often suggesting and prioritizing Western-centric content. For example, LMs refer to alcoholic beverages even when the prompt in Arabic explicitly mentions Islamic prayer . While \u201cgoing for a drink\u201d in Western culture commonly refers to the consumption of alcoholic beverages, conversely, in the predominantly Muslim Arab world where alcohol is not prevalent, the same phrase in everyday life often refers to the consumption of coffee or tea. Western-centric entities are also generated by LMs when suggesting people\u2019s names and food dishes, despite being inappropriate to the cultural context of the prompts. Such observations raise concerns, as users may find it upsetting to see inadequate cultural representation by LMs in their own languages. This leads to the question: do LMs exhibit bias towards Western entities in non-English, non-Western languages ? Report issue for preceding element",
    "masked_text": "As we show in Figure 1, LMs fail at appropriate cultural adaptation in Arabic when asked to provide completions to various prompts, often suggesting and prioritizing Western-centric content. For example, LMs refer to alcoholic beverages even when the prompt in Arabic explicitly mentions Islamic prayer. While \u201cgoing for a drink\u201d in Western culture commonly refers to the consumption of alcoholic beverages, conversely, in the predominantly Muslim Arab world where alcohol is not prevalent, the same phrase in everyday life often refers to the consumption of coffee or tea. Western-centric entities are also generated by LMs when suggesting people\u2019s names and food dishes, despite being inappropriate to the cultural context of the prompts. Such observations raise concerns, as users may find it upsetting to see inadequate cultural representation by LMs in their own languages. This leads to the question: do LMs exhibit bias towards Western entities in non-English, non-Western languages ?Report issue for preceding element",
    "citations": []
  },
  "S1.p3": {
    "text": "While considerable effort has gone into exploring biases in LMs with regards to groups of different demographic or social dimensions Sheng et\u00a0al. ( 2021 ) such as religion Abid et\u00a0al. ( 2021a , b ) , race An et\u00a0al. ( 2023 ); Ahn and Oh ( 2021 ) , and nationalities Cao et\u00a0al. ( 2022b ) , much less work (\u00a7 2 ) has examined the cultural appropriateness of LMs in the non-Western and non-English environments. In order to address this gap, we center our study on culturally relevant entities, as they are important aspects of cultural heritage Montanari ( 2006 ); Tajuddin ( 2018 ) and can symbolize regional identities G\u00f3mez-Bantel ( 2018 ) . To the best of our knowledge, there is no resource readily available for doing so, especially one that can contrast Arab vs. Western cultural differences. We thus construct a new benchmark, CAMeL ( C ultural A ppropriateness Me asure Set for L Ms), which consists of an extensive list of 20,368 Arab and Western entities extracted from Wikidata and CommonCrawl, covering eight entity types (i.e., person names, food dishes, beverages, clothing items, locations, authors, religious places of worship, and sports clubs), and an associated set of 628 naturally occurring prompts as contexts for those entities (\u00a7 3 ). Report issue for preceding element",
    "masked_text": "While considerable effort has gone into exploring biases in LMs with regards to groups of different demographic or social dimensions [CITATION] such as religion [CITATION], race [CITATION], and nationalities [CITATION], much less work (\u00a72) has examined the cultural appropriateness of LMs in the non-Western and non-English environments. In order to address this gap, we center our study on culturally relevant entities, as they are important aspects of cultural heritage [CITATION] and can symbolize regional identities [CITATION]. To the best of our knowledge, there is no resource readily available for doing so, especially one that can contrast Arab vs. Western cultural differences. We thus construct a new benchmark, CAMeL (Cultural Appropriateness Measure Set for LMs), which consists of an extensive list of 20,368 Arab and Western entities extracted from Wikidata and CommonCrawl, covering eight entity types (i.e., person names, food dishes, beverages, clothing items, locations, authors, religious places of worship, and sports clubs), and an associated set of 628 naturally occurring prompts as contexts for those entities (\u00a73).Report issue for preceding element",
    "citations": [
      {
        "tag": "Sheng et\u00a0al. (2021)",
        "title": "Societal biases in language generation: Progress and challenges.",
        "authors": "Emily Sheng, Kai-Wei Chang, Prem Natarajan, and Nanyun Peng. 2021.",
        "journal": "InProceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing (Volume 1: Long Papers), pages 4275\u20134293."
      },
      {
        "tag": "Cao et\u00a0al. (2022b)",
        "title": "Theory-grounded measurement of U.S. social stereotypes in English\nlanguage models.",
        "authors": "Yang\u00a0Trista Cao, Anna Sotnikova, Hal Daum\u00e9\u00a0III, Rachel Rudinger, and Linda\nZou. 2022b.",
        "journal": "InProceedings of the 2022 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language\nTechnologies, pages 1276\u20131295, Seattle, United States. Association for\nComputational Linguistics."
      },
      {
        "tag": "Montanari (2006)",
        "title": "Food is culture.",
        "authors": "Massimo Montanari. 2006.",
        "journal": "Columbia University Press."
      },
      {
        "tag": "Abid et\u00a0al. (2021b)",
        "title": "Persistent anti-muslim bias in large language models.",
        "authors": "Abubakar Abid, Maheen Farooqi, and James Zou. 2021b.",
        "journal": "InProceedings of the 2021 AAAI/ACM Conference on AI, Ethics,\nand Society, AIES \u201921, page 298\u2013306, New York, NY, USA. Association for\nComputing Machinery."
      },
      {
        "tag": "Tajuddin (2018)",
        "title": "Cultural and social identity in clothing matters \u201cdifferent\ncultures, different meanings\u201d.",
        "authors": "Fatjri\u00a0Nur Tajuddin. 2018.",
        "journal": "European Journal of Behavioral Sciences, 1(4):21\u201325."
      },
      {
        "tag": "An et\u00a0al. (2023)",
        "title": "SODAPOP: Open-ended discovery of social biases in social\ncommonsense reasoning models.",
        "authors": "Haozhe An, Zongxia Li, Jieyu Zhao, and Rachel Rudinger. 2023.",
        "journal": "InProceedings of the 17th Conference of the European Chapter\nof the Association for Computational Linguistics, pages 1565\u20131588."
      },
      {
        "tag": "Abid et\u00a0al. (2021a)",
        "title": "Large language models associate muslims with violence.",
        "authors": "Abubakar Abid, Maheen Farooqi, and James Zou. 2021a.",
        "journal": "Nature Machine Intelligence, 3(6):461\u2013463."
      },
      {
        "tag": "G\u00f3mez-Bantel (2018)",
        "title": "Football clubs as symbols of regional identities.",
        "authors": "Adriano G\u00f3mez-Bantel. 2018.",
        "journal": "InFootball, Community and Sustainability, pages 32\u201342.\nRoutledge."
      },
      {
        "tag": "Ahn and Oh (2021)",
        "title": "Mitigating\nlanguage-dependent ethnic bias in BERT.",
        "authors": "Jaimeen Ahn and Alice Oh. 2021.",
        "journal": "InProceedings of the 2021 Conference on Empirical Methods in\nNatural Language Processing, pages 533\u2013549, Online and Punta Cana,\nDominican Republic. Association for Computational Linguistics."
      }
    ]
  },
  "S1.p4": {
    "text": "We show that CAMeL entities and prompts enable cross-cultural testing of LMs in versatile experimental setups, including story generation, NER, sentiment analysis, and text infilling (\u00a7 4 ). We benchmark 16 LMs pre-trained with Arabic data (\u00a7 4.1 ). Our results reveal concerning cases of cultural stereotypes in LM-generated stories, such as the association of Arab names with poverty/traditionalism (\u00a7 4.2 ), and cultural unfairness , such as better NER tagging performance of Western entities and higher association of Arab entities with negative sentiment (\u00a7 4.3 ). We further show that LMs exhibit high levels of preference towards Western-associated entities even when prompted by contexts uniquely suited for Arab culture-associated entities (\u00a7 4.4 ). Report issue for preceding element",
    "masked_text": "We show that CAMeL entities and prompts enable cross-cultural testing of LMs in versatile experimental setups, including story generation, NER, sentiment analysis, and text infilling (\u00a74). We benchmark 16 LMs pre-trained with Arabic data (\u00a74.1). Our results reveal concerning cases of cultural stereotypes in LM-generated stories, such as the association of Arab names with poverty/traditionalism (\u00a74.2), and cultural unfairness, such as better NER tagging performance of Western entities and higher association of Arab entities with negative sentiment (\u00a74.3). We further show that LMs exhibit high levels of preference towards Western-associated entities even when prompted by contexts uniquely suited for Arab culture-associated entities (\u00a74.4).Report issue for preceding element",
    "citations": []
  },
  "S1.p5": {
    "text": "Lastly, we discuss that the prevalence of Western content in Arabic corpora may be a key contributor to the observed biases in LMs. We analyze the cultural relevance of 6 Arabic pre-training corpora by training n-gram LMs on each corpus and comparing their text-infilling performance on CAMeL . We find that sources such as Wikipedia may not be ideal for building culturally-aware LMs (\u00a7 5 ). Report issue for preceding element",
    "masked_text": "Lastly, we discuss that the prevalence of Western content in Arabic corpora may be a key contributor to the observed biases in LMs. We analyze the cultural relevance of 6 Arabic pre-training corpora by training n-gram LMs on each corpus and comparing their text-infilling performance on CAMeL. We find that sources such as Wikipedia may not be ideal for building culturally-aware LMs (\u00a75).Report issue for preceding element",
    "citations": []
  },
  "S2.p1": {
    "text": "There have been several recent efforts on examining the cultural alignment of LMs. One line of work explored the moral knowledge (e.g., judgment of right and wrong actions) encoded in LMs Fraser et\u00a0al. ( 2022 ); Schramowski et\u00a0al. ( 2022 ); H\u00e4mmerl et\u00a0al. ( 2022 ); Xu et\u00a0al. ( 2023 ) , probing their ability to infer moral variation on topics with cultural divergence of opinions Ramezani and Xu ( 2023 ) . It has been found that LMs can be biased towards the moral values of certain societies (e.g., American Johnson et\u00a0al. ( 2022 ) ) and political ideologies (e.g., liberalism Abdulhai et\u00a0al. ( 2023 ) ). Similar works studied LMs\u2019 understanding of cross-cultural differences in values and beliefs (e.g., attitude towards individualism) Cao et\u00a0al. ( 2023 ); Arora et\u00a0al. ( 2023 ) , and what opinions they hold on political Hartmann et\u00a0al. ( 2023 ); Feng et\u00a0al. ( 2023 ) or other global topics Santurkar et\u00a0al. ( 2023 ); Durmus et\u00a0al. ( 2023 ) . Report issue for preceding element",
    "masked_text": "There have been several recent efforts on examining the cultural alignment of LMs. One line of work explored the moral knowledge (e.g., judgment of right and wrong actions) encoded in LMs [CITATION], probing their ability to infer moral variation on topics with cultural divergence of opinions [CITATION]. It has been found that LMs can be biased towards the moral values of certain societies (e.g., American [CITATION]) and political ideologies (e.g., liberalism [CITATION]). Similar works studied LMs\u2019 understanding of cross-cultural differences in values and beliefs (e.g., attitude towards individualism) [CITATION], and what opinions they hold on political [CITATION] or other global topics [CITATION]. Report issue for preceding element",
    "citations": [
      {
        "tag": "Durmus et\u00a0al. (2023)",
        "title": "Towards measuring the representation of subjective global opinions in\nlanguage models.",
        "authors": "Esin Durmus, Karina Nyugen, Thomas\u00a0I Liao, Nicholas Schiefer, Amanda Askell,\nAnton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez, Nicholas\nJoseph, et\u00a0al. 2023.",
        "journal": "arXiv preprint arXiv:2306.16388."
      },
      {
        "tag": "H\u00e4mmerl et\u00a0al. (2022)",
        "title": "Speaking multiple languages affects the moral bias of language\nmodels.",
        "authors": "Katharina H\u00e4mmerl, Bj\u00f6rn Deiseroth, Patrick Schramowski, Jind\u0159ich\nLibovick\u1ef3, Constantin\u00a0A Rothkopf, Alexander Fraser, and Kristian\nKersting. 2022.",
        "journal": "arXiv preprint arXiv:2211.07733."
      },
      {
        "tag": "Schramowski et\u00a0al. (2022)",
        "title": "Large pre-trained language models contain human-like biases of what\nis right and wrong to do.",
        "authors": "Patrick Schramowski, Cigdem Turan, Nico Andersen, Constantin\u00a0A Rothkopf, and\nKristian Kersting. 2022.",
        "journal": "Nature Machine Intelligence, 4(3):258\u2013268."
      },
      {
        "tag": "Ramezani and Xu (2023)",
        "title": "Knowledge of cultural moral norms in large language models.",
        "authors": "Aida Ramezani and Yang Xu. 2023.",
        "journal": "arXiv preprint arXiv:2306.01857."
      },
      {
        "tag": "Abdulhai et\u00a0al. (2023)",
        "title": "Moral foundations of large language models.",
        "authors": "Marwa Abdulhai, Gregory Serapio-Garcia, Cl\u00e9ment Crepy, Daria Valter, John\nCanny, and Natasha Jaques. 2023.",
        "journal": "arXiv preprint arXiv:2310.15337."
      },
      {
        "tag": "Hartmann et\u00a0al. (2023)",
        "title": "The political ideology of conversational ai: Converging evidence on\nchatgpt\u2019s pro-environmental, left-libertarian orientation.",
        "authors": "Jochen Hartmann, Jasper Schwenzow, and Maximilian Witte. 2023.",
        "journal": "arXiv preprint arXiv:2301.01768."
      },
      {
        "tag": "Johnson et\u00a0al. (2022)",
        "title": "The Ghost in the Machine has an American accent: value conflict\nin GPT-3.",
        "authors": "Rebecca\u00a0L Johnson, Giada Pistilli, Natalia Men\u00e9dez-Gonz\u00e1lez, Leslye\nDenisse\u00a0Dias Duran, Enrico Panai, Julija Kalpokiene, and Donald\u00a0Jay Bertulfo.\n2022.",
        "journal": "arXiv preprint arXiv:2203.07785."
      },
      {
        "tag": "Xu et\u00a0al. (2023)",
        "title": "Align on the fly: Adapting chatbot behavior to established norms.",
        "authors": "Chunpu Xu, Steffi Chern, Ethan Chern, Ge\u00a0Zhang, Zekun Wang, Ruibo Liu, Jing Li,\nJie Fu, and Pengfei Liu. 2023.",
        "journal": "arXiv preprint arXiv:2312.15907."
      },
      {
        "tag": "Arora et\u00a0al. (2023)",
        "title": "Probing pre-trained language models for cross-cultural differences in\nvalues.",
        "authors": "Arnav Arora, Lucie-Aim\u00e9e Kaffee, and Isabelle Augenstein. 2023.",
        "journal": "InProceedings of the First Workshop on Cross-Cultural\nConsiderations in NLP (C3NLP), pages 114\u2013130."
      },
      {
        "tag": "Feng et\u00a0al. (2023)",
        "title": "From pretraining data to language models to downstream tasks:\nTracking the trails of political biases leading to unfair nlp models.",
        "authors": "Shangbin Feng, Chan\u00a0Young Park, Yuhan Liu, and Yulia Tsvetkov. 2023.",
        "journal": "arXiv preprint arXiv:2305.08283."
      },
      {
        "tag": "Fraser et\u00a0al. (2022)",
        "title": "Does moral code have a moral code? probing delphi\u2019s moral\nphilosophy.",
        "authors": "Kathleen\u00a0C Fraser, Svetlana Kiritchenko, and Esma Balkir. 2022.",
        "journal": "InProceedings of the 2nd Workshop on Trustworthy Natural\nLanguage Processing (TrustNLP 2022), pages 26\u201342."
      },
      {
        "tag": "Cao et\u00a0al. (2023)",
        "title": "Assessing cross-cultural alignment between ChatGPT and human\nsocieties: An empirical study.",
        "authors": "Yong Cao, Li\u00a0Zhou, Seolhwa Lee, Laura Cabello, Min Chen, and Daniel\nHershcovich. 2023.",
        "journal": "InProceedings of the First Workshop on Cross-Cultural\nConsiderations in NLP (C3NLP), pages 53\u201367."
      },
      {
        "tag": "Santurkar et\u00a0al. (2023)",
        "title": "Whose opinions do language models reflect?",
        "authors": "Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, and\nTatsunori Hashimoto. 2023.",
        "journal": "arXiv preprint arXiv:2303.17548."
      }
    ]
  },
  "S2.p2": {
    "text": "These past studies have quantified the alignment of LMs through their responses to cultural surveys Hofstede ( 1984 ); Haerpfer et\u00a0al. ( 2021 ); Graham et\u00a0al. ( 2011 ); Guerra and Giner-Sorolla ( 2010 ) , where LMs were probed using survey type of questions in a QA setting (e.g., \u2018Is sex before marriage acceptable in China?\u2019 ), or cloze-style questions reformulated from these surveys (e.g., \u2018In China, sex before marriage is [acceptable/unacceptable]\u2019 ). Wang et\u00a0al. ( 2023b ) and Masoud et\u00a0al. ( 2023 ) have shown that LMs reflect values and opinions aligned with Western culture when probed with such surveys, which persists across multiple languages. Report issue for preceding element",
    "masked_text": "These past studies have quantified the alignment of LMs through their responses to cultural surveys [CITATION], where LMs were probed using survey type of questions in a QA setting (e.g., \u2018Is sex before marriage acceptable in China?\u2019), or cloze-style questions reformulated from these surveys (e.g., \u2018In China, sex before marriage is [acceptable/unacceptable]\u2019). [CITATION] and [CITATION] have shown that LMs reflect values and opinions aligned with Western culture when probed with such surveys, which persists across multiple languages.Report issue for preceding element",
    "citations": [
      {
        "tag": "Guerra and Giner-Sorolla (2010)",
        "title": "The community, autonomy, and divinity scale (cads): A new tool for\nthe cross-cultural study of morality.",
        "authors": "Valeschka\u00a0M Guerra and Roger Giner-Sorolla. 2010.",
        "journal": "Journal of cross-cultural psychology, 41(1):35\u201350."
      },
      {
        "tag": "Haerpfer et\u00a0al. (2021)",
        "title": "World values survey: Round seven.",
        "authors": "Christian Haerpfer, Ronald Inglehart, Alejandro Moreno, Christian Welzel,\nKseniya Kizilova, Jaime Diez-Medrano, Marta Lagos, Pippa Norris, E\u00a0Ponarin,\nand B\u00a0Puranen. 2021.",
        "journal": "JD Systems Institute & WVSA Secretariat. Data File Version,\n2(0)."
      },
      {
        "tag": "Wang et\u00a0al. (2023b)",
        "title": "Not all countries celebrate thanksgiving: On the cultural dominance\nin large language models.",
        "authors": "Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jen-tse Huang, Zhaopeng\nTu, and Michael\u00a0R Lyu. 2023b.",
        "journal": "arXiv preprint arXiv:2310.12481."
      },
      {
        "tag": "Masoud et\u00a0al. (2023)",
        "title": "Cultural alignment in large language models: An explanatory analysis\nbased on hofstede\u2019s cultural dimensions.",
        "authors": "Reem\u00a0I Masoud, Ziquan Liu, Martin Ferianc, Philip Treleaven, and Miguel\nRodrigues. 2023.",
        "journal": "arXiv preprint arXiv:2309.12342."
      },
      {
        "tag": "Graham et\u00a0al. (2011)",
        "title": "Mapping the moral domain.",
        "authors": "Jesse Graham, Brian\u00a0A Nosek, Jonathan Haidt, Ravi Iyer, Spassena Koleva, and\nPeter\u00a0H Ditto. 2011.",
        "journal": "Journal of personality and social psychology, 101(2):366."
      },
      {
        "tag": "Hofstede (1984)",
        "title": "Culture\u2019s consequences: International differences in\nwork-related values, volume\u00a05.",
        "authors": "Geert Hofstede. 1984.",
        "journal": "Sage."
      }
    ]
  },
  "S2.p3": {
    "text": "Another line of work explored how well LMs store culture-related commonsense knowledge by probing for their ability to answer geo-diverse facts (e.g., \u2018The color of the bridal dress in China is [red/white]\u2019 ) Nguyen et\u00a0al. ( 2023 ); Yin et\u00a0al. ( 2022 ); Keleg and Magdy ( 2023 ) . Other studies probe LMs for cultural norms such as culinary customs Palta and Rudinger ( 2023 ) and time expressions Shwartz ( 2022 ) . Huang and Yang ( 2023 ) studied social norm reasoning as an entailment classification task. Report issue for preceding element",
    "masked_text": "Another line of work explored how well LMs store culture-related commonsense knowledge by probing for their ability to answer geo-diverse facts (e.g., \u2018The color of the bridal dress in China is [red/white]\u2019) [CITATION]. Other studies probe LMs for cultural norms such as culinary customs [CITATION] and time expressions [CITATION]. [CITATION] studied social norm reasoning as an entailment classification task.Report issue for preceding element",
    "citations": [
      {
        "tag": "Huang and Yang (2023)",
        "title": "Culturally aware natural language inference.",
        "authors": "Jing Huang and Diyi Yang. 2023.",
        "journal": "InFindings of the Association for Computational Linguistics:\nEMNLP 2023, pages 7591\u20137609."
      },
      {
        "tag": "Palta and Rudinger (2023)",
        "title": "FORK: A bite-sized test set for probing culinary cultural biases in\ncommonsense reasoning models.",
        "authors": "Shramay Palta and Rachel Rudinger. 2023.",
        "journal": "InFindings of the Association for Computational Linguistics:\nACL 2023, pages 9952\u20139962."
      },
      {
        "tag": "Shwartz (2022)",
        "title": "Good night at 4 pm?! time expressions in different cultures.",
        "authors": "Vered Shwartz. 2022.",
        "journal": "InFindings of the Association for Computational Linguistics:\nACL 2022, pages 2842\u20132853."
      },
      {
        "tag": "Nguyen et\u00a0al. (2023)",
        "title": "Extracting cultural commonsense knowledge at scale.",
        "authors": "Tuan-Phong Nguyen, Simon Razniewski, Aparna Varde, and Gerhard Weikum. 2023.",
        "journal": "InProceedings of the ACM Web Conference 2023, pages\n1907\u20131917."
      },
      {
        "tag": "Keleg and Magdy (2023)",
        "title": "DLAMA: A framework for curating culturally diverse facts for\nprobing the knowledge of pretrained language models.",
        "authors": "Amr Keleg and Walid Magdy. 2023.",
        "journal": "arXiv preprint arXiv:2306.05076."
      },
      {
        "tag": "Yin et\u00a0al. (2022)",
        "title": "GeoMLAMA: Geo-diverse commonsense probing on multilingual\npre-trained language models.",
        "authors": "Da\u00a0Yin, Hritik Bansal, Masoud Monajatipoor, Liunian\u00a0Harold Li, and Kai-Wei\nChang. 2022.",
        "journal": "InProceedings of the 2022 Conference on Empirical Methods in\nNatural Language Processing, pages 2039\u20132055."
      }
    ]
  },
  "S2.p4": {
    "text": "Different from existing work, we study how LMs behave with entities that exhibit cultural variation (e.g., people names, food dishes, etc.). We extract and annotate an extensive list of cultural entities from Wikidata and CommonCrawl, which in turn enables the evaluation of LMs using naturally-occurring prompts that we collect from social media, instead of the artificial prompts used in survey-based studies. Our dataset provides a foundation for measuring biases in various setups, including stereotype examination in LM-generated content, fairness evaluation on NER and sentiment analysis tasks, and text-infilling tests (\u00a7 4 ), that complement the existing literature. We refer readers to our background section in Appendix A , and the excellent survey of Gallegos et\u00a0al. ( 2023 ) , for information on other bias-related issues studied in the past. Report issue for preceding element",
    "masked_text": "Different from existing work, we study how LMs behave with entities that exhibit cultural variation (e.g., people names, food dishes, etc.). We extract and annotate an extensive list of cultural entities from Wikidata and CommonCrawl, which in turn enables the evaluation of LMs using naturally-occurring prompts that we collect from social media, instead of the artificial prompts used in survey-based studies. Our dataset provides a foundation for measuring biases in various setups, including stereotype examination in LM-generated content, fairness evaluation on NER and sentiment analysis tasks, and text-infilling tests (\u00a7 4), that complement the existing literature. We refer readers to our background section in Appendix A, and the excellent survey of [CITATION], for information on other bias-related issues studied in the past.Report issue for preceding element",
    "citations": [
      {
        "tag": "Gallegos et\u00a0al. (2023)",
        "title": "Bias and fairness in large language models: A survey.",
        "authors": "Isabel\u00a0O Gallegos, Ryan\u00a0A Rossi, Joe Barrow, Md\u00a0Mehrab Tanjim, Sungchul Kim,\nFranck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen\u00a0K Ahmed. 2023.",
        "journal": "arXiv preprint arXiv:2309.00770."
      }
    ]
  },
  "S3.p1": {
    "text": "We describe the construction process of CAMeL , starting by collecting entities that exhibit cultural variation.\nWe then obtain prompts from Twitter/X data as natural contexts for these entities, which enable various testing setups for measuring cultural biases in LMs (see examples in Figure 2 ). Report issue for preceding element",
    "masked_text": "We describe the construction process of CAMeL, starting by collecting entities that exhibit cultural variation. We then obtain prompts from Twitter/X data as natural contexts for these entities, which enable various testing setups for measuring cultural biases in LMs (see examples in Figure 2).Report issue for preceding element",
    "citations": []
  },
  "S3.SS1.p1": {
    "text": "We consider eight types of culturally-relevant entities that include both proper nouns and common nouns: person names , food dishes , beverages , clothing items , locations (cities) , literary authors , religious places of worship , and sports clubs .\nTo obtain a comprehensive set of these culturally diverse entities, beyond ones found in the typical lists on the web or generated by LMs when prompted to list them, we first derive entities from the Wikidata knowledge base Vrande\u010di\u0107 and Kr\u00f6tzsch ( 2014 ) then perform pattern-based entity extraction from the CommonCrawl corpus. Extracted results are manually filtered and annotated to ensure quality. Report issue for preceding element",
    "masked_text": "We consider eight types of culturally-relevant entities that include both proper nouns and common nouns: person names, food dishes, beverages, clothing items, locations (cities), literary authors, religious places of worship, and sports clubs. To obtain a comprehensive set of these culturally diverse entities, beyond ones found in the typical lists on the web or generated by LMs when prompted to list them, we first derive entities from the Wikidata knowledge base [CITATION] then perform pattern-based entity extraction from the CommonCrawl corpus. Extracted results are manually filtered and annotated to ensure quality.Report issue for preceding element",
    "citations": [
      {
        "tag": "Vrande\u010di\u0107 and Kr\u00f6tzsch (2014)",
        "title": "Wikidata: a free collaborative knowledgebase.",
        "authors": "Denny Vrande\u010di\u0107 and Markus Kr\u00f6tzsch. 2014.",
        "journal": "Communications of the ACM, 57(10):78\u201385."
      }
    ]
  },
  "S3.SS1.SSS0.Px1.p1": {
    "text": "For each entity type, we manually identified relevant Wikidata classes under which common entities are grouped in the knowledge base (e.g., \" food \", \" city \", \" drink \", etc.). We then extract all entities registered under those classes that have a label in Arabic language. For Location, Authors, and Sports Club entities, it was possible to extract all entities per each country of the Arab world or the Western world (Western Europe and North America), as they are linked to either a country of origin or a nationality label in the knowledge base. However, for other entity types, we had to manually classify them into Arab and Western lists due to the lack of such demographic labels (see Appendix B.1 for details). Wikidata\u2019s coverage of entities in Arabic was extensive for locations, sports clubs, and authors (see Figure 3 ), but more limited for the other entity types. Report issue for preceding element",
    "masked_text": "For each entity type, we manually identified relevant Wikidata classes under which common entities are grouped in the knowledge base (e.g., \"food\", \"city\", \"drink\", etc.). We then extract all entities registered under those classes that have a label in Arabic language. For Location, Authors, and Sports Club entities, it was possible to extract all entities per each country of the Arab world or the Western world (Western Europe and North America), as they are linked to either a country of origin or a nationality label in the knowledge base. However, for other entity types, we had to manually classify them into Arab and Western lists due to the lack of such demographic labels (see Appendix B.1 for details). Wikidata\u2019s coverage of entities in Arabic was extensive for locations, sports clubs, and authors (see Figure 3), but more limited for the other entity types.Report issue for preceding element",
    "citations": []
  },
  "S3.SS1.SSS0.Px2.p1": {
    "text": "To expand on entities collected from Wikidata for entity types where coverage was limited, we perform pattern-based entity extraction on the Arabic subset of the CommonCrawl corpus. Pattern-matching is a simple yet effective method Chiticariu et\u00a0al. ( 2013 ); Freitag et\u00a0al. ( 2022 ) ; and importantly, it avoids using any LMs in the construction of the dataset that will be used for evaluating LMs. For each entity type, we manually design 5 to 10 generic patterns composed of nouns or noun-verb expressions typically followed by a specific entity. For example, the pattern \\setcode utf-8\" \\< \u0634\u0642\u064a\u0642\u0629 \u062a\u062f\u0639\u0649>\" (sister named) is likely to be followed by a female name. We used multiple Arabic verb conjugations of the same pattern to reflect number and gender 1 1 1 In Arabic, verbs are conjugated to reflect gender (male or female) and number (singular, dual, or plural) of the subject. . Using such patterns, we perform pattern matching and extract up to two words that appear after a detected pattern. We avoid using more specific and longer patterns to ensure wider coverage of entities (i.e., higher recall lower precision). This process returns between 5k and 10k unique extractions for each entity type, which are then manually filtered and annotated to achieve high precision. We split name and clothing entities into male/female categories to match Arabic\u2019s gendered grammar, without intending to exclude other gender identities Stanczak and Augenstein ( 2021 ) . More details are in Appendix B.2 . Report issue for preceding element",
    "masked_text": "To expand on entities collected from Wikidata for entity types where coverage was limited, we perform pattern-based entity extraction on the Arabic subset of the CommonCrawl corpus. Pattern-matching is a simple yet effective method [CITATION]; and importantly, it avoids using any LMs in the construction of the dataset that will be used for evaluating LMs. For each entity type, we manually design 5 to 10 generic patterns composed of nouns or noun-verb expressions typically followed by a specific entity. For example, the pattern \\setcodeutf-8\"\\<\u0634\u0642\u064a\u0642\u0629 \u062a\u062f\u0639\u0649>\" (sister named) is likely to be followed by a female name. We used multiple Arabic verb conjugations of the same pattern to reflect number and gender111In Arabic, verbs are conjugated to reflect gender (male or female) and number (singular, dual, or plural) of the subject.. Using such patterns, we perform pattern matching and extract up to two words that appear after a detected pattern. We avoid using more specific and longer patterns to ensure wider coverage of entities (i.e., higher recall lower precision). This process returns between 5k and 10k unique extractions for each entity type, which are then manually filtered and annotated to achieve high precision. We split name and clothing entities into male/female categories to match Arabic\u2019s gendered grammar, without intending to exclude other gender identities [CITATION]. More details are in Appendix B.2.Report issue for preceding element",
    "citations": [
      {
        "tag": "Stanczak and Augenstein (2021)",
        "title": "A survey on gender bias in natural language processing.",
        "authors": "Karolina Stanczak and Isabelle Augenstein. 2021.",
        "journal": "arXiv preprint arXiv:2112.14168."
      },
      {
        "tag": "Freitag et\u00a0al. (2022)",
        "title": "Valet: Rule-based\ninformation extraction for rapid deployment.",
        "authors": "Dayne Freitag, John Cadigan, Robert Sasseen, and Paul Kalmar. 2022.",
        "journal": "InProceedings of the Thirteenth Language Resources and\nEvaluation Conference, pages 524\u2013533, Marseille, France. European Language\nResources Association."
      },
      {
        "tag": "Chiticariu et\u00a0al. (2013)",
        "title": "Rule-based information\nextraction is dead! long live rule-based information extraction systems!",
        "authors": "Laura Chiticariu, Yunyao Li, and Frederick\u00a0R. Reiss. 2013.",
        "journal": "InProceedings of the 2013 Conference on Empirical Methods in\nNatural Language Processing, pages 827\u2013832, Seattle, Washington, USA.\nAssociation for Computational Linguistics."
      }
    ]
  },
  "S3.SS1.SSS0.Px3.p1": {
    "text": "We hired two undergraduate students who are native Arabic speakers and paid them at the rate of $18 per hour to classify the extractions into: Arab culture (Arab countries), Western culture (European and North American countries), other foreign culture , not culture-specific , or non-entities . For example, when annotating clothing items, we consider Arab entities as traditional/ethnic wear within the Arab world (e.g., Jellabiya, Dishdasha, etc. ), and Western entities as terms that refer to specific styles/types of clothing prevalent in the Western world (e.g., Khaki, Hoodie, etc. ). The inter-annotator agreement is 0.927 by Cohen\u2019s Kappa. The small number of cases of disagreements were discussed between the annotators to decide on the final label. Annotation required \u223c similar-to \\sim \u223c 60 minutes per 1k extractions. About 15-20% of entities extracted from CommonCrawl overlap with those in Wikidata. CAMeL covers both frequently encountered and less frequent entities (Figure 4 ). Report issue for preceding element",
    "masked_text": "We hired two undergraduate students who are native Arabic speakers and paid them at the rate of $18 per hour to classify the extractions into: Arab culture (Arab countries), Western culture (European and North American countries), other foreign culture, not culture-specific, or non-entities. For example, when annotating clothing items, we consider Arab entities as traditional/ethnic wear within the Arab world (e.g., Jellabiya, Dishdasha, etc.), and Western entities as terms that refer to specific styles/types of clothing prevalent in the Western world (e.g., Khaki, Hoodie, etc.). The inter-annotator agreement is 0.927 by Cohen\u2019s Kappa. The small number of cases of disagreements were discussed between the annotators to decide on the final label. Annotation required \u223csimilar-to\\sim\u223c60 minutes per 1k extractions. About 15-20% of entities extracted from CommonCrawl overlap with those in Wikidata. CAMeL covers both frequently encountered and less frequent entities (Figure 4).Report issue for preceding element",
    "citations": []
  },
  "S3.SS2.p1": {
    "text": "One of our primary objectives is to assess whether LMs can appropriately distinguish between Arab and Western entities when prompted by culturally specific contexts. To achieve this, we create prompts that embed an Arab cultural reference, ensuring they provide contexts uniquely suited for Arab entities. This allows to gauge the LM\u2019s cultural adaptation ability. Additionally, we create prompts with neutral contexts, enabling us to determine the default cultural leanings of LMs. Hence, CAMeL prompts are split across two types: culturally-contextualized prompts ( CAMeL-Co ) and culturally-agnostic prompts ( CAMeL-Ag ). Table 1 offers contrasting examples from each. Report issue for preceding element",
    "masked_text": "One of our primary objectives is to assess whether LMs can appropriately distinguish between Arab and Western entities when prompted by culturally specific contexts. To achieve this, we create prompts that embed an Arab cultural reference, ensuring they provide contexts uniquely suited for Arab entities. This allows to gauge the LM\u2019s cultural adaptation ability. Additionally, we create prompts with neutral contexts, enabling us to determine the default cultural leanings of LMs. Hence, CAMeL prompts are split across two types: culturally-contextualized prompts (CAMeL-Co) and culturally-agnostic prompts (CAMeL-Ag). Table 1 offers contrasting examples from each.Report issue for preceding element",
    "citations": []
  },
  "S3.SS2.SSS0.Px1.p1": {
    "text": "To ensure we evaluate LMs in scenarios that mirror actual language uses, we construct our prompts from natural contexts that we retrieve from Twitter/X, rather than crowdsourcing prompts Nadeem et\u00a0al. ( 2021a ); Nangia et\u00a0al. ( 2020a ) . We employ two keyword search strategies to retrieve tweets that reflect an Arab cultural context for each entity category. First, we use 20 randomly sampled Arab entities from our lists as search queries to capture discussions about culturally-relevant entities. We further refine our search using one or two manually-designed patterns of adjective phrases that directly reference an Arab entity (e.g., \\setcode utf-8\" \\< \u0644\u0644\u0643\u0627\u062a\u0628 \u0627\u0644\u0639\u0631\u0628\u064a>\" (by the Arab author) ). We search for tweets over the period of 8/1/2023 to 9/30/2023 to avoid overlap with the data LMs may have been pre-trained on. Retrieved tweets are manually inspected to select ones with suitable Arab cultural contexts. From these, we created 250 CAMeL-Co prompts by replacing the original context entities with a [MASK] token. Similarly, we constructed 378 prompts for CAMeL-Ag using generic patterns as search queries that do not contain any cultural reference (see Appendix C ). Report issue for preceding element",
    "masked_text": "To ensure we evaluate LMs in scenarios that mirror actual language uses, we construct our prompts from natural contexts that we retrieve from Twitter/X, rather than crowdsourcing prompts [CITATION]. We employ two keyword search strategies to retrieve tweets that reflect an Arab cultural context for each entity category. First, we use 20 randomly sampled Arab entities from our lists as search queries to capture discussions about culturally-relevant entities. We further refine our search using one or two manually-designed patterns of adjective phrases that directly reference an Arab entity (e.g., \\setcodeutf-8\"\\<\u0644\u0644\u0643\u0627\u062a\u0628 \u0627\u0644\u0639\u0631\u0628\u064a>\" (by the Arab author)). We search for tweets over the period of 8/1/2023 to 9/30/2023 to avoid overlap with the data LMs may have been pre-trained on. Retrieved tweets are manually inspected to select ones with suitable Arab cultural contexts. From these, we created 250 CAMeL-Co prompts by replacing the original context entities with a [MASK] token. Similarly, we constructed 378 prompts for CAMeL-Ag using generic patterns as search queries that do not contain any cultural reference (see Appendix C).Report issue for preceding element",
    "citations": [
      {
        "tag": "Nadeem et\u00a0al. (2021a)",
        "title": "Stereoset: Measuring stereotypical bias in pretrained language\nmodels.",
        "authors": "Moin Nadeem, Anna Bethke, and Siva Reddy. 2021a.",
        "journal": "InProceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing (Volume 1: Long Papers), pages 5356\u20135371."
      },
      {
        "tag": "Nangia et\u00a0al. (2020a)",
        "title": "CrowS-pairs: A challenge dataset for measuring social biases in masked\nlanguage models.",
        "authors": "Nikita Nangia, Clara Vania, Rasika Bhalerao, and Samuel\u00a0R. Bowman.\n2020a.",
        "journal": "InProceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pages 1953\u20131967, Online. Association\nfor Computational Linguistics."
      }
    ]
  },
  "S3.SS2.SSS0.Px2.p1": {
    "text": "To support fairness evaluation of LMs on sentiment analysis, the prompts were labeled by the annotators for positive, negative, or neutral sentiment. The inter-annotator agreement is 0.954 as measured by Cohen\u2019s Kappa. More details and statistics are provided in Appendix C.3 . Report issue for preceding element",
    "masked_text": "To support fairness evaluation of LMs on sentiment analysis, the prompts were labeled by the annotators for positive, negative, or neutral sentiment. The inter-annotator agreement is 0.954 as measured by Cohen\u2019s Kappa. More details and statistics are provided in Appendix C.3.Report issue for preceding element",
    "citations": []
  },
  "S4.p1": {
    "text": "Using CAMeL , we measure cultural biases of several monolingual and multilingual LMs (\u00a7 4.1 ). First, we analyze stereotypes in LM-generated stories (\u00a7 4.2 ). We then examine cross-cultural fairness of LMs on the NER and Sentiment Analysis tasks (\u00a7 4.3 ). Finally, we benchmark the capability of LMs on culturally appropriate text-infilling (\u00a7 4.4 ). Report issue for preceding element",
    "masked_text": "Using CAMeL, we measure cultural biases of several monolingual and multilingual LMs (\u00a74.1). First, we analyze stereotypes in LM-generated stories (\u00a74.2). We then examine cross-cultural fairness of LMs on the NER and Sentiment Analysis tasks (\u00a74.3). Finally, we benchmark the capability of LMs on culturally appropriate text-infilling (\u00a74.4).Report issue for preceding element",
    "citations": []
  },
  "S4.SS1.p1": {
    "text": "We consider LMs that have been intentionally trained for Arabic . For monolingual LMs, we use AraBERT Antoun et\u00a0al. ( 2020 ) , ARBERT Abdul-Mageed et\u00a0al. ( 2021 ) , and CAMeLBERT Inoue et\u00a0al. ( 2021 ) ; we compare CAMeLBERT to its variants trained exclusively on Dialectal Arabic ( CAMeLBERT-DA ) or Modern Standard Arabic ( CAMeLBERT-MSA ). Additionally, we use models trained on Arabic tweets such as MARBERT Abdul-Mageed et\u00a0al. ( 2021 ) and AraBERT-T . We also include AraGPT2 Antoun et\u00a0al. ( 2021 ) . For multilingual LMs, besides mBERT , XLM-R Conneau et\u00a0al. ( 2020 ) , BLOOM Scao et\u00a0al. ( 2022 ) , GPT-3.5 and GPT-4 , we use Arabic-English bilingual JAIS Sengupta et\u00a0al. ( 2023 ) , GigaBERT and GigaBERT-CS Lan et\u00a0al. ( 2020 ) , which was further trained on synthetic Arabic-English Code-Switched data. We also use AceGPT Huang et\u00a0al. ( 2023 ) , an instruction-tuned version of Llama2 Touvron et\u00a0al. ( 2023 ) on localized Arabic instructions. Lastly, we use mT5 X \u2062 X \u2062 L \ud835\udc4b \ud835\udc4b \ud835\udc3f {}_{XXL} start_FLOATSUBSCRIPT italic_X italic_X italic_L end_FLOATSUBSCRIPT Xue et\u00a0al. ( 2021 ) and its recent instruction-tuned counterpart Aya \u00dcst\u00fcn et\u00a0al. ( 2024 ) . We use the base ( B \ud835\udc35 {}_{B} start_FLOATSUBSCRIPT italic_B end_FLOATSUBSCRIPT ) and large ( L \ud835\udc3f {}_{L} start_FLOATSUBSCRIPT italic_L end_FLOATSUBSCRIPT ) versions whenever available. More details about all the LMs used can be found in Appendix D . Report issue for preceding element",
    "masked_text": "We consider LMs that have been intentionally trained for Arabic. For monolingual LMs, we use AraBERT [CITATION], ARBERT [CITATION], and CAMeLBERT [CITATION]; we compare CAMeLBERT to its variants trained exclusively on Dialectal Arabic (CAMeLBERT-DA) or Modern Standard Arabic (CAMeLBERT-MSA). Additionally, we use models trained on Arabic tweets such as MARBERT [CITATION] and AraBERT-T. We also include AraGPT2 [CITATION]. For multilingual LMs, besides mBERT, XLM-R [CITATION], BLOOM [CITATION], GPT-3.5 and GPT-4, we use Arabic-English bilingual JAIS [CITATION], GigaBERT and GigaBERT-CS [CITATION], which was further trained on synthetic Arabic-English Code-Switched data. We also use AceGPT [CITATION], an instruction-tuned version of Llama2 [CITATION] on localized Arabic instructions. Lastly, we use mT5X\u2062X\u2062L\ud835\udc4b\ud835\udc4b\ud835\udc3f{}_{XXL}start_FLOATSUBSCRIPT italic_X italic_X italic_L end_FLOATSUBSCRIPT [CITATION] and its recent instruction-tuned counterpart Aya [CITATION]. We use the base (B\ud835\udc35{}_{B}start_FLOATSUBSCRIPT italic_B end_FLOATSUBSCRIPT) and large (L\ud835\udc3f{}_{L}start_FLOATSUBSCRIPT italic_L end_FLOATSUBSCRIPT) versions whenever available. More details about all the LMs used can be found in Appendix D.Report issue for preceding element",
    "citations": [
      {
        "tag": "Huang et\u00a0al. (2023)",
        "title": "AceGPT, localizing large language models in Arabic.",
        "authors": "Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song,\nZhihong Chen, Abdulmohsen Alharthi, Bang An, Ziche Liu, et\u00a0al. 2023.",
        "journal": "arXiv preprint arXiv:2309.12053."
      },
      {
        "tag": "Antoun et\u00a0al. (2021)",
        "title": "AraGPT2: Pre-trained transformer for arabic language generation.",
        "authors": "Wissam Antoun, Fady Baly, and Hazem Hajj. 2021.",
        "journal": "InProceedings of the Sixth Arabic Natural Language Processing\nWorkshop, pages 196\u2013207."
      },
      {
        "tag": "Inoue et\u00a0al. (2021)",
        "title": "The interplay of variant, size, and task type in arabic pre-trained\nlanguage models.",
        "authors": "Go\u00a0Inoue, Bashar Alhafni, Nurpeiis Baimukan, Houda Bouamor, and Nizar Habash.\n2021.",
        "journal": "InProceedings of the Sixth Arabic Natural Language Processing\nWorkshop, pages 92\u2013104."
      },
      {
        "tag": "Abdul-Mageed et\u00a0al. (2021)",
        "title": "ARBERT & MARBERT: Deep bidirectional transformers for arabic.",
        "authors": "Muhammad Abdul-Mageed, AbdelRahim Elmadany, et\u00a0al. 2021.",
        "journal": "InProceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing (Volume 1: Long Papers), pages 7088\u20137105."
      },
      {
        "tag": "Lan et\u00a0al. (2020)",
        "title": "An empirical study of pre-trained transformers for arabic information\nextraction.",
        "authors": "Wuwei Lan, Yang Chen, Wei Xu, and Alan Ritter. 2020.",
        "journal": "InProceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pages 4727\u20134734."
      },
      {
        "tag": "Conneau et\u00a0al. (2020)",
        "title": "Unsupervised cross-lingual representation learning at scale.",
        "authors": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume\nWenzek, Francisco Guzm\u00e1n, \u00c9douard Grave, Myle Ott, Luke Zettlemoyer,\nand Veselin Stoyanov. 2020.",
        "journal": "InProceedings of the 58th Annual Meeting of the Association\nfor Computational Linguistics, pages 8440\u20138451."
      },
      {
        "tag": "Touvron et\u00a0al. (2023)",
        "title": "Llama 2: Open foundation and fine-tuned chat models.",
        "authors": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine\nBabaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,\net\u00a0al. 2023.",
        "journal": "arXiv preprint arXiv:2307.09288."
      },
      {
        "tag": "\u00dcst\u00fcn et\u00a0al. (2024)",
        "title": "Aya model: An instruction finetuned open-access multilingual language\nmodel.",
        "authors": "Ahmet \u00dcst\u00fcn, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel\nD\u2019souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr\nKayid, et\u00a0al. 2024.",
        "journal": "arXiv preprint arXiv:2402.07827."
      },
      {
        "tag": "Sengupta et\u00a0al. (2023)",
        "title": "Jais and jais-chat: Arabic-centric foundation and instruction-tuned\nopen generative large language models.",
        "authors": "Neha Sengupta, Sunil\u00a0Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li,\nFajri Koto, Osama\u00a0Mohammed Afzal, Samta Kamboj, Onkar Pandit, Rahul Pal,\net\u00a0al. 2023.",
        "journal": "arXiv preprint arXiv:2308.16149."
      },
      {
        "tag": "Antoun et\u00a0al. (2020)",
        "title": "AraBERT: Transformer-based model for arabic language understanding.",
        "authors": "Wissam Antoun, Fady Baly, and Hazem Hajj. 2020.",
        "journal": "InLREC Workshop Language Resources and Evaluation Conference\n11\u201316 May 2020, page\u00a09."
      },
      {
        "tag": "Xue et\u00a0al. (2021)",
        "title": "mT5: A massively multilingual pre-trained text-to-text transformer.",
        "authors": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya\nSiddhant, Aditya Barua, and Colin Raffel. 2021.",
        "journal": "InProceedings of the 2021 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language\nTechnologies, pages 483\u2013498."
      },
      {
        "tag": "Scao et\u00a0al. (2022)",
        "title": "Bloom: A 176b-parameter open-access multilingual language model.",
        "authors": "Teven\u00a0Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili\u0107,\nDaniel Hesslow, Roman Castagn\u00e9, Alexandra\u00a0Sasha Luccioni, Fran\u00e7ois\nYvon, Matthias Gall\u00e9, et\u00a0al. 2022.",
        "journal": "arXiv preprint arXiv:2211.05100."
      }
    ]
  },
  "S4.SS2.p1": {
    "text": "We examine the potential of GPT-type LMs to reflect stereotypes in their generations when portraying Arab and Western entities. Specifically, we analyze their lexical choices in stories generated about characters with Arab and Western names. Report issue for preceding element",
    "masked_text": "We examine the potential of GPT-type LMs to reflect stereotypes in their generations when portraying Arab and Western entities. Specifically, we analyze their lexical choices in stories generated about characters with Arab and Western names.Report issue for preceding element",
    "citations": []
  },
  "S4.SS2.SSS0.Px1.p1": {
    "text": "For each of the male and female names in CAMeL , we prompt LMs in Arabic to \u201c Generate a story about a character named [PERSON NAME] \u201d. Then, we analyze the frequency of adjective usage by LMs in the stories featuring Arab or Western names. To do so, we extract all adjectives from stories using the Farasa POS tagger Abdelali et\u00a0al. ( 2016 ) and compute their Odds Ratio (OR) Wan et\u00a0al. ( 2023 ) (see Appendix F.1 for the formula). A large OR indicates more odds for an adjective of appearing in Western stories, while a small OR indicates more odds of appearing in Arab ones. We inspect adjectives with the 50 highest and lowest ORs to identify and categorize adjectives that reflect stereotypes based on the work of Cao et\u00a0al. ( 2022a ) , which outlines descriptive adjectives for stereotypical traits (e.g., poor , likeable , etc.) using the Agency-Belief Communion (ABC) framework Koch et\u00a0al. ( 2016 ) . Report issue for preceding element",
    "masked_text": "For each of the male and female names in CAMeL, we prompt LMs in Arabic to \u201cGenerate a story about a character named [PERSON NAME]\u201d. Then, we analyze the frequency of adjective usage by LMs in the stories featuring Arab or Western names. To do so, we extract all adjectives from stories using the Farasa POS tagger [CITATION] and compute their Odds Ratio (OR) [CITATION] (see Appendix F.1 for the formula). A large OR indicates more odds for an adjective of appearing in Western stories, while a small OR indicates more odds of appearing in Arab ones. We inspect adjectives with the 50 highest and lowest ORs to identify and categorize adjectives that reflect stereotypes based on the work of [CITATION], which outlines descriptive adjectives for stereotypical traits (e.g., poor, likeable, etc.) using the Agency-Belief Communion (ABC) framework [CITATION].Report issue for preceding element",
    "citations": [
      {
        "tag": "Abdelali et\u00a0al. (2016)",
        "title": "Farasa: A fast and furious segmenter for arabic.",
        "authors": "Ahmed Abdelali, Kareem Darwish, Nadir Durrani, and Hamdy Mubarak. 2016.",
        "journal": "InProceedings of the 2016 conference of the North American\nchapter of the association for computational linguistics: Demonstrations,\npages 11\u201316."
      },
      {
        "tag": "Koch et\u00a0al. (2016)",
        "title": "The abc of stereotypes about groups: Agency/socioeconomic success,\nconservative\u2013progressive beliefs, and communion.",
        "authors": "Alex Koch, Roland Imhoff, Ron Dotsch, Christian Unkelbach, and Hans Alves.\n2016.",
        "journal": "Journal of personality and social psychology, 110(5):675."
      },
      {
        "tag": "Cao et\u00a0al. (2022a)",
        "title": "Theory-grounded measurement of us social stereotypes in english\nlanguage models.",
        "authors": "Yang Cao, Anna Sotnikova, Hal Daum\u00e9\u00a0III, Rachel Rudinger, and Linda Zou.\n2022a.",
        "journal": "InProceedings of the 2022 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language\nTechnologies, pages 1276\u20131295."
      },
      {
        "tag": "Wan et\u00a0al. (2023)",
        "title": "\u201ckelly is a warm person, joseph is a role model\u201d: Gender biases\nin llm-generated reference letters.",
        "authors": "Yixin Wan, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, and Nanyun\nPeng. 2023.",
        "journal": "InFindings of the Association for Computational Linguistics:\nEMNLP 2023, pages 3730\u20133748."
      }
    ]
  },
  "S4.SS2.SSS0.Px2.p1": {
    "text": "Figure 5 displays the identified adjectives, revealing multiple stereotypical associations. Stories about Arab characters more often cover a theme of poverty with adjectives such as \u201cpoor\u201d persistently used across LMs. On the other hand, the adjective \u201cwealthy\u201d was more likely to appear in Western stories. LMs also tend to use adjectives describing Traditionalism, Dominance (for male names) and Benevolence (for female names) in Arab stories, while using adjectives that reflect Likeability and High-Status in Western stories. We manually inspected stories containing those adjectives, where we found a consistent opening narrative of Arab characters being \u201c born into a poor and modest family \u201d. This was less prevalent Western stories where LMs often portray positive attributes about the character (see examples in Table 2 ). Report issue for preceding element",
    "masked_text": "Figure 5 displays the identified adjectives, revealing multiple stereotypical associations. Stories about Arab characters more often cover a theme of poverty with adjectives such as \u201cpoor\u201d persistently used across LMs. On the other hand, the adjective \u201cwealthy\u201d was more likely to appear in Western stories. LMs also tend to use adjectives describing Traditionalism, Dominance (for male names) and Benevolence (for female names) in Arab stories, while using adjectives that reflect Likeability and High-Status in Western stories. We manually inspected stories containing those adjectives, where we found a consistent opening narrative of Arab characters being \u201cborn into a poor and modest family\u201d. This was less prevalent Western stories where LMs often portray positive attributes about the character (see examples in Table 2).Report issue for preceding element",
    "citations": []
  },
  "S4.SS3.p1": {
    "text": "To examine whether LMs treat Arab and Western entities fairly, we analyze their cross-cultural performance on the tasks of NER and sentiment analysis. We perform this analysis using evaluation sentences that include either Arab or Western entities. Report issue for preceding element",
    "masked_text": "To examine whether LMs treat Arab and Western entities fairly, we analyze their cross-cultural performance on the tasks of NER and sentiment analysis. We perform this analysis using evaluation sentences that include either Arab or Western entities.Report issue for preceding element",
    "citations": []
  },
  "S4.SS3.SSS0.Px1.p1": {
    "text": "We leverage culturally-contextualized prompts ( CAMeL-Co ) which have been manually labelled for sentiment (\u00a7 3.2 ) to create the test data. Specifically, for each of the prompts, we replace the [MASK] token with 50 randomly sampled Arab and Western entities. This generates two distinct culturally-contrasting evaluation sets (one Arab, one Western) for the sentiment analysis experiment, each comprising around 12k sentences. For NER, we use the subset of 5.7k sentences that contain either person names or locations in the evaluation. Report issue for preceding element",
    "masked_text": "We leverage culturally-contextualized prompts (CAMeL-Co) which have been manually labelled for sentiment (\u00a73.2) to create the test data. Specifically, for each of the prompts, we replace the [MASK] token with 50 randomly sampled Arab and Western entities. This generates two distinct culturally-contrasting evaluation sets (one Arab, one Western) for the sentiment analysis experiment, each comprising around 12k sentences. For NER, we use the subset of 5.7k sentences that contain either person names or locations in the evaluation.Report issue for preceding element",
    "citations": []
  },
  "S4.SS3.SSS0.Px1.p2": {
    "text": "We create models capable of performing Arabic NER and sentiment prediction by fine-tuning LMs on datasets commonly used in Arabic NLU benchmarks Elmadany et\u00a0al. ( 2023 ); Abdul-Mageed et\u00a0al. ( 2021 ) . We use the ANERCorp Benajiba et\u00a0al. ( 2007 ) dataset for NER (name and location tags were used only) and HARD dataset Elnagar et\u00a0al. ( 2018 ) for sentiment analysis. For GPT-type LMs, we perform in-context learning with 5-shot examples (see prompts in Appendix F.2 ). Report issue for preceding element",
    "masked_text": "We create models capable of performing Arabic NER and sentiment prediction by fine-tuning LMs on datasets commonly used in Arabic NLU benchmarks [CITATION]. We use the ANERCorp [CITATION] dataset for NER (name and location tags were used only) and HARD dataset [CITATION] for sentiment analysis. For GPT-type LMs, we perform in-context learning with 5-shot examples (see prompts in Appendix F.2).Report issue for preceding element",
    "citations": [
      {
        "tag": "Elnagar et\u00a0al. (2018)",
        "title": "Hotel arabic-reviews dataset construction for sentiment analysis\napplications.",
        "authors": "Ashraf Elnagar, Yasmin\u00a0S Khalifa, and Anas Einea. 2018.",
        "journal": "Intelligent natural language processing: Trends and\napplications, pages 35\u201352."
      },
      {
        "tag": "Benajiba et\u00a0al. (2007)",
        "title": "Anersys: An arabic named entity recognition system based on maximum\nentropy.",
        "authors": "Yassine Benajiba, Paolo Rosso, and Jos\u00e9\u00a0Miguel Bened\u00edruiz. 2007.",
        "journal": "InComputational Linguistics and Intelligent Text Processing:\n8th International Conference, CICLing 2007, Mexico City, Mexico, February\n18-24, 2007. Proceedings 8, pages 143\u2013153. Springer."
      },
      {
        "tag": "Elmadany et\u00a0al. (2023)",
        "title": "ORCA: A\nchallenging benchmark for Arabic language understanding.",
        "authors": "AbdelRahim Elmadany, ElMoatez\u00a0Billah Nagoudi, and Muhammad Abdul-Mageed. 2023.",
        "journal": "InFindings of the Association for Computational Linguistics:\nACL 2023, pages 9559\u20139586, Toronto, Canada. Association for Computational\nLinguistics."
      },
      {
        "tag": "Abdul-Mageed et\u00a0al. (2021)",
        "title": "ARBERT & MARBERT: Deep bidirectional transformers for arabic.",
        "authors": "Muhammad Abdul-Mageed, AbdelRahim Elmadany, et\u00a0al. 2021.",
        "journal": "InProceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing (Volume 1: Long Papers), pages 7088\u20137105."
      }
    ]
  },
  "S4.SS3.SSS0.Px2.p1": {
    "text": "Figure 6 shows the F1 scores achieved by LMs on recognizing Arab and Western related entities. We find that most LMs perform better when tagging Western person names and locations . Larger discrepancies are observed on locations, reaching up to 20 F1 points of difference. The gap was smaller for tagging of male and female names, where differences were around 5 F1 points. Report issue for preceding element",
    "masked_text": "Figure 6 shows the F1 scores achieved by LMs on recognizing Arab and Western related entities. We find that most LMs perform better when tagging Western person names and locations. Larger discrepancies are observed on locations, reaching up to 20 F1 points of difference. The gap was smaller for tagging of male and female names, where differences were around 5 F1 points.Report issue for preceding element",
    "citations": []
  },
  "S4.SS3.SSS0.Px3.p1": {
    "text": "Following past work on fairness of sentiment classifiers Czarnowska et\u00a0al. ( 2021 ) , we examine differences in false positive and false negative predictions between sentences containing Arab vs. Western entities. This enables closer analysis of whether LMs show more association of Arab or Western entities with positive or negative sentiments, as opposed to comparing F1 scores which had minimal differences. The results are shown in Figure 7 . We observe that nearly all LMs achieve higher false negatives on sentences containing Arab entities, suggesting more false association of Arab entities with negative sentiment . On the other hand, no clear trend of stronger positive sentiment association towards Arab or Western entities is observed. Report issue for preceding element",
    "masked_text": "Following past work on fairness of sentiment classifiers [CITATION], we examine differences in false positive and false negative predictions between sentences containing Arab vs. Western entities. This enables closer analysis of whether LMs show more association of Arab or Western entities with positive or negative sentiments, as opposed to comparing F1 scores which had minimal differences. The results are shown in Figure 7. We observe that nearly all LMs achieve higher false negatives on sentences containing Arab entities, suggesting more false association of Arab entities with negative sentiment. On the other hand, no clear trend of stronger positive sentiment association towards Arab or Western entities is observed.Report issue for preceding element",
    "citations": [
      {
        "tag": "Czarnowska et\u00a0al. (2021)",
        "title": "Quantifying social biases in nlp: A generalization and empirical\ncomparison of extrinsic fairness metrics.",
        "authors": "Paula Czarnowska, Yogarshi Vyas, and Kashif Shah. 2021.",
        "journal": "Transactions of the Association for Computational Linguistics,\n9:1249\u20131267."
      }
    ]
  },
  "S4.SS4.p1": {
    "text": "To test the ability of LMs at adaptation to cultural contexts, we use a likelihood-based score that compares model preference of Western vs. Arab entities as fillings of [MASK] tokens in CAMeL prompts. Report issue for preceding element",
    "masked_text": "To test the ability of LMs at adaptation to cultural contexts, we use a likelihood-based score that compares model preference of Western vs. Arab entities as fillings of [MASK] tokens in CAMeL prompts.Report issue for preceding element",
    "citations": []
  },
  "S4.SS4.SSS0.Px1.p1": {
    "text": "Inspired by the likelihood scoring metric of Nadeem et\u00a0al. ( 2021a ) , we define a C ultural B ias S core (CBS) to measure the level of Western bias in a model LM \u03b8 \ud835\udf03 {}_{\\theta} start_FLOATSUBSCRIPT italic_\u03b8 end_FLOATSUBSCRIPT . The CBS computes the percentage of a model\u2019s preference of Western entities over Arab ones. Consider an entity type D \ud835\udc37 D italic_D and two type-specific sets of Arab entities A = { a i } i = 1 N \ud835\udc34 superscript subscript subscript \ud835\udc4e \ud835\udc56 \ud835\udc56 1 \ud835\udc41 A=\\{a_{i}\\}_{i=1}^{N} italic_A = { italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT and Western entities B = { b j } j = 1 M \ud835\udc35 superscript subscript subscript \ud835\udc4f \ud835\udc57 \ud835\udc57 1 \ud835\udc40 B=\\{b_{j}\\}_{j=1}^{M} italic_B = { italic_b start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT .\nFor a prompt t k subscript \ud835\udc61 \ud835\udc58 t_{k} italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , we compute CBS D \u2062 ( LM \u03b8 , A , B , t k ) subscript CBS \ud835\udc37 subscript LM \ud835\udf03 \ud835\udc34 \ud835\udc35 subscript \ud835\udc61 \ud835\udc58 \\mathrm{CBS}_{D}(\\text{LM}_{\\theta},A,B,t_{k}) roman_CBS start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( LM start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT , italic_A , italic_B , italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) as: Report issue for preceding element 1 N \u00d7 M \u2062 \u2211 i = 1 N \u2211 j = 1 M \ud835\udfd9 \u2062 [ P [ \ud835\ude7c\ud835\ude70\ud835\ude82\ud835\ude7a ] \u2062 ( b j | t k ) > P [ \ud835\ude7c\ud835\ude70\ud835\ude82\ud835\ude7a ] \u2062 ( a i | t k ) ] , 1 \ud835\udc41 \ud835\udc40 superscript subscript \ud835\udc56 1 \ud835\udc41 superscript subscript \ud835\udc57 1 \ud835\udc40 1 delimited-[] subscript \ud835\udc43 delimited-[] \ud835\ude7c\ud835\ude70\ud835\ude82\ud835\ude7a conditional subscript \ud835\udc4f \ud835\udc57 subscript \ud835\udc61 \ud835\udc58 subscript \ud835\udc43 delimited-[] \ud835\ude7c\ud835\ude70\ud835\ude82\ud835\ude7a conditional subscript \ud835\udc4e \ud835\udc56 subscript \ud835\udc61 \ud835\udc58 \\frac{1}{N\\times M}\\sum_{i=1}^{N}\\sum_{j=1}^{M}\\mathbbm{1}[P_{\\mathtt{[MASK]}}%\n(b_{j}|t_{k})>P_{\\mathtt{[MASK]}}(a_{i}|t_{k})], divide start_ARG 1 end_ARG start_ARG italic_N \u00d7 italic_M end_ARG \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT blackboard_1 [ italic_P start_POSTSUBSCRIPT [ typewriter_MASK ] end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) > italic_P start_POSTSUBSCRIPT [ typewriter_MASK ] end_POSTSUBSCRIPT ( italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ] ,",
    "masked_text": "Inspired by the likelihood scoring metric of [CITATION], we define a Cultural Bias Score (CBS) to measure the level of Western bias in a model LM\u03b8\ud835\udf03{}_{\\theta}start_FLOATSUBSCRIPT italic_\u03b8 end_FLOATSUBSCRIPT. The CBS computes the percentage of a model\u2019s preference of Western entities over Arab ones. Consider an entity type D\ud835\udc37Ditalic_D and two type-specific sets of Arab entities A={ai}i=1N\ud835\udc34superscriptsubscriptsubscript\ud835\udc4e\ud835\udc56\ud835\udc561\ud835\udc41A=\\{a_{i}\\}_{i=1}^{N}italic_A = { italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT and Western entities B={bj}j=1M\ud835\udc35superscriptsubscriptsubscript\ud835\udc4f\ud835\udc57\ud835\udc571\ud835\udc40B=\\{b_{j}\\}_{j=1}^{M}italic_B = { italic_b start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT. For a prompt tksubscript\ud835\udc61\ud835\udc58t_{k}italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, we compute CBSD\u2062(LM\u03b8,A,B,tk)subscriptCBS\ud835\udc37subscriptLM\ud835\udf03\ud835\udc34\ud835\udc35subscript\ud835\udc61\ud835\udc58\\mathrm{CBS}_{D}(\\text{LM}_{\\theta},A,B,t_{k})roman_CBS start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( LM start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT , italic_A , italic_B , italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) as: Report issue for preceding element 1N\u00d7M\u2062\u2211i=1N\u2211j=1M\ud835\udfd9\u2062[P[\ud835\ude7c\ud835\ude70\ud835\ude82\ud835\ude7a]\u2062(bj|tk)>P[\ud835\ude7c\ud835\ude70\ud835\ude82\ud835\ude7a]\u2062(ai|tk)],1\ud835\udc41\ud835\udc40superscriptsubscript\ud835\udc561\ud835\udc41superscriptsubscript\ud835\udc571\ud835\udc401delimited-[]subscript\ud835\udc43delimited-[]\ud835\ude7c\ud835\ude70\ud835\ude82\ud835\ude7aconditionalsubscript\ud835\udc4f\ud835\udc57subscript\ud835\udc61\ud835\udc58subscript\ud835\udc43delimited-[]\ud835\ude7c\ud835\ude70\ud835\ude82\ud835\ude7aconditionalsubscript\ud835\udc4e\ud835\udc56subscript\ud835\udc61\ud835\udc58\\frac{1}{N\\times M}\\sum_{i=1}^{N}\\sum_{j=1}^{M}\\mathbbm{1}[P_{\\mathtt{[MASK]}}% (b_{j}|t_{k})>P_{\\mathtt{[MASK]}}(a_{i}|t_{k})],divide start_ARG 1 end_ARG start_ARG italic_N \u00d7 italic_M end_ARG \u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u2211 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT blackboard_1 [ italic_P start_POSTSUBSCRIPT [ typewriter_MASK ] end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) > italic_P start_POSTSUBSCRIPT [ typewriter_MASK ] end_POSTSUBSCRIPT ( italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ] ,",
    "citations": [
      {
        "tag": "Nadeem et\u00a0al. (2021a)",
        "title": "Stereoset: Measuring stereotypical bias in pretrained language\nmodels.",
        "authors": "Moin Nadeem, Anna Bethke, and Siva Reddy. 2021a.",
        "journal": "InProceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th International Joint Conference on\nNatural Language Processing (Volume 1: Long Papers), pages 5356\u20135371."
      }
    ]
  },
  "S4.SS4.SSS0.Px1.p2": {
    "text": "where P [MASK] subscript \ud835\udc43 [MASK] P_{\\texttt{[MASK]}} italic_P start_POSTSUBSCRIPT [MASK] end_POSTSUBSCRIPT is the LM\u2019s probability of an entity filling the masked token. We evaluate LMs with BERT-type architecture using the full prompts with a [MASK] token for text-infilling and GPT-type/T5-type LMs using only the portion of the prompt appearing before the [MASK] . We take the average over all the sub-words for entities tokenized into sub-words. For a set of prompts T = { t k } k = 1 K \ud835\udc47 superscript subscript subscript \ud835\udc61 \ud835\udc58 \ud835\udc58 1 \ud835\udc3e T=\\{t_{k}\\}_{k=1}^{K} italic_T = { italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT , the CBS per entity type for an LM is computed by averaging over all t k \u2208 T subscript \ud835\udc61 \ud835\udc58 \ud835\udc47 t_{k}\\in T italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \u2208 italic_T . LMs are considered more Western-biased as its CBS gets closer to 100%. Report issue for preceding element",
    "masked_text": "where P[MASK]subscript\ud835\udc43[MASK]P_{\\texttt{[MASK]}}italic_P start_POSTSUBSCRIPT [MASK] end_POSTSUBSCRIPT is the LM\u2019s probability of an entity filling the masked token. We evaluate LMs with BERT-type architecture using the full prompts with a [MASK] token for text-infilling and GPT-type/T5-type LMs using only the portion of the prompt appearing before the [MASK]. We take the average over all the sub-words for entities tokenized into sub-words. For a set of prompts T={tk}k=1K\ud835\udc47superscriptsubscriptsubscript\ud835\udc61\ud835\udc58\ud835\udc581\ud835\udc3eT=\\{t_{k}\\}_{k=1}^{K}italic_T = { italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT, the CBS per entity type for an LM is computed by averaging over all tk\u2208Tsubscript\ud835\udc61\ud835\udc58\ud835\udc47t_{k}\\in Titalic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \u2208 italic_T. LMs are considered more Western-biased as its CBS gets closer to 100%.Report issue for preceding element",
    "citations": []
  },
  "S4.SS4.SSS0.Px2.p1": {
    "text": "In addition to using the vanilla prompts, we also experiment with two prompt-adaption techniques that may help in localizing LMs to the relevant Arab culture: (1) Culture Token , where the special token \\< [\u0639\u0631\u0628\u064a]> ([Arab]) is prepended to prompts, and (2) N-shot demos , where randomly sampled Arab entities are prepended to prompts as demonstrations. We make sure the entity being evaluated is not in the demonstrations. Report issue for preceding element",
    "masked_text": "In addition to using the vanilla prompts, we also experiment with two prompt-adaption techniques that may help in localizing LMs to the relevant Arab culture: (1) Culture Token, where the special token \\<[\u0639\u0631\u0628\u064a]> ([Arab]) is prepended to prompts, and (2) N-shot demos, where randomly sampled Arab entities are prepended to prompts as demonstrations. We make sure the entity being evaluated is not in the demonstrations.Report issue for preceding element",
    "citations": []
  },
  "S4.SS4.SSS0.Px3.p1": {
    "text": "Figure 8 show the average CBS across all entity types on culturally-contextualized prompts ( CAMeL-Co ). We provide CBS per each entity type and additional results on CAMeL-Ag in Appendix F.3 . We observe the following key findings: Report issue for preceding element",
    "masked_text": "Figure 8 show the average CBS across all entity types on culturally-contextualized prompts (CAMeL-Co). We provide CBS per each entity type and additional results on CAMeL-Ag in Appendix F.3. We observe the following key findings:Report issue for preceding element",
    "citations": []
  },
  "S4.SS4.SSS0.Px4.p1": {
    "text": "Since CAMeL-Co prompts explicitly refer to Arab culture, an ideal LM is expected to (nearly) always score higher likelihood to Arab entities over Western ones, i.e., with CBS close to 0. However, existing LMs show high average CBS (40-60%), which is on par with their performance on CAMeL-Ag prompts where contexts are neutral. This indicates a struggle in localizing to the appropriate culture in context, and a noticeable preference for Western entities. Report issue for preceding element",
    "masked_text": "Since CAMeL-Co prompts explicitly refer to Arab culture, an ideal LM is expected to (nearly) always score higher likelihood to Arab entities over Western ones, i.e., with CBS close to 0. However, existing LMs show high average CBS (40-60%), which is on par with their performance on CAMeL-Ag prompts where contexts are neutral. This indicates a struggle in localizing to the appropriate culture in context, and a noticeable preference for Western entities.Report issue for preceding element",
    "citations": []
  },
  "S4.SS4.SSS0.Px5.p1": {
    "text": "Surprisingly, although monolingual LMs are trained on Arabic-only data, they still obtain high CBS scores. The reason may be that part of the pre-training data (more in \u00a7 5 ), even if solely in Arabic, often discusses Western topics. Report issue for preceding element",
    "masked_text": "Surprisingly, although monolingual LMs are trained on Arabic-only data, they still obtain high CBS scores. The reason may be that part of the pre-training data (more in \u00a75), even if solely in Arabic, often discusses Western topics. Report issue for preceding element",
    "citations": []
  },
  "S4.SS4.SSS0.Px6.p1": {
    "text": "Most multilingual LMs showed a higher CBS compared with monolingual LMs. This implies that multilingual training could impact cultural relevance of LMs in non-Western languages. We find that embeddings of Arab and Western entities are grouped into distinct clusters by monolingual LMs while mixed up in multilingual LMs (see Appendix G.1 ). Report issue for preceding element",
    "masked_text": "Most multilingual LMs showed a higher CBS compared with monolingual LMs. This implies that multilingual training could impact cultural relevance of LMs in non-Western languages. We find that embeddings of Arab and Western entities are grouped into distinct clusters by monolingual LMs while mixed up in multilingual LMs (see Appendix G.1).Report issue for preceding element",
    "citations": []
  },
  "S4.SS4.SSS0.Px7.p1": {
    "text": "Prompt-adaption techniques can potentially help in localizing LMs to the relevant culture. In particular, prepending Arab demonstrations reduced CBS for most LMs. However, introducing a special culture token had little effect. Report issue for preceding element",
    "masked_text": "Prompt-adaption techniques can potentially help in localizing LMs to the relevant culture. In particular, prepending Arab demonstrations reduced CBS for most LMs. However, introducing a special culture token had little effect.Report issue for preceding element",
    "citations": []
  },
  "S5.p1": {
    "text": "One main contributor to the observed failures of LMs in appropriate cultural adaptation could be the prevalence of Western content in the Arabic pre-training corpora. To gain more insight, we analyze six Arabic corpora that are commonly used in pre-training LMs, comparing their cultural relevance. Report issue for preceding element",
    "masked_text": "One main contributor to the observed failures of LMs in appropriate cultural adaptation could be the prevalence of Western content in the Arabic pre-training corpora. To gain more insight, we analyze six Arabic corpora that are commonly used in pre-training LMs, comparing their cultural relevance.Report issue for preceding element",
    "citations": []
  },
  "S5.SS0.SSS0.Px1.p1": {
    "text": "We use two local Arabic news corpora (1.5B corpus by El-Khair ( 2016 ) ) and Assafir news Antoun et\u00a0al. ( 2020 ) ), an international news corpus (OSIAN by Zeroual et\u00a0al. ( 2019 ) ), the Arabic portion of CommonCrawl (from OSCAR by Su\u00e1rez et\u00a0al. ( 2019 ) ), Arabic Wikipedia, and the 60M Arabic tweets corpus used in training AraBERT-T Antoun et\u00a0al. ( 2020 ) . We train 4-gram LMs using OpenGRM Roark et\u00a0al. ( 2012 ) without smoothing on each corpus, leveraging their frequency count-based nature to directly compare prevalence of cultural contexts and entities across corpora. We then use the trained 4-grams to compute the average CBS for each corpus using CAMeL-Co for analysis. Report issue for preceding element",
    "masked_text": "We use two local Arabic news corpora (1.5B corpus by [CITATION]) and Assafir news [CITATION]), an international news corpus (OSIAN by [CITATION]), the Arabic portion of CommonCrawl (from OSCAR by [CITATION]), Arabic Wikipedia, and the 60M Arabic tweets corpus used in training AraBERT-T [CITATION]. We train 4-gram LMs using OpenGRM [CITATION] without smoothing on each corpus, leveraging their frequency count-based nature to directly compare prevalence of cultural contexts and entities across corpora. We then use the trained 4-grams to compute the average CBS for each corpus using CAMeL-Co for analysis.Report issue for preceding element",
    "citations": [
      {
        "tag": "Su\u00e1rez et\u00a0al. (2019)",
        "title": "Asynchronous pipeline for processing huge corpora on medium to low\nresource infrastructures.",
        "authors": "Pedro Javier\u00a0Ortiz Su\u00e1rez, Beno\u00eet Sagot, and Laurent Romary. 2019.",
        "journal": "In7th Workshop on the Challenges in the Management of Large\nCorpora (CMLC-7). Leibniz-Institut f\u00fcr Deutsche Sprache."
      },
      {
        "tag": "Roark et\u00a0al. (2012)",
        "title": "The opengrm open-source finite-state grammar software libraries.",
        "authors": "Brian Roark, Richard Sproat, Cyril Allauzen, Michael Riley, Jeffrey Sorensen,\nand Terry Tai. 2012.",
        "journal": "InProceedings of the ACL 2012 System Demonstrations, pages\n61\u201366."
      },
      {
        "tag": "El-Khair (2016)",
        "title": "1.5 billion words Arabic corpus.",
        "authors": "Ibrahim\u00a0Abu El-Khair. 2016.",
        "journal": "arXiv preprint arXiv:1611.04033."
      },
      {
        "tag": "Zeroual et\u00a0al. (2019)",
        "title": "OSIAN: Open source international Arabic news corpus-preparation\nand integration into the CLARIN-infrastructure.",
        "authors": "Imad Zeroual, Dirk Goldhahn, Thomas Eckart, and Abdelhak Lakhouaja. 2019.",
        "journal": "InProceedings of the fourth arabic natural language processing\nworkshop, pages 175\u2013182."
      },
      {
        "tag": "Antoun et\u00a0al. (2020)",
        "title": "AraBERT: Transformer-based model for arabic language understanding.",
        "authors": "Wissam Antoun, Fady Baly, and Hazem Hajj. 2020.",
        "journal": "InLREC Workshop Language Resources and Evaluation Conference\n11\u201316 May 2020, page\u00a09."
      }
    ]
  },
  "S5.SS0.SSS0.Px2.p1": {
    "text": "Figure 9 shows the average CBS of 4-gram LMs trained on each corpus. The results suggest that (Arabic) Wikipedia is the most Western-centric among all corpora, despite being often considered as one of the highest-quality sources for pre-training data . This is mostly because a large portion of Arabic Wikipedia articles discuss Western content. International news had the second highest CBS. Interestingly, web-crawled data was the third most Western-centric source. A recent analysis of CommonCrawl by Thompson et\u00a0al. ( 2024 ) has shown that a large fraction of the total web content is machine-translated. This could explain the prevalence of Western content as it may get translated into Arabic from languages such as English. We also find that an English-like grammatical structure of Arabic sentences can incite more Western bias in LMs (see Appendix G.2 ). Local news and Twitter/X corpora had the lowest CBS, suggesting that future work may consider these sources for training more culturally adapted LMs. Report issue for preceding element",
    "masked_text": "Figure 9 shows the average CBS of 4-gram LMs trained on each corpus. The results suggest that (Arabic) Wikipedia is the most Western-centric among all corpora, despite being often considered as one of the highest-quality sources for pre-training data. This is mostly because a large portion of Arabic Wikipedia articles discuss Western content. International news had the second highest CBS. Interestingly, web-crawled data was the third most Western-centric source. A recent analysis of CommonCrawl by [CITATION] has shown that a large fraction of the total web content is machine-translated. This could explain the prevalence of Western content as it may get translated into Arabic from languages such as English. We also find that an English-like grammatical structure of Arabic sentences can incite more Western bias in LMs (see Appendix G.2). Local news and Twitter/X corpora had the lowest CBS, suggesting that future work may consider these sources for training more culturally adapted LMs.Report issue for preceding element",
    "citations": [
      {
        "tag": "Thompson et\u00a0al. (2024)",
        "title": "A shocking amount of the web is machine translated: Insights from\nmulti-way parallelism.",
        "authors": "Brian Thompson, Mehak\u00a0Preet Dhaliwal, Peter Frisch, Tobias Domhan, and Marcello\nFederico. 2024.",
        "journal": "arXiv preprint arXiv:2401.05749."
      }
    ]
  },
  "S6.p1": {
    "text": "We introduced CAMeL , a novel dataset of naturally occurring prompts and culturally-relevant entities as prompt completions across eight entity types. We showed that when operating in Arabic, LMs exhibit bias towards Western entities, failing in appropriate cultural adaptation. LMs also show cultural unfairness on tasks such as NER and sentiment analysis, and stereotypes in generated stories. By releasing CAMeL , we hope to enable the evaluation and development of culturally-aware LMs. Report issue for preceding element",
    "masked_text": "We introduced CAMeL, a novel dataset of naturally occurring prompts and culturally-relevant entities as prompt completions across eight entity types. We showed that when operating in Arabic, LMs exhibit bias towards Western entities, failing in appropriate cultural adaptation. LMs also show cultural unfairness on tasks such as NER and sentiment analysis, and stereotypes in generated stories. By releasing CAMeL, we hope to enable the evaluation and development of culturally-aware LMs.Report issue for preceding element",
    "citations": []
  },
  "Sx1.p1": {
    "text": "We focused on assessing the overall ability of LMs to adapt to Arab cultural contexts and exploring their biases towards Western entities. The entities in CAMeL are therefore primarily categorized as being associated with Arab or Western cultures. However, entities belonging to certain categories, such as food dishes or locations, can be further divided into specific regions and countries within the Arab and Western worlds. This finer-grained categorization could enable analysis of LMs\u2019 ability to distinguish between entities belonging to sub-groups of a particular culture. We leave such detailed factual knowledge exploration of sub-cultural distinctions in LMs for future studies. Report issue for preceding element",
    "masked_text": "We focused on assessing the overall ability of LMs to adapt to Arab cultural contexts and exploring their biases towards Western entities. The entities in CAMeL are therefore primarily categorized as being associated with Arab or Western cultures. However, entities belonging to certain categories, such as food dishes or locations, can be further divided into specific regions and countries within the Arab and Western worlds. This finer-grained categorization could enable analysis of LMs\u2019 ability to distinguish between entities belonging to sub-groups of a particular culture. We leave such detailed factual knowledge exploration of sub-cultural distinctions in LMs for future studies.Report issue for preceding element",
    "citations": []
  },
  "Sx1.p2": {
    "text": "CAMeL only covers the Arabic language and enables the evaluation of model biases with respect to Western vs. Arab cultural entities. The works of Wang et\u00a0al. ( 2023b ) and Masoud et\u00a0al. ( 2023 ) have shown that when probed using cultural surveys in Chinese, Korean, or Slovak, LMs tend to respond with answers reflecting Western values. CAMeL can be extended in the future to such languages by adopting our approach for entity extraction and prompt construction. Report issue for preceding element",
    "masked_text": "CAMeL only covers the Arabic language and enables the evaluation of model biases with respect to Western vs. Arab cultural entities. The works of [CITATION] and [CITATION] have shown that when probed using cultural surveys in Chinese, Korean, or Slovak, LMs tend to respond with answers reflecting Western values. CAMeL can be extended in the future to such languages by adopting our approach for entity extraction and prompt construction.Report issue for preceding element",
    "citations": [
      {
        "tag": "Wang et\u00a0al. (2023b)",
        "title": "Not all countries celebrate thanksgiving: On the cultural dominance\nin large language models.",
        "authors": "Wenxuan Wang, Wenxiang Jiao, Jingyuan Huang, Ruyi Dai, Jen-tse Huang, Zhaopeng\nTu, and Michael\u00a0R Lyu. 2023b.",
        "journal": "arXiv preprint arXiv:2310.12481."
      },
      {
        "tag": "Masoud et\u00a0al. (2023)",
        "title": "Cultural alignment in large language models: An explanatory analysis\nbased on hofstede\u2019s cultural dimensions.",
        "authors": "Reem\u00a0I Masoud, Ziquan Liu, Martin Ferianc, Philip Treleaven, and Miguel\nRodrigues. 2023.",
        "journal": "arXiv preprint arXiv:2309.12342."
      }
    ]
  },
  "Sx1.p3": {
    "text": "We limited the scope of our experiment on stereotypes in generated stories to only the analysis of lexical terms, specifically adjectives. Future work can leverage CAMeL entities to analyze further variations beyond lexical content, such as stylistic features of the generations. We believe that the release of CAMeL entities will be a valuable asset to the research community for exploring biases in generation tasks beyond only story generation. Report issue for preceding element",
    "masked_text": "We limited the scope of our experiment on stereotypes in generated stories to only the analysis of lexical terms, specifically adjectives. Future work can leverage CAMeL entities to analyze further variations beyond lexical content, such as stylistic features of the generations. We believe that the release of CAMeL entities will be a valuable asset to the research community for exploring biases in generation tasks beyond only story generation.Report issue for preceding element",
    "citations": []
  },
  "Sx1.p4": {
    "text": "Our analysis of pre-training corpora was limited to examining the relevance of their cultural content, particularly to understand why LMs fail at adapting to Arab cultural contexts. However, to gain deeper insights into the manifested issues of stereotyping and unfairness, more analyses would be necessary. This involves quantifying the co-occurrences of Arab and Western entities with specific themes (e.g., poverty, negativity, etc.) within the corpora. Further, fine-tuning datasets could also play an additional role in amplifying fairness problems. Future research can leverage CAMeL to examine these issues, building on our initial findings. Report issue for preceding element",
    "masked_text": "Our analysis of pre-training corpora was limited to examining the relevance of their cultural content, particularly to understand why LMs fail at adapting to Arab cultural contexts. However, to gain deeper insights into the manifested issues of stereotyping and unfairness, more analyses would be necessary. This involves quantifying the co-occurrences of Arab and Western entities with specific themes (e.g., poverty, negativity, etc.) within the corpora. Further, fine-tuning datasets could also play an additional role in amplifying fairness problems. Future research can leverage CAMeL to examine these issues, building on our initial findings.Report issue for preceding element",
    "citations": []
  },
  "Sx2.p1": {
    "text": "While LMs must adapt to Arab entities when prompts are specifically grounded in an Arab cultural context, the question of what culture they should default to in neutral contexts is more nuanced. This largely depends on the preferences and backgrounds of users. For instance, Arabic speakers residing in non-Arab countries might prefer Arabic LMs to align with the local culture they identify with. However, current LMs default to Western culture in neutral contexts. The neutral prompts we provide in CAMeL-Ag can serve as a valuable test bed for future studies that aim at aligning LMs to meet the unique cultural preferences of their users. Report issue for preceding element",
    "masked_text": "While LMs must adapt to Arab entities when prompts are specifically grounded in an Arab cultural context, the question of what culture they should default to in neutral contexts is more nuanced. This largely depends on the preferences and backgrounds of users. For instance, Arabic speakers residing in non-Arab countries might prefer Arabic LMs to align with the local culture they identify with. However, current LMs default to Western culture in neutral contexts. The neutral prompts we provide in CAMeL-Ag can serve as a valuable test bed for future studies that aim at aligning LMs to meet the unique cultural preferences of their users.Report issue for preceding element",
    "citations": []
  },
  "Sx2.p2": {
    "text": "Our prompts were derived from naturally occurring social media contexts obtained from Twitter/X. We do not share the original raw tweets but rather modified versions where original entities mentioned by users have been replaced by [MASK] tokens. The prompts are, therefore, anonymized and do not contain any personally identifiable information. The release of CAMeL prompts is exclusively for research purposes, particularly for evaluating the cultural adaptation of LMs. When constructing our prompts, we have carefully selected contexts that do not contain toxic or offensive language. Report issue for preceding element",
    "masked_text": "Our prompts were derived from naturally occurring social media contexts obtained from Twitter/X. We do not share the original raw tweets but rather modified versions where original entities mentioned by users have been replaced by [MASK] tokens. The prompts are, therefore, anonymized and do not contain any personally identifiable information. The release of CAMeL prompts is exclusively for research purposes, particularly for evaluating the cultural adaptation of LMs. When constructing our prompts, we have carefully selected contexts that do not contain toxic or offensive language.Report issue for preceding element",
    "citations": []
  },
  "Sx2.p3": {
    "text": "Arabic is a grammatically gendered language where verbs must be conjugated for either male or female genders in the second and third persons. This linguistic restriction affects how we construct prompts for categories such as names and clothing , leading us to separate these prompts into male and female groups. This follows the approach taken by past work on social biases in languages with grammatical gender distinctions Levy et\u00a0al. ( 2023 ) . It\u2019s important to clarify that this categorization by gender does not aim to define or differentiate gender identities Stanczak and Augenstein ( 2021 ) but is done to reflect the language\u2019s structure accurately. We also note that the aim of our study is to investigate biases in LMs toward Western entities and not the examination of gender biases. Report issue for preceding element",
    "masked_text": "Arabic is a grammatically gendered language where verbs must be conjugated for either male or female genders in the second and third persons. This linguistic restriction affects how we construct prompts for categories such as names and clothing, leading us to separate these prompts into male and female groups. This follows the approach taken by past work on social biases in languages with grammatical gender distinctions [CITATION]. It\u2019s important to clarify that this categorization by gender does not aim to define or differentiate gender identities [CITATION] but is done to reflect the language\u2019s structure accurately. We also note that the aim of our study is to investigate biases in LMs toward Western entities and not the examination of gender biases.Report issue for preceding element",
    "citations": [
      {
        "tag": "Stanczak and Augenstein (2021)",
        "title": "A survey on gender bias in natural language processing.",
        "authors": "Karolina Stanczak and Isabelle Augenstein. 2021.",
        "journal": "arXiv preprint arXiv:2112.14168."
      },
      {
        "tag": "Levy et\u00a0al. (2023)",
        "title": "Comparing biases and the impact of multilingual training across\nmultiple languages.",
        "authors": "Sharon Levy, Neha\u00a0Anna John, Ling Liu, Yogarshi Vyas, Jie Ma, Yoshinari\nFujinuma, Miguel Ballesteros, Vittorio Castelli, and Dan Roth. 2023.",
        "journal": "arXiv preprint arXiv:2305.11242."
      }
    ]
  },
  "Sx3.p1": {
    "text": "The author would like to thank Youssef Naous and Nour Allah El Senary for their help in data annotation. The author also thanks Wissam Antoun for sharing data that facilitated our analysis on pre-training corpora. This research is supported in part by the NSF awards IIS-2144493 and IIS-2052498, ODNI and IARPA via the HIATUS program (contract 2022-22072200004). The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of NSF, ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. Report issue for preceding element",
    "masked_text": "The author would like to thank Youssef Naous and Nour Allah El Senary for their help in data annotation. The author also thanks Wissam Antoun for sharing data that facilitated our analysis on pre-training corpora. This research is supported in part by the NSF awards IIS-2144493 and IIS-2052498, ODNI and IARPA via the HIATUS program (contract 2022-22072200004). The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of NSF, ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.Report issue for preceding element",
    "citations": []
  }
}