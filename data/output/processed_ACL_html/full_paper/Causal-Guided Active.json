{
  "title": "Causal-Guided Active Learning for Debiasing Large Language Models",
  "text": "Large language models (LLMs) are growing to be the foundation of Natural Language Processing. Through the generative pretraining process upon a large-scale corpus, the LLMs have demonstrated impressive performance in understanding the language and conducting complex reasoning tasks Achiam et\u00a0al. ( 2023 ) , demonstrating immense potential in real-world applications. Report issue for preceding element\nHowever, the generative pretraining process is a double-edged sword, as it would also inevitably incur dataset bias into the LLMs such as position bias and stereotype bias Schick et\u00a0al. ( 2021 ); Navigli et\u00a0al. ( 2023 ); Zheng et\u00a0al. ( 2023 ); Shaikh et\u00a0al. ( 2023 ) . This is because, the LLMs only passively learn to model the correlation between contexts in the pretraining corpus, and the pretraining corpus is biased as it reflects the inherent preference or prejudice of human beings.\nFor example, the existence of position bias is due to the subconscious human belief that the first option is better, leading to a higher frequency of the first option in corpora, and LLMs trained to model the corpus distribution would also capture such biased correlation.\nSuch biases would lead to poor generalizability and harmfulness of LLMs Navigli et\u00a0al. ( 2023 ); Huang et\u00a0al. ( 2023 ) .\nFor instance, when an LLM is asked to evaluate which option is better, the LLM may utilize position bias and tend to choose the first option. However, which option is better is completely unrelated to its position. Therefore, when the second option is generally better in some datasets, the performance of the LLM will significantly decline. While biases such as stereotyping bias would make LLMs generate harmful content such as women are less capable in STEM fields, which in turn reinforces harmful stereotypes. Report issue for preceding element\nThese problems highlight the necessity of debiasing LLMs.\nThe key issue to debias LLMs lies in how to recognize the dataset biases and prevent it from utilizing biases during inference. To this end, prevalent methods rely on researchers\u2019 prior knowledge to artificially recognize the potential dataset biases, and then eliminate such biases through aligning or prompt-based regularization Schick et\u00a0al. ( 2021 ); Oba et\u00a0al. ( 2023 ); Liu et\u00a0al. ( 2023b ) . However, due to the diversity and complexity of dataset biases Poliak et\u00a0al. ( 2018 ); Schuster et\u00a0al. ( 2019 ); Schick et\u00a0al. ( 2021 ) , it\u2019s impractical to identify them one by one manually. A vast amount of biases remains unrecognized in different tasks Nie et\u00a0al. ( 2020 ) and new biases are continually being discovered. Report issue for preceding element\nHence, there is an urgent need for methods to automatically identify biases of generative LLMs. However, previous automatic debiasing methods are mainly designed for discriminative models and are hard to adapt to generative LLMs. Moreover, these methods generally rely on a fine-tuning-based process on certain dataset(s) to regularize the model. The finetuning-based debiasing process would lead to over-optimization and undermine the generalizability of LLMs on other tasks Aribandi et\u00a0al. ( 2021 ); Liu et\u00a0al. ( 2023a ) . Report issue for preceding element\nTo address these issues, considering the powerful pattern recognition and inductive ability of LLMs, we explore combining active learning with the causal mechanisms and propose a C asual-guided A ctive L earning (CAL) framework, which utilizes LLMs themselves to automatically and autonomously identify biased samples and induce the bias patterns.\nActive learning aims at selecting the most informative instances, and then querying external information source(s) to label these data points. In the debiasing scenario,\nCAL identifies the biased instances by finding instances where the LLMs fail to model causal invariant semantic relationship among context, then selects the most informative biased instances by finding the instances on which dataset biases have the most influence on the generation of LLMs. The causal invariance can be employed to disentangle the semantic information with dataset biases, as the content of the subsequent text is decided by the semantics of the preceding text (i.e., \u201c causal \u201d), and such relationship exists in all corpora (i.e., \u201c invariant \u201d); on the contrary, although the subsequent text would be correlative to dataset bias, such correlation changes upon different datasets.\nGiven the biased instances, a set of explainable bias patterns is further induced, and we devise a cost-effective and efficient in-context learning (ICL) based method to regularize LLMs using the explainable bias patterns. Report issue for preceding element\nBased on the method of this paper, we construct a Python package to facilitate the automatic identification of dataset bias on Instruct Tuning Datasets. We attempt to discover biased instances and explainable biased patterns from several commonly used instruct-tuning datasets. The code is publicly available at https://github.com/spirit-moon-fly/CAL. Report issue for preceding element\nExperimental results show that our approach can automatically induce various explainable bias patterns (some of them may be unreported), and improve the generalizability and safety of LLMs by using the ICL-based debiasing method based on the bias patterns and biased instances. Report issue for preceding element\nText records and reflects the thoughts of human beings. Inherent biases such as gender and racial biases persist in the human mind, and thus are also reflected in various corpora Schick et\u00a0al. ( 2021 ); Navigli et\u00a0al. ( 2023 ) . Due to potential annotation artifacts, various biases such as position and verbosity biases still broadly exist in task-specific datasets. Report issue for preceding element\nFormally, as shown in Figure 1 (a), given a piece of text X \ud835\udc4b X italic_X , the subsequent text Y \ud835\udc4c Y italic_Y within a corpus \ud835\udc9f \ud835\udc9f \\mathcal{D} caligraphic_D would be affected by two factors: (1) The semantic relationship between X \ud835\udc4b X italic_X and Y \ud835\udc4c Y italic_Y , (2) The existence of dataset bias within \ud835\udc9f \ud835\udc9f \\mathcal{D} caligraphic_D . For example, given X = The physician hired the secretary because \ud835\udc4b The physician hired the secretary because X=\\textbf{The physician hired the secretary because} italic_X = The physician hired the secretary because , due to the existence of gender bias, the following text Y \ud835\udc4c Y italic_Y in the corpus would more likely be he was overwhelmed with clients , rather than she . Such biased relationship characterizes the unwanted correlation between the context brought by dataset bias. In the following sections, for clarity, we denote the semantic relationship as f S \u2062 ( \u22c5 ) subscript \ud835\udc53 \ud835\udc46 \u22c5 f_{S}(\\cdot) italic_f start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( \u22c5 ) , and denote the biased relationship as g B \u2062 ( \u22c5 ) subscript \ud835\udc54 \ud835\udc35 \u22c5 g_{B}(\\cdot) italic_g start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( \u22c5 ) . Hence, given X \ud835\udc4b X italic_X , the conditional distribution of Y \ud835\udc4c Y italic_Y given X \ud835\udc4b X italic_X in corpus \ud835\udc9f \ud835\udc9f \\mathcal{D} caligraphic_D can be formalized as P \u2062 ( Y | X ) = P \u2062 ( f S \u2062 ( X ) , g B \u2062 ( X ) | X ) \ud835\udc43 conditional \ud835\udc4c \ud835\udc4b \ud835\udc43 subscript \ud835\udc53 \ud835\udc46 \ud835\udc4b conditional subscript \ud835\udc54 \ud835\udc35 \ud835\udc4b \ud835\udc4b P(Y|X)=P(f_{S}(X),g_{B}(X)|X) italic_P ( italic_Y | italic_X ) = italic_P ( italic_f start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_X ) , italic_g start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( italic_X ) | italic_X ) . Report issue for preceding element\nThe key difference between the semantic relationship and the biased relationship is that the semantic relationship possesses the causal invariance , while the biased relationship does not. Specifically, for all instances upon all datasets, given preceding text X \ud835\udc4b X italic_X , the subsequent text Y \ud835\udc4c Y italic_Y would be determined by the semantic relationship Pearl et\u00a0al. ( 2000 ); Pearl ( 2009 ) , while the biased relationship only describes certain superficial statistical correlation between X \ud835\udc4b X italic_X and Y \ud835\udc4c Y italic_Y .\nConsider the example where an LLM acts as a judge to assess the responses of two AI assistants, as illustrated in Figure 1 (a): The answer ( Y \ud835\udc4c Y italic_Y ) is determined by the semantic relationship between the prompt X \ud835\udc4b X italic_X and answer Y \ud835\udc4c Y italic_Y . While in the corpus, certain biases such as the position of the responses that show a correlation with the answer can be predictive. However, Y \ud835\udc4c Y italic_Y is not determined by the bias and such a correlation may fail to be predictive in other instances. Hence, as Y \ud835\udc4c Y italic_Y is determined by X \ud835\udc4b X italic_X , their semantic relationship is a \u201ccausal\u201d relationship and invariant upon all instances. While the biased relationship is only correlative. Report issue for preceding element\nDuring the pretraining and task-specific supervised fine-tuning process, the training objective of generative LLMs is consistent, i.e., learn to generate the subsequent text Y \ud835\udc4c Y italic_Y given input text X \ud835\udc4b X italic_X . Given X \ud835\udc4b X italic_X in corpus \ud835\udc9f \ud835\udc9f \\mathcal{D} caligraphic_D , the distribution of Y \ud835\udc4c Y italic_Y can be formalized as P \u2062 ( Y | X ) = P \u2062 ( f S \u2062 ( X ) , g B \u2062 ( X ) | X ) \ud835\udc43 conditional \ud835\udc4c \ud835\udc4b \ud835\udc43 subscript \ud835\udc53 \ud835\udc46 \ud835\udc4b conditional subscript \ud835\udc54 \ud835\udc35 \ud835\udc4b \ud835\udc4b P(Y|X)=P(f_{S}(X),g_{B}(X)|X) italic_P ( italic_Y | italic_X ) = italic_P ( italic_f start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_X ) , italic_g start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( italic_X ) | italic_X ) , the generative LLMs would inevitably be trained to model both f S \u2062 ( X ) subscript \ud835\udc53 \ud835\udc46 \ud835\udc4b f_{S}(X) italic_f start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_X ) and g B \u2062 ( X ) subscript \ud835\udc54 \ud835\udc35 \ud835\udc4b g_{B}(X) italic_g start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( italic_X ) . \u00a0Therefore, given preceding text X i subscript \ud835\udc4b \ud835\udc56 X_{i} italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , LLMs would not only attend to the semantics of X i subscript \ud835\udc4b \ud835\udc56 X_{i} italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT but also would attend to the biased patterns such as negation word, gender indicator, position of choices, etc, to generate Y \ud835\udc4c Y italic_Y . As a result, during inference, the model generation Y ^ ^ \ud835\udc4c \\hat{Y} over^ start_ARG italic_Y end_ARG would inevitably be affected by the dataset biases. For brevity, we denote the semantic information within X i subscript \ud835\udc4b \ud835\udc56 X_{i} italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as S i subscript \ud835\udc46 \ud835\udc56 S_{i} italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and denote the biased patterns as B i subscript \ud835\udc35 \ud835\udc56 B_{i} italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Report issue for preceding element\nActive learning aims at selecting the most informative instances, and then querying external information source(s) to label these data points Cohn et\u00a0al. ( 1994 ); Zhang et\u00a0al. ( 2022 ) . The key of active learning lies in how to devise query strategies to select the most informative instances Zhan et\u00a0al. ( 2022 ) . For example, uncertainty-based active learning methods aim at finding the most uncertain instances, and then send them to annotators for labeling Liu et\u00a0al. ( 2022 ) . In this paper, under the automatic debiasing scenario, two key issues are: (1) finding which instance contains bias ; (2) finding the most informative biased instances. Hence, we propose a causal-guided active learning framework, which identifies the biased instances under the guidance of causal-invariance-based criterion, and finds the most informative biased instances by identifying the instances on which dataset biases have most influence on the generation of LLMs. Report issue for preceding element\nAs Figure 1 (b) shows, CAL contains two main components: (i) causal invariance-based biased instance identification; (ii) typical biased instances selection and bias pattern induction. Given the recognized bias patterns, we propose an in context learning-based debiasing method for regularizing LLMs. Report issue for preceding element\nWe first identify a set of biased instances that reflect the inherent biases within LLMs using the difference between semantic information and biased information in the perspective of causal variance. Report issue for preceding element\nCompared to semantic information, the essential characteristic of biased information is that B \ud835\udc35 B italic_B does not have an invariant causal relationship with the subsequent text, which enables the disentanglement of biased information with semantic information. Moreover, note that, the generative LLMs would capture biased information to obtain the representations (e.g. the hidden states) of input texts. Hence, if we can find the instances where the model obtains representations that are not invariant predictive , then the representations of these instances would contain biased information, which indicates that these instances are very likely to contain bias and could be identified as biased instances. Report issue for preceding element\nSpecifically, as described in Sec. 2.1 , since the input preceding text X \ud835\udc4b X italic_X consists of both the semantics S \ud835\udc46 S italic_S and dataset biases B \ud835\udc35 B italic_B , hence, for an arbitrary instance ( X i , Y i ) subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 (X_{i},Y_{i}) ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) within a large enough dataset, there could exist other instance(s) ( X j , Y j ) subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 (X_{j},Y_{j}) ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) , which has the following relationship with ( X i , Y i ) subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 (X_{i},Y_{i}) ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) : ( B i , S i ) \u2282 X i , ( B j , S j ) \u2282 X j , B i = B j , S i \u2260 S j formulae-sequence subscript \ud835\udc35 \ud835\udc56 subscript \ud835\udc46 \ud835\udc56 subscript \ud835\udc4b \ud835\udc56 formulae-sequence subscript \ud835\udc35 \ud835\udc57 subscript \ud835\udc46 \ud835\udc57 subscript \ud835\udc4b \ud835\udc57 formulae-sequence subscript \ud835\udc35 \ud835\udc56 subscript \ud835\udc35 \ud835\udc57 subscript \ud835\udc46 \ud835\udc56 subscript \ud835\udc46 \ud835\udc57 (B_{i},S_{i})\\subset X_{i},(B_{j},S_{j})\\subset X_{j},B_{i}=B_{j},S_{i}\\neq S_%\n{j} ( italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \u2282 italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , ( italic_B start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u2282 italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_B start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2260 italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT . In other words, this pair of instances shares almost the same kind of dataset biases, while the semantic information entailed in the input text is different. The existence of such instance pairs enables the identification of biased instances using causal invariance. Report issue for preceding element\nUnder such assumption, considering an instance pair \u27e8 ( X i , Y i ) , ( X j , Y j ) \u27e9 subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 \\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle \u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 , if \u2133 \u2133 \\mathcal{M} caligraphic_M has mainly captured the semantic information S i subscript \ud835\udc46 \ud835\udc56 S_{i} italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and S j subscript \ud835\udc46 \ud835\udc57 S_{j} italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , and H i \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 H^{\\mathcal{M}}_{i} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is close to H j \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 H^{\\mathcal{M}}_{j} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , then S i subscript \ud835\udc46 \ud835\udc56 S_{i} italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is similar to S j subscript \ud835\udc46 \ud835\udc57 S_{j} italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , so that S \u2062 i \u2062 m \u2062 ( Y i , Y j ) \u2192 1 \u2192 \ud835\udc46 \ud835\udc56 \ud835\udc5a subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4c \ud835\udc57 1 Sim(Y_{i},Y_{j})\\rightarrow 1 italic_S italic_i italic_m ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u2192 1 . In other words, the LLM has captured invariant predictive information for making generations. Report issue for preceding element\nInstances on which the model fails to capture invariant predictive information Report issue for preceding element\nHence, on the contrary, if we can find an instance pair \u27e8 ( X i , Y i ) , ( X j , Y j ) \u27e9 subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 \\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle \u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 , on which H i \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 H^{\\mathcal{M}}_{i} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is close to H j \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 H^{\\mathcal{M}}_{j} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ,\nwhereas S \u2062 i \u2062 m \u2062 ( Y i , Y j ) \ud835\udc46 \ud835\udc56 \ud835\udc5a subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4c \ud835\udc57 Sim(Y_{i},Y_{j}) italic_S italic_i italic_m ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) is low,\nthen \u27e8 ( X i , Y i ) , ( X j , Y j ) \u27e9 subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 \\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle \u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 can be regarded as instances on which \u2133 \u2133 \\mathcal{M} caligraphic_M violates the causal invariance, and such instance pair can be utilized for characterizing the biases captured by LLMs. For clarity, we define such an instance pair \u27e8 ( X i , Y i ) , ( X j , Y j ) \u27e9 subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 \\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle \u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 as a counter example pair : Report issue for preceding element\nDefinition 1 (Counter Example Pair): \u2200 ( X i , Y i ) for-all subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 \\forall(X_{i},Y_{i}) \u2200 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( X j , Y j ) subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 (X_{j},Y_{j}) ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u2208 \ud835\udc9f absent \ud835\udc9f \\in\\mathcal{D} \u2208 caligraphic_D , i \u2260 j \ud835\udc56 \ud835\udc57 i\\neq j italic_i \u2260 italic_j , if: Report issue for preceding element S \u2062 ( H i \u2133 , H j \u2133 ) > \u03c4 , s . t . S \u2062 i \u2062 m \u2062 ( Y i , Y j ) < \u03b1 , formulae-sequence \ud835\udc46 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 \ud835\udf0f \ud835\udc60 \ud835\udc61 \ud835\udc46 \ud835\udc56 \ud835\udc5a subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4c \ud835\udc57 \ud835\udefc S(H^{\\mathcal{M}}_{i},H^{\\mathcal{M}}_{j})\\!>\\!\\tau,\\\\\ns.t.\\ Sim(Y_{i},Y_{j})\\!<\\!\\alpha, italic_S ( italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) > italic_\u03c4 , italic_s . italic_t . italic_S italic_i italic_m ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) < italic_\u03b1 , (1) where \ud835\udc9f \ud835\udc9f \\mathcal{D} caligraphic_D is the dataset, S \u2062 ( \u22c5 ) \ud835\udc46 \u22c5 S(\\cdot) italic_S ( \u22c5 ) is a score function measuring the similarity between H i \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 H^{\\mathcal{M}}_{i} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and H j \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 H^{\\mathcal{M}}_{j} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , \u03c4 \ud835\udf0f \\tau italic_\u03c4 is a threshold controlling the confidence that H i \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 H^{\\mathcal{M}}_{i} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and H j \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 H^{\\mathcal{M}}_{j} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT can be regarded as close enough, and \u03b1 \ud835\udefc \\alpha italic_\u03b1 is another threshold ensuring that Y i subscript \ud835\udc4c \ud835\udc56 Y_{i} italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Y j subscript \ud835\udc4c \ud835\udc57 Y_{j} italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT can be regarded as sufficiently different. Report issue for preceding element\nDefinition 1 enables us to detect all counter example pairs within the dataset \ud835\udc9f \ud835\udc9f \\mathcal{D} caligraphic_D . On these counter example pairs, the invariance is violated so that subsequent texts are generated based on biased information. Hence, H i \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 H^{\\mathcal{M}}_{i} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and H j \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 H^{\\mathcal{M}}_{j} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT contains the bias information B i = B j subscript \ud835\udc35 \ud835\udc56 subscript \ud835\udc35 \ud835\udc57 B_{i}=B_{j} italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_B start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT . However, the aforementioned theory is built upon the assumption that LLMs have captured the predictive information (including bias and semantic information). In fact, when X i subscript \ud835\udc4b \ud835\udc56 X_{i} italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is very difficult or ambiguous, it cannot be ruled out that the LLM does not capture any predictive information. To rule out such instances, we introduce an additional filtering process using a Predictive Criterion , which requires that \u2133 \u2133 \\mathcal{M} caligraphic_M should at least make a proper generation for the instance i \ud835\udc56 i italic_i or j \ud835\udc57 j italic_j , since if on both i \ud835\udc56 i italic_i and j \ud835\udc57 j italic_j model generation are improper, it is rather probable that \u2133 \u2133 \\mathcal{M} caligraphic_M has not captured any predictive information in X i subscript \ud835\udc4b \ud835\udc56 X_{i} italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or X j subscript \ud835\udc4b \ud835\udc57 X_{j} italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT : Report issue for preceding element\nS \u2062 i \u2062 m \u2062 ( Y ^ i , Y i ) > \u03b2 \u2228 S \u2062 i \u2062 m \u2062 ( Y ^ j , Y j ) > \u03b2 , \ud835\udc46 \ud835\udc56 \ud835\udc5a subscript ^ \ud835\udc4c \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 \ud835\udefd \ud835\udc46 \ud835\udc56 \ud835\udc5a subscript ^ \ud835\udc4c \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 \ud835\udefd \\displaystyle Sim(\\hat{Y}_{i},Y_{i})\\!>\\!\\beta\\vee Sim(\\hat{Y}_{j},Y_{j})\\!>\\!\\beta, italic_S italic_i italic_m ( over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) > italic_\u03b2 \u2228 italic_S italic_i italic_m ( over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) > italic_\u03b2 , (3) where Y ^ i subscript ^ \ud835\udc4c \ud835\udc56 \\hat{Y}_{i} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , and Y ^ j subscript ^ \ud835\udc4c \ud835\udc57 \\hat{Y}_{j} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT are the generated subsequent text, \u03b2 \ud835\udefd \\beta italic_\u03b2 is a threshold ensuring that Y ^ i subscript ^ \ud835\udc4c \ud835\udc56 \\hat{Y}_{i} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Y i subscript \ud835\udc4c \ud835\udc56 Y_{i} italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can be regarded as similar enough so that Y ^ i subscript ^ \ud835\udc4c \ud835\udc56 \\hat{Y}_{i} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can also be seen as a correct answer (the same for Y ^ j subscript ^ \ud835\udc4c \ud835\udc57 \\hat{Y}_{j} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ). Report issue for preceding element\nUsing the criterion mentioned above, we could identify a set of instances that contain bias (i.e., counter instance pairs) as they violate the causal invariance criterion. Next, we hope to select a subset that is more informative and contains typical dataset bias. So that we can further induce explainable patterns of biases to prevent the LLMs from utilizing bias. To this end, we consider that: Report issue for preceding element\nTypical Biased Instances Identification Firstly, for any input text X i subscript \ud835\udc4b \ud835\udc56 X_{i} italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ,\nif the probability that Y i subscript \ud835\udc4c \ud835\udc56 Y_{i} italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is properly generated is rather low, it suggests that biased information significantly hinders the LLM. Hence, such examples would contain a high level of bias and could be informative biased instances. Report issue for preceding element\nSecondly, for a counter instance pair \u27e8 ( X i , Y i ) , ( X j , Y j ) \u27e9 subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 \\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle \u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 , if the corresponding generation of LLM Y ^ i subscript ^ \ud835\udc4c \ud835\udc56 \\hat{Y}_{i} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Y ^ j subscript ^ \ud835\udc4c \ud835\udc57 \\hat{Y}_{j} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is rather different, it means the influences of dataset bias are diversified and hence it would be challenging to summarize a unified bias pattern based on these samples. Conversely, if Y ^ i subscript ^ \ud835\udc4c \ud835\udc56 \\hat{Y}_{i} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Y ^ j subscript ^ \ud835\udc4c \ud835\udc57 \\hat{Y}_{j} over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT are similar, it would be easier to conclude the influence caused by the bias, as the influence of dataset bias is typical.\nBased on the two characteristics, we introduce the following two criteria to select the informative biased instances: Report issue for preceding element\nInfluential Criterion : p ^ j , l j < \u03c4 p , s . t . S i m ( Y ^ j , Y j ) < \u03b1 , \\displaystyle\\textbf{Influential Criterion}\\!:\\hat{p}_{j,l_{j}}\\!<\\!\\tau_{p},%\n\\!\\ s.t.\\ Sim(\\hat{Y}_{j},\\!Y_{j})\\!<\\!\\alpha, Influential Criterion : over^ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_j , italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT < italic_\u03c4 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_s . italic_t . italic_S italic_i italic_m ( over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) < italic_\u03b1 , (2) Typical Criterion : S \u2062 i \u2062 m \u2062 ( Y ^ i , Y ^ j ) > \u03b2 , : Typical Criterion \ud835\udc46 \ud835\udc56 \ud835\udc5a subscript ^ \ud835\udc4c \ud835\udc56 subscript ^ \ud835\udc4c \ud835\udc57 \ud835\udefd \\displaystyle\\textbf{Typical Criterion}\\!:Sim(\\hat{Y}_{i},\\!\\hat{Y}_{j})\\!>\\!\\beta, Typical Criterion : italic_S italic_i italic_m ( over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) > italic_\u03b2 , (3) where l j subscript \ud835\udc59 \ud835\udc57 l_{j} italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is the gold subsequent text, p ^ i , l j subscript ^ \ud835\udc5d \ud835\udc56 subscript \ud835\udc59 \ud835\udc57 \\hat{p}_{i,l_{j}} over^ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i , italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT is the predicted probability of gold subsequent text, and \u03c4 p \u2208 [ 0 , 1 ] subscript \ud835\udf0f \ud835\udc5d 0 1 \\tau_{p}\\in[0,1] italic_\u03c4 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u2208 [ 0 , 1 ] is a threshold for controlling the probability that \u2133 \u2133 \\mathcal{M} caligraphic_M generates gold subsequent text. Report issue for preceding element\nBias Pattern Induction Based on the identified informative biased instances, we further induce certain explainable patterns that characterize several major types of dataset biases among the corpus.\nTo this end, we first group the counter example pairs into several clusters, and then induce patterns for each cluster. Report issue for preceding element\nThe cluster of counter example pairs is derived based on the bias representation vectors of the counter example pairs, which refers to the representation vector of the bias component of a counter example pair. We obtain the bias representation vectors of a counter example pair \u27e8 ( X i , Y i ) , ( X j , Y j ) \u27e9 subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 \\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle \u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 by extracting the similar parts in the representations of two examples (i.e. H i \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 H^{\\mathcal{M}}_{i} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and H j \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 H^{\\mathcal{M}}_{j} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ). This is because, as described in the definition of counter instance pair, the similar parts of H i \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 H^{\\mathcal{M}}_{i} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and H j \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 H^{\\mathcal{M}}_{j} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT carry the biased information. Report issue for preceding element\nAfter obtaining the representation vector of the biases in each counter example pair, we first apply Principal Component Analysis to reduce the dimension of bias representation vectors to two dimensions. As the dimension of data increases, the distances between data points become increasingly similar, so traditional distance metrics (such as Euclidean distance) would be less effective and in turn affect the performance of clustering algorithms. Then we perform clustering based on the dimension-reduced biased representation vectors using the density-based clustering method DBSCAN 1 1 1 We find that the first two principal components can explain over 96% of the total variance. Thus, the left part may mainly be noise and would disturb the process of clustering. Hence, we perform the DBSCAN based on the first two PCA components. . Finally, we obtain counter example pairs within each cluster, and provide them to GPT 4 for summarizing bias patterns. For example, from the selected counter example pair in Figure 1 (b), we can summarize the position bias. Report issue for preceding element\nTo prevent the LLMs from utilizing dataset biases for making generation, meanwhile avoiding the drawbacks of fine-tuning-based methods, we propose a cost-effective and efficient in-context learning (ICL) based method. Concretely: Report issue for preceding element\nIn the zero-shot scenario, as shown in Figure 1 (b), we use the automatically induced bias patterns to explicitly tell the LLM what kind of information it should not use during inference\nby appending the text \u201c [bias xxx] is not related to [the goal of the task] \u201d to the end of the original prompt. Report issue for preceding element\nIn the few-shot scenario , we propose a counterfactual ICL method, which provides LLMs with automatically derived counterfactual examples to correct the LLM\u2019s belief about bias. Specifically, if we could find \u201ccounterfactual examples\u201d, on which using biased information for inference would conversely lead to incorrect generations. Then by providing such examples to LLMs in the prompt, LLMs would be implicitly informed that the biased information is not related to the subsequent text, and thus it would be regularized to not use biased information for making inferences. To find such \u201ccounterfactual examples\u201d, notice that according to the Influential Criterion, for an arbitrary counter example pair \u27e8 ( X i , Y i ) , ( X j , Y j ) \u27e9 subscript \ud835\udc4b \ud835\udc56 subscript \ud835\udc4c \ud835\udc56 subscript \ud835\udc4b \ud835\udc57 subscript \ud835\udc4c \ud835\udc57 \\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle \u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 , the LLM would make improper generation upon instance i \ud835\udc56 i italic_i or j \ud835\udc57 j italic_j . Without generality, we denote this instance as i \ud835\udc56 i italic_i and instance i \ud835\udc56 i italic_i could be regarded as a counterfactual example for debiasing LLMs. Intuitively, in instance i \ud835\udc56 i italic_i the dataset bias leads to improper generations, which is contrary to most cases within the corpus, hence we call instance i \ud835\udc56 i italic_i as a counterfactual example. Report issue for preceding element\nHence, to correct the LLM\u2019s belief about bias, we construct the prompt with such counterfactual examples using the following format: \u201c<EXAMPLES>. Note that you should not utilize biased information to make generations\u201d , where <EXAMPLES> are the counterfactual examples. Report issue for preceding element\nIn this work, we use llama2-13B-chat Touvron et\u00a0al. ( 2023 ) and vicuna-13B-v1.5 Chiang et\u00a0al. ( 2023 ) for our experiments. Without loss of generality, we examine our approach on datasets that have a clear set of possible answers, e.g., multiple-choice question-answering task. So that we can implement the S \u2062 i \u2062 m \u2062 ( \u22c5 ) \ud835\udc46 \ud835\udc56 \ud835\udc5a \u22c5 Sim(\\cdot) italic_S italic_i italic_m ( \u22c5 ) function in Equation 1 using an exact match of strings. If matched, the function\u2019s value is 1, otherwise it\u2019s 0. So \u03b1 \ud835\udefc \\alpha italic_\u03b1 and \u03b2 \ud835\udefd \\beta italic_\u03b2 can be any value between 0 and 1.\nAdditionally, we derive the representation of input text by employing the embedding vector of the last token at the top of the LLM\u2019s layer, and the cosine function is employed as the scoring function S \u2062 ( \u22c5 ) \ud835\udc46 \u22c5 S(\\cdot) italic_S ( \u22c5 ) to measure the similarity between these hidden states. Report issue for preceding element\nTo derive bias representation vector of a counter example pair, we need to extract similar parts in the hidden states corresponding to two examples of the counter example pair. This is because, the similar parts in the hidden states carry the biased information as mentioned in Section 3.2 . To this end, we obtain the similar components of two hidden states in an element-wise manner. Specifically, we use the following function: Report issue for preceding element\nf ( H i \u2062 k , H j \u2062 k ) = { ( H i \u2062 k + H j \u2062 k ) / 2 i \u2062 f \u2062 | H i \u2062 k \u2212 H j \u2062 k | H i \u2062 k + H j \u2062 k < \u03bc 0 o \u2062 t \u2062 h \u2062 e \u2062 r \u2062 w \u2062 i \u2062 s \u2062 e f(H_{ik},H_{jk})\\!=\\!\\left\\{\\begin{matrix}(H_{ik}\\!+\\!H_{jk})/2&if\\frac{|H_{ik%\n}-H_{jk}|}{H_{ik}+H_{jk}}\\!<\\!\\mu\\\\\n0&otherwise\\end{matrix}\\right. italic_f ( italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT , italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT ) = { start_ARG start_ROW start_CELL ( italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT ) / 2 end_CELL start_CELL italic_i italic_f divide start_ARG | italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT - italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT | end_ARG start_ARG italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT end_ARG < italic_\u03bc end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL italic_o italic_t italic_h italic_e italic_r italic_w italic_i italic_s italic_e end_CELL end_ROW end_ARG (4) where H i \u2062 k , H j \u2062 k subscript \ud835\udc3b \ud835\udc56 \ud835\udc58 subscript \ud835\udc3b \ud835\udc57 \ud835\udc58 H_{ik},H_{jk} italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT , italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT are the k-th element of two hidden states H i \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc56 H^{\\mathcal{M}}_{i} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and H j \u2133 subscript superscript \ud835\udc3b \u2133 \ud835\udc57 H^{\\mathcal{M}}_{j} italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT .\nIf H i \u2062 k subscript \ud835\udc3b \ud835\udc56 \ud835\udc58 H_{ik} italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT and H j \u2062 k subscript \ud835\udc3b \ud835\udc57 \ud835\udc58 H_{jk} italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT are similar enough, then their difference should be relatively small. We measure such difference using | H i \u2062 k \u2212 H j \u2062 k | subscript \ud835\udc3b \ud835\udc56 \ud835\udc58 subscript \ud835\udc3b \ud835\udc57 \ud835\udc58 |H_{ik}-H_{jk}| | italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT - italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT | / | H i \u2062 k + H j \u2062 k | subscript \ud835\udc3b \ud835\udc56 \ud835\udc58 subscript \ud835\udc3b \ud835\udc57 \ud835\udc58 |H_{ik}+H_{jk}| | italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT | , and then using a threshold \u03bc \ud835\udf07 \\mu italic_\u03bc to determine if | H i \u2062 k \u2212 H j \u2062 k | subscript \ud835\udc3b \ud835\udc56 \ud835\udc58 subscript \ud835\udc3b \ud835\udc57 \ud835\udc58 |H_{ik}-H_{jk}| | italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT - italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT | / | H i \u2062 k + H j \u2062 k | subscript \ud835\udc3b \ud835\udc56 \ud835\udc58 subscript \ud835\udc3b \ud835\udc57 \ud835\udc58 |H_{ik}+H_{jk}| | italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT | is small enough, in other words, H i \u2062 k subscript \ud835\udc3b \ud835\udc56 \ud835\udc58 H_{ik} italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT and H j \u2062 k subscript \ud835\udc3b \ud835\udc57 \ud835\udc58 H_{jk} italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT are similar enough. If they are similar enough, we use the average of H i \u2062 k subscript \ud835\udc3b \ud835\udc56 \ud835\udc58 H_{ik} italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT and H j \u2062 k subscript \ud835\udc3b \ud835\udc57 \ud835\udc58 H_{jk} italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT to represent the k-th element of the bias representation vector of a counter example pair. If not, we use 0 to represent the k-th element of the bias representation vector.\nIn practice, we choose \u03bc \ud835\udf07 \\mu italic_\u03bc by controlling the ratio that the two elements of certain position can be considered as similar enough in MNLI dataset when using llama2-13B-chat. We set a strict threshold of 0.15 for the ratio to ensure that the bias representation vectors of the counter example pairs have purer bias information. Report issue for preceding element\nMoreover, note that, it is UNNECESSARY to run CAL upon the whole corpus to obtain the biased instances and the bias patterns. A subset would be enough (e.g., 2,0000 instances) to save the computational cost. In the Section 4.8 and Appendix C , we provide the sensitivity analysis of the dataset size and hyperparameters, including the influence of the size of data for obtaining the counter instance pairs and the thresholds. Report issue for preceding element\nIn few-shot scenarios, to make results comparable, we ensure that the number of examples in prompts equals that used in other few-shot baselines.\nAdditionally, we maintain the order of gold answers that appear in the few-shot examples to avoid introducing additional label bias.\nWe report the average results across 10 runs considering the randomness in sampling counterfactual examples. Report issue for preceding element\nBelow we call our method zero-shot-CAL and few-shot-CAL in zero-shot and few-shot settings respectively. More details about experimental settings are provided in Appendix. Report issue for preceding element\nWe examine the effectiveness of CAL by investigating whether CAL could debias LLMs to improve the generalizability and unharmfulness of LLMs. Report issue for preceding element\nTo evaluate the improvement of generalizability, we conduct experiments by deriving biased instances and bias patterns on dataset A and utilizing the identified instances and biased patterns to debias both dataset A and dataset B. Heuristically, two datasets A and B may share different dataset bias distributions. If an LLM only adapts to dataset A, then its performance upon dataset B would be impacted. On the contrary, if an LLM can focus more on semantics, the performance on both datasets would be improved.\nHence, the generalizability could be evaluated by the performance improvement compared to baseline methods . Specifically, We evaluate our approach on benchmarks representing two categories of bias: (1) Generative-LLM-specific biases. We employ the Chatbot and the MT-Bench datasets Zheng et\u00a0al. ( 2023 ) as benchmarks.\nOn both datasets, LLM is required to choose a better response from two candidates.\nWe induce the bias patterns on the Chatbot dataset, then test whether the Chatbot-based bias patterns can be utilized to debias LLMs on both the Chatbot and the MT-Bench dataset. (2) Task-specific biases. We choose the natural language inference dataset MNLI Williams et\u00a0al. ( 2018 ) and the corresponding manually debiased dataset HANS McCoy et\u00a0al. ( 2019 ) as benchmarks. Hence, models that only utilize the biased information often perform close to a random baseline on HANS.\nThe bias patterns are induced from the MNLI dataset, then test whether CAL can utilize the induced bias patterns to debias LLMs on both the MNLI and the HANS datasets. Report issue for preceding element\nTo evaluate the improvement of unharmfulness, we conduct experiments on the BBQ Parrish et\u00a0al. ( 2022 ) and the UNQOVER Li et\u00a0al. ( 2020 ) dataset, which is designed for evaluating stereotype biases (such as gender bias and racial bias) of LLMs. These two datasets containing 9 and 4 types of stereotype bias, respectively. On these two datasets, if the model achieves a higher accuracy, then it could be regarded as having a lower likelihood of containing stereotypes. Report issue for preceding element\nOn Chatbot and MT-Bench dataset, model performance is evaluated based on the agreement ratio between human-majority annotations and LLMs. On other datasets, model performance is evaluated using accuracy. Report issue for preceding element\nWe compare the casual-guided active learning method with two categories of baseline methods: Report issue for preceding element\nvanilla zero-shot and few-shot baselines We examine the vanilla zero-shot and few-shot performance of LLMs using the prompt of Zheng et\u00a0al. ( 2023 ); Si et\u00a0al. ( 2023 ); Xu et\u00a0al. ( 2023 ) . Report issue for preceding element\nzero-shot-known-bias These methods mainly rely on human prior knowledge of bias to design debiasing prompts.\nFor Chatbot and MT-Bench datasets, we compare CAL with the debiasing method of swapping positions proposed in Zheng et\u00a0al. ( 2023 ) . For BBQ and UNQOVER datasets, we follow the instruction from Si et\u00a0al. ( 2023 ) to avoid stereotype bias. For MNLI and HANS datasets, we use the debiasing prompt to prevent lexical overlap and subsequence bias proposed in McCoy et\u00a0al. ( 2019 ) . Report issue for preceding element\nTo the best of our knowledge, the only few-shot debiasing method comes from Oba et\u00a0al. ( 2023 ) . However, this method is unsuitable for our dataset. Details can be seen in Appendix G . Report issue for preceding element\nWe list the experimental results of two LLMs on six datasets in Table 1 . From which we find that: Report issue for preceding element\n(1) Compared to the vanilla zero-shot shows that, in general, the prior knowledge-based zero-shot debiasing methods show improved performance on all the datasets. This indicates that through ICL, LLMs can both effectively debias themselves and avoid the in-distribution performance degradation which is always associated with fine-tuning-based approaches Du et\u00a0al. ( 2023 ) , suggesting the superiority of ICL-based debiasing methods. Report issue for preceding element\n(2) Compared to the zero-shot baselines and few-shot baselines, in general, few-shot CAL achieves consistent performance improvement on the two categories of benchmarks. This demonstrates that, CAL can improve both the generalizability and the unharmfuless of LLMs, and suggests that by utilizing the essential differences between semantic information,\nCAL can identify a set of biased instances, and the counterfactual ICL-based prompts can effectively leverage the biased counterfactual examples to debias LLMs. Report issue for preceding element\n(3) Compared with vanilla zero-shot baselines, zero-shot CAL can consistently improve model performance on all the datasets, and even surpass the performance of few-shot methods on part of benchmarks.\nThe effectiveness of zero-shot CAL suggests that the biased patterns induced by CAL are typical and truly exist in the datasets. This is because, by utilizing the causal invariance together with the influential and typical criterion, a set of typical biased instances could be selected, so that the biased patterns could be effectively induced. Report issue for preceding element\n(4) Compared with the prior knowledge-based zero-shot debiasing methods, zero-shot CAL shows comparable or better performance on two categories of benchmarks. On the one hand, the complexity of the distribution of dataset biases brings challenges for precisely and comprehensively detecting the potential biases. On the other hand, the comparable performance between zero-shot CAL and prior knowledge-based zero-shot debiasing methods shows the effectiveness of our approach, and the potential for application in real-world scenarios, as it would be impractical to investigate all biases for various real-world corpus. Report issue for preceding element\n(5) In general, our method is effective for both llama2-13B-chat and vicuna-13B-v1.5. This suggests the prevalence of biases in LLMs, and demonstrates the generality of our approach in adapting to different LLMs. Report issue for preceding element\nWe argue that one of our potential major contributions is that by utilizing the causal invariance together with the influential and typical criterion, we can identify a set of typical biased instances, and then autonomously summarize explainable bias patterns from data. In Figure 2 ,\nwe present the results of clustering analysis based on the bias representations derived from bias instances, and bias patterns summarized from the clustered categories. Experiments are conducted using llama2-13B-chat. Report issue for preceding element\nOverall, it can be observed that bias representations are concentrated in several distinct groups after dimensionality reduction through PCA. Moreover, the bias patterns summarized based on different clustering categories are also distinguished. This indicates that our method could discover different types of biased instances and then induce bias patterns. Report issue for preceding element\nBased on the counter example pairs derived from the Chatbot dataset, CAL can simultaneously induce position bias, verbosity bias, and format bias, which is separately identified by several previous research Zheng et\u00a0al. ( 2023 ); Zhu et\u00a0al. ( 2023 ) , suggesting the efficiency and effectiveness of our approach.\nFurthermore, we also observe several potential bias patterns such as \u201clength or complexity of a response\u201d and \u201cthe presence of specific details or a confident tone\u201d, Report issue for preceding element\nthat are previously unreported.\nWhen we tell llama2-13B-chat not to make predictions\nbased on these biases, its performance increases on both Chatbot and MT-Bench datasets, suggesting that these patterns could be the truly existing biases.\nAmong the 9 known types of stereotype biases in the BBQ dataset Parrish et\u00a0al. ( 2022 ) , our method can automatically identify 7 of them without prior knowledge (the bias of gender, sexual orientation, and religion are grouped into \u201ccultural association of a name\u201d during the bias induction procedure).\nOn the MNLI dataset, we observe some unreported new bias patterns such as \u201cspeculative language in the hypothesis\u201d (e.g., should, perhaps, possibly),\nand we can also improve the performance of llama2-13B-chat by telling it not to make predictions based on these bias patterns.\nMore analyses of the counter example pairs can be seen in Appendix B . Report issue for preceding element\nThe automatically summarized bias patterns demonstrate the diversity of dataset biases in practical datasets, and it would be impractical to identify all of them manually. Therefore, there is an urgent need for methods to automatically identify biases. As a pioneer work, we explored that the LLMs can be automatically debiased by combining the causal mechanism and active learning, suggesting the potential feasibility of utilizing LLMs to autonomously debias themselves. Report issue for preceding element\nThe pretraining corpus of different LLMs share unnegligible overlaps, so they would also possess common biases.\nHence, we investigate the generalizability of the automatically induced bias patterns by testing if it is possible to debias LLM-A based on the bias pattern identified from another LLM-B. Specifically, we attempt to debias GPT-4 based on the bias pattern (and the corresponding debiasing prompt) identified from llama2-13b-chat. Experimental results are shown in Table 2 , from which we can observe that compared to vanilla zero-shot, ZS-CAL achieves higher performance in most cases. This demonstrated that different LLMs might share similar bias patterns and we can debias an LLM based on the bias pattern identified from other LLMs, which further demonstrates the universality of our method. Report issue for preceding element\nIn the above sections, we induce the explainable bias patterns using GPT-4. We also attempt to use the open-source LLM Qwen1.5-72B-Chat for inducing bias patterns to examine the generalizability. As Table 3 shows, the results still outperform the baseline methods with the biased patterns induced by free open-source LLM, while slightly inferior to that of GPT-4. This shows the generality of our approach, and implicates the potential application in real-world scenarios. Report issue for preceding element\nTo investigate the influence of the dataset size used in our framework, We conducted experiments using a 20% subset of the MNLI dataset utilized in our main experiments, employing the llama2-13b-chat model. As Table 4 shows, the performance of CAL keeps relatively stable with 20% data. Moreover, our approach still far outperforms the baseline method on the HANS dataset, which demonstrates the effectiveness of our approach to debias LLMs. This indicates that our method is still effective in situations where data is relatively scarce. Report issue for preceding element\nPrevious analyses demonstrate that LLMs still suffer from biases such as position bias Zheng et\u00a0al. ( 2023 ) and stereotyping bias Shaikh et\u00a0al. ( 2023 ) . To mitigate the LLMs\u2019 biases, one line of methods relies on researchers\u2019 prior knowledge to artificially recognize the potential dataset biases, followed by debiasing through prompt-based regularization or aligning with human through instruct tuning Oba et\u00a0al. ( 2023 ); Liu et\u00a0al. ( 2023b ); Ganguli et\u00a0al. ( 2023 ) . However, these methods are limited by the dependence on researchers\u2019 prior. Moreover, due to the diversity of dataset biases Poliak et\u00a0al. ( 2018 ); Schuster et\u00a0al. ( 2019 ); Schick et\u00a0al. ( 2021 ) , it is unrealistic to identify them one by one manually. To tackle these issues, automatic debiasing methods are proposed. They automatically extract bias features characterizing the dataset biases by training certain biased models Utama et\u00a0al. ( 2020 ); Du et\u00a0al. ( 2023 ); Sanh et\u00a0al. ( 2020 ); Lyu et\u00a0al. ( 2023 ) for regularizing the main model. However, such methods are designed for discriminative models and are hard to adapt to generative LLMs. Report issue for preceding element\nIn this paper, we propose a causal-guided active learning framework for automatically debiasing generative LLMs.\nWe borrow the idea from active learning Zhang et\u00a0al. ( 2022 ) by first automatically identifying the potentially biased instances using the causal invariance mechanism, then automatically selecting the informative biased instances using the typical criterion and influential criterion.\nBased on such biased instances, the LLMs are regularized using the ICL-based method to prevent them from utilizing the bias patterns. Report issue for preceding element\nIn this paper, we propose a causal-guided active learning framework. Depending on the difference between the dataset biases and semantics in causal invariance, we can automatically identify counter example pairs that contain bias. Then we utilize an influential and a typical criterion to select counter example pairs that are more informative for inducing bias patterns. Finally, a cost-saving yet effective ICL-based debiasing method is proposed to prevent the LLM from utilizing biases for generation. Experimental results show that our approach can effectively recognize various bias patterns automatically, and debias LLMs to enhance their generalizability and unharmfulness. Report issue for preceding element\nWe thank the anonymous reviewers for their constructive comments and gratefully acknowledge the National Natural Science Foundation of China (U22B2059, 62176079), and the Natural Science Foundation of Heilongjiang Province (Y02022F005). Report issue for preceding element\nAlthough our method can automatically debias LLMs, the identification of typical bias instances relies on the hidden state and the predicted probability of the gold subsequent text, which are inaccessible in proprietary models such as GPT-4. This limitation makes it challenging for us to comprehensively uncover the bias patterns present in closed-source models. Report issue for preceding element",
  "masked_text": "Large language models (LLMs) are growing to be the foundation of Natural Language Processing. Through the generative pretraining process upon a large-scale corpus, the LLMs have demonstrated impressive performance in understanding the language and conducting complex reasoning tasks [CITATION], demonstrating immense potential in real-world applications.Report issue for preceding element\nHowever, the generative pretraining process is a double-edged sword, as it would also inevitably incur dataset bias into the LLMs such as position bias and stereotype bias [CITATION]. This is because, the LLMs only passively learn to model the correlation between contexts in the pretraining corpus, and the pretraining corpus is biased as it reflects the inherent preference or prejudice of human beings. For example, the existence of position bias is due to the subconscious human belief that the first option is better, leading to a higher frequency of the first option in corpora, and LLMs trained to model the corpus distribution would also capture such biased correlation. Such biases would lead to poor generalizability and harmfulness of LLMs [CITATION]. For instance, when an LLM is asked to evaluate which option is better, the LLM may utilize position bias and tend to choose the first option. However, which option is better is completely unrelated to its position. Therefore, when the second option is generally better in some datasets, the performance of the LLM will significantly decline. While biases such as stereotyping bias would make LLMs generate harmful content such as women are less capable in STEM fields, which in turn reinforces harmful stereotypes.Report issue for preceding element\nThese problems highlight the necessity of debiasing LLMs. The key issue to debias LLMs lies in how to recognize the dataset biases and prevent it from utilizing biases during inference. To this end, prevalent methods rely on researchers\u2019 prior knowledge to artificially recognize the potential dataset biases, and then eliminate such biases through aligning or prompt-based regularization [CITATION]. However, due to the diversity and complexity of dataset biases [CITATION], it\u2019s impractical to identify them one by one manually. A vast amount of biases remains unrecognized in different tasks [CITATION] and new biases are continually being discovered.Report issue for preceding element\nHence, there is an urgent need for methods to automatically identify biases of generative LLMs. However, previous automatic debiasing methods are mainly designed for discriminative models and are hard to adapt to generative LLMs. Moreover, these methods generally rely on a fine-tuning-based process on certain dataset(s) to regularize the model. The finetuning-based debiasing process would lead to over-optimization and undermine the generalizability of LLMs on other tasks [CITATION].Report issue for preceding element\nTo address these issues, considering the powerful pattern recognition and inductive ability of LLMs, we explore combining active learning with the causal mechanisms and propose a Casual-guided Active Learning (CAL) framework, which utilizes LLMs themselves to automatically and autonomously identify biased samples and induce the bias patterns. Active learning aims at selecting the most informative instances, and then querying external information source(s) to label these data points. In the debiasing scenario, CAL identifies the biased instances by finding instances where the LLMs fail to model causal invariant semantic relationship among context, then selects the most informative biased instances by finding the instances on which dataset biases have the most influence on the generation of LLMs. The causal invariance can be employed to disentangle the semantic information with dataset biases, as the content of the subsequent text is decided by the semantics of the preceding text (i.e., \u201ccausal\u201d), and such relationship exists in all corpora (i.e., \u201cinvariant\u201d); on the contrary, although the subsequent text would be correlative to dataset bias, such correlation changes upon different datasets. Given the biased instances, a set of explainable bias patterns is further induced, and we devise a cost-effective and efficient in-context learning (ICL) based method to regularize LLMs using the explainable bias patterns.Report issue for preceding element\nBased on the method of this paper, we construct a Python package to facilitate the automatic identification of dataset bias on Instruct Tuning Datasets. We attempt to discover biased instances and explainable biased patterns from several commonly used instruct-tuning datasets. The code is publicly available at https://github.com/spirit-moon-fly/CAL.Report issue for preceding element\nExperimental results show that our approach can automatically induce various explainable bias patterns (some of them may be unreported), and improve the generalizability and safety of LLMs by using the ICL-based debiasing method based on the bias patterns and biased instances.Report issue for preceding element\nText records and reflects the thoughts of human beings. Inherent biases such as gender and racial biases persist in the human mind, and thus are also reflected in various corpora [CITATION]. Due to potential annotation artifacts, various biases such as position and verbosity biases still broadly exist in task-specific datasets.Report issue for preceding element\nFormally, as shown in Figure 1 (a), given a piece of text X\ud835\udc4bXitalic_X, the subsequent text Y\ud835\udc4cYitalic_Y within a corpus \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D would be affected by two factors: (1) The semantic relationship between X\ud835\udc4bXitalic_X and Y\ud835\udc4cYitalic_Y, (2) The existence of dataset bias within \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D. For example, given X=The physician hired the secretary because\ud835\udc4bThe physician hired the secretary becauseX=\\textbf{The physician hired the secretary because}italic_X = The physician hired the secretary because, due to the existence of gender bias, the following text Y\ud835\udc4cYitalic_Y in the corpus would more likely be he was overwhelmed with clients, rather than she. Such biased relationship characterizes the unwanted correlation between the context brought by dataset bias. In the following sections, for clarity, we denote the semantic relationship as fS\u2062(\u22c5)subscript\ud835\udc53\ud835\udc46\u22c5f_{S}(\\cdot)italic_f start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( \u22c5 ), and denote the biased relationship as gB\u2062(\u22c5)subscript\ud835\udc54\ud835\udc35\u22c5g_{B}(\\cdot)italic_g start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( \u22c5 ). Hence, given X\ud835\udc4bXitalic_X, the conditional distribution of Y\ud835\udc4cYitalic_Y given X\ud835\udc4bXitalic_X in corpus \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D can be formalized as P\u2062(Y|X)=P\u2062(fS\u2062(X),gB\u2062(X)|X)\ud835\udc43conditional\ud835\udc4c\ud835\udc4b\ud835\udc43subscript\ud835\udc53\ud835\udc46\ud835\udc4bconditionalsubscript\ud835\udc54\ud835\udc35\ud835\udc4b\ud835\udc4bP(Y|X)=P(f_{S}(X),g_{B}(X)|X)italic_P ( italic_Y | italic_X ) = italic_P ( italic_f start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_X ) , italic_g start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( italic_X ) | italic_X ).Report issue for preceding element\nThe key difference between the semantic relationship and the biased relationship is that the semantic relationship possesses the causal invariance, while the biased relationship does not. Specifically, for all instances upon all datasets, given preceding text X\ud835\udc4bXitalic_X, the subsequent text Y\ud835\udc4cYitalic_Y would be determined by the semantic relationship [CITATION], while the biased relationship only describes certain superficial statistical correlation between X\ud835\udc4bXitalic_X and Y\ud835\udc4cYitalic_Y. Consider the example where an LLM acts as a judge to assess the responses of two AI assistants, as illustrated in Figure 1 (a): The answer (Y\ud835\udc4cYitalic_Y) is determined by the semantic relationship between the prompt X\ud835\udc4bXitalic_X and answer Y\ud835\udc4cYitalic_Y. While in the corpus, certain biases such as the position of the responses that show a correlation with the answer can be predictive. However, Y\ud835\udc4cYitalic_Y is not determined by the bias and such a correlation may fail to be predictive in other instances. Hence, as Y\ud835\udc4cYitalic_Y is determined by X\ud835\udc4bXitalic_X, their semantic relationship is a \u201ccausal\u201d relationship and invariant upon all instances. While the biased relationship is only correlative.Report issue for preceding element\nDuring the pretraining and task-specific supervised fine-tuning process, the training objective of generative LLMs is consistent, i.e., learn to generate the subsequent text Y\ud835\udc4cYitalic_Y given input text X\ud835\udc4bXitalic_X. Given X\ud835\udc4bXitalic_X in corpus \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D, the distribution of Y\ud835\udc4cYitalic_Y can be formalized as P\u2062(Y|X)=P\u2062(fS\u2062(X),gB\u2062(X)|X)\ud835\udc43conditional\ud835\udc4c\ud835\udc4b\ud835\udc43subscript\ud835\udc53\ud835\udc46\ud835\udc4bconditionalsubscript\ud835\udc54\ud835\udc35\ud835\udc4b\ud835\udc4bP(Y|X)=P(f_{S}(X),g_{B}(X)|X)italic_P ( italic_Y | italic_X ) = italic_P ( italic_f start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_X ) , italic_g start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( italic_X ) | italic_X ), the generative LLMs would inevitably be trained to model both fS\u2062(X)subscript\ud835\udc53\ud835\udc46\ud835\udc4bf_{S}(X)italic_f start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT ( italic_X ) and gB\u2062(X)subscript\ud835\udc54\ud835\udc35\ud835\udc4bg_{B}(X)italic_g start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ( italic_X ). Therefore, given preceding text Xisubscript\ud835\udc4b\ud835\udc56X_{i}italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, LLMs would not only attend to the semantics of Xisubscript\ud835\udc4b\ud835\udc56X_{i}italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT but also would attend to the biased patterns such as negation word, gender indicator, position of choices, etc, to generate Y\ud835\udc4cYitalic_Y. As a result, during inference, the model generation Y^^\ud835\udc4c\\hat{Y}over^ start_ARG italic_Y end_ARG would inevitably be affected by the dataset biases. For brevity, we denote the semantic information within Xisubscript\ud835\udc4b\ud835\udc56X_{i}italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as Sisubscript\ud835\udc46\ud835\udc56S_{i}italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and denote the biased patterns as Bisubscript\ud835\udc35\ud835\udc56B_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT.Report issue for preceding element\nActive learning aims at selecting the most informative instances, and then querying external information source(s) to label these data points [CITATION]. The key of active learning lies in how to devise query strategies to select the most informative instances [CITATION]. For example, uncertainty-based active learning methods aim at finding the most uncertain instances, and then send them to annotators for labeling [CITATION]. In this paper, under the automatic debiasing scenario, two key issues are: (1) finding which instance contains bias; (2) finding the most informative biased instances. Hence, we propose a causal-guided active learning framework, which identifies the biased instances under the guidance of causal-invariance-based criterion, and finds the most informative biased instances by identifying the instances on which dataset biases have most influence on the generation of LLMs.Report issue for preceding element\nAs Figure 1 (b) shows, CAL contains two main components: (i) causal invariance-based biased instance identification; (ii) typical biased instances selection and bias pattern induction. Given the recognized bias patterns, we propose an in context learning-based debiasing method for regularizing LLMs.Report issue for preceding element\nWe first identify a set of biased instances that reflect the inherent biases within LLMs using the difference between semantic information and biased information in the perspective of causal variance. Report issue for preceding element\nCompared to semantic information, the essential characteristic of biased information is that B\ud835\udc35Bitalic_B does not have an invariant causal relationship with the subsequent text, which enables the disentanglement of biased information with semantic information. Moreover, note that, the generative LLMs would capture biased information to obtain the representations (e.g. the hidden states) of input texts. Hence, if we can find the instances where the model obtains representations that are not invariant predictive, then the representations of these instances would contain biased information, which indicates that these instances are very likely to contain bias and could be identified as biased instances.Report issue for preceding element\nSpecifically, as described in Sec. 2.1, since the input preceding text X\ud835\udc4bXitalic_X consists of both the semantics S\ud835\udc46Sitalic_S and dataset biases B\ud835\udc35Bitalic_B, hence, for an arbitrary instance (Xi,Yi)subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56(X_{i},Y_{i})( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) within a large enough dataset, there could exist other instance(s) (Xj,Yj)subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57(X_{j},Y_{j})( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ), which has the following relationship with (Xi,Yi)subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56(X_{i},Y_{i})( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ): (Bi,Si)\u2282Xi,(Bj,Sj)\u2282Xj,Bi=Bj,Si\u2260Sjformulae-sequencesubscript\ud835\udc35\ud835\udc56subscript\ud835\udc46\ud835\udc56subscript\ud835\udc4b\ud835\udc56formulae-sequencesubscript\ud835\udc35\ud835\udc57subscript\ud835\udc46\ud835\udc57subscript\ud835\udc4b\ud835\udc57formulae-sequencesubscript\ud835\udc35\ud835\udc56subscript\ud835\udc35\ud835\udc57subscript\ud835\udc46\ud835\udc56subscript\ud835\udc46\ud835\udc57(B_{i},S_{i})\\subset X_{i},(B_{j},S_{j})\\subset X_{j},B_{i}=B_{j},S_{i}\\neq S_% {j}( italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \u2282 italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , ( italic_B start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u2282 italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_B start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2260 italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. In other words, this pair of instances shares almost the same kind of dataset biases, while the semantic information entailed in the input text is different. The existence of such instance pairs enables the identification of biased instances using causal invariance.Report issue for preceding element\nUnder such assumption, considering an instance pair \u27e8(Xi,Yi),(Xj,Yj)\u27e9subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57\\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle\u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9, if \u2133\u2133\\mathcal{M}caligraphic_M has mainly captured the semantic information Sisubscript\ud835\udc46\ud835\udc56S_{i}italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Sjsubscript\ud835\udc46\ud835\udc57S_{j}italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, and Hi\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56H^{\\mathcal{M}}_{i}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is close to Hj\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57H^{\\mathcal{M}}_{j}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, then Sisubscript\ud835\udc46\ud835\udc56S_{i}italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is similar to Sjsubscript\ud835\udc46\ud835\udc57S_{j}italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, so that S\u2062i\u2062m\u2062(Yi,Yj)\u21921\u2192\ud835\udc46\ud835\udc56\ud835\udc5asubscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4c\ud835\udc571Sim(Y_{i},Y_{j})\\rightarrow 1italic_S italic_i italic_m ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u2192 1. In other words, the LLM has captured invariant predictive information for making generations.Report issue for preceding element\nInstances on which the model fails to capture invariant predictive informationReport issue for preceding element\nHence, on the contrary, if we can find an instance pair \u27e8(Xi,Yi),(Xj,Yj)\u27e9subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57\\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle\u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9, on which Hi\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56H^{\\mathcal{M}}_{i}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is close to Hj\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57H^{\\mathcal{M}}_{j}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, whereas S\u2062i\u2062m\u2062(Yi,Yj)\ud835\udc46\ud835\udc56\ud835\udc5asubscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4c\ud835\udc57Sim(Y_{i},Y_{j})italic_S italic_i italic_m ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) is low, then \u27e8(Xi,Yi),(Xj,Yj)\u27e9subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57\\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle\u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 can be regarded as instances on which \u2133\u2133\\mathcal{M}caligraphic_M violates the causal invariance, and such instance pair can be utilized for characterizing the biases captured by LLMs. For clarity, we define such an instance pair \u27e8(Xi,Yi),(Xj,Yj)\u27e9subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57\\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle\u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9 as a counter example pair:Report issue for preceding element\nDefinition 1 (Counter Example Pair): \u2200(Xi,Yi)for-allsubscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56\\forall(X_{i},Y_{i})\u2200 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), (Xj,Yj)subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57(X_{j},Y_{j})( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u2208\ud835\udc9fabsent\ud835\udc9f\\in\\mathcal{D}\u2208 caligraphic_D, i\u2260j\ud835\udc56\ud835\udc57i\\neq jitalic_i \u2260 italic_j, if:Report issue for preceding element S\u2062(Hi\u2133,Hj\u2133)>\u03c4,s.t.S\u2062i\u2062m\u2062(Yi,Yj)<\u03b1,formulae-sequence\ud835\udc46subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57\ud835\udf0f\ud835\udc60\ud835\udc61\ud835\udc46\ud835\udc56\ud835\udc5asubscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4c\ud835\udc57\ud835\udefcS(H^{\\mathcal{M}}_{i},H^{\\mathcal{M}}_{j})\\!>\\!\\tau,\\\\ s.t.\\ Sim(Y_{i},Y_{j})\\!<\\!\\alpha,italic_S ( italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) > italic_\u03c4 , italic_s . italic_t . italic_S italic_i italic_m ( italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) < italic_\u03b1 , (1) where \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D is the dataset, S\u2062(\u22c5)\ud835\udc46\u22c5S(\\cdot)italic_S ( \u22c5 ) is a score function measuring the similarity between Hi\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56H^{\\mathcal{M}}_{i}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTand Hj\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57H^{\\mathcal{M}}_{j}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, \u03c4\ud835\udf0f\\tauitalic_\u03c4 is a threshold controlling the confidence that Hi\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56H^{\\mathcal{M}}_{i}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Hj\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57H^{\\mathcal{M}}_{j}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT can be regarded as close enough, and \u03b1\ud835\udefc\\alphaitalic_\u03b1 is another threshold ensuring that Yisubscript\ud835\udc4c\ud835\udc56Y_{i}italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Yjsubscript\ud835\udc4c\ud835\udc57Y_{j}italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT can be regarded as sufficiently different.Report issue for preceding element\nDefinition 1 enables us to detect all counter example pairs within the dataset \ud835\udc9f\ud835\udc9f\\mathcal{D}caligraphic_D. On these counter example pairs, the invariance is violated so that subsequent texts are generated based on biased information. Hence, Hi\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56H^{\\mathcal{M}}_{i}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Hj\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57H^{\\mathcal{M}}_{j}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT contains the bias information Bi=Bjsubscript\ud835\udc35\ud835\udc56subscript\ud835\udc35\ud835\udc57B_{i}=B_{j}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_B start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. However, the aforementioned theory is built upon the assumption that LLMs have captured the predictive information (including bias and semantic information). In fact, when Xisubscript\ud835\udc4b\ud835\udc56X_{i}italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is very difficult or ambiguous, it cannot be ruled out that the LLM does not capture any predictive information. To rule out such instances, we introduce an additional filtering process using a Predictive Criterion, which requires that \u2133\u2133\\mathcal{M}caligraphic_M should at least make a proper generation for the instance i\ud835\udc56iitalic_i or j\ud835\udc57jitalic_j, since if on both i\ud835\udc56iitalic_i and j\ud835\udc57jitalic_j model generation are improper, it is rather probable that \u2133\u2133\\mathcal{M}caligraphic_M has not captured any predictive information in Xisubscript\ud835\udc4b\ud835\udc56X_{i}italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or Xjsubscript\ud835\udc4b\ud835\udc57X_{j}italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT:Report issue for preceding element\nS\u2062i\u2062m\u2062(Y^i,Yi)>\u03b2\u2228S\u2062i\u2062m\u2062(Y^j,Yj)>\u03b2,\ud835\udc46\ud835\udc56\ud835\udc5asubscript^\ud835\udc4c\ud835\udc56subscript\ud835\udc4c\ud835\udc56\ud835\udefd\ud835\udc46\ud835\udc56\ud835\udc5asubscript^\ud835\udc4c\ud835\udc57subscript\ud835\udc4c\ud835\udc57\ud835\udefd\\displaystyle Sim(\\hat{Y}_{i},Y_{i})\\!>\\!\\beta\\vee Sim(\\hat{Y}_{j},Y_{j})\\!>\\!\\beta,italic_S italic_i italic_m ( over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) > italic_\u03b2 \u2228 italic_S italic_i italic_m ( over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) > italic_\u03b2 , (3) where Y^isubscript^\ud835\udc4c\ud835\udc56\\hat{Y}_{i}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and Y^jsubscript^\ud835\udc4c\ud835\udc57\\hat{Y}_{j}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT are the generated subsequent text, \u03b2\ud835\udefd\\betaitalic_\u03b2 is a threshold ensuring that Y^isubscript^\ud835\udc4c\ud835\udc56\\hat{Y}_{i}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Yisubscript\ud835\udc4c\ud835\udc56Y_{i}italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can be regarded as similar enough so that Y^isubscript^\ud835\udc4c\ud835\udc56\\hat{Y}_{i}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can also be seen as a correct answer (the same for Y^jsubscript^\ud835\udc4c\ud835\udc57\\hat{Y}_{j}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT).Report issue for preceding element\nUsing the criterion mentioned above, we could identify a set of instances that contain bias (i.e., counter instance pairs) as they violate the causal invariance criterion. Next, we hope to select a subset that is more informative and contains typical dataset bias. So that we can further induce explainable patterns of biases to prevent the LLMs from utilizing bias. To this end, we consider that: Report issue for preceding element\nTypical Biased Instances Identification Firstly, for any input text Xisubscript\ud835\udc4b\ud835\udc56X_{i}italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, if the probability that Yisubscript\ud835\udc4c\ud835\udc56Y_{i}italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is properly generated is rather low, it suggests that biased information significantly hinders the LLM. Hence, such examples would contain a high level of bias and could be informative biased instances.Report issue for preceding element\nSecondly, for a counter instance pair \u27e8(Xi,Yi),(Xj,Yj)\u27e9subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57\\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle\u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9, if the corresponding generation of LLM Y^isubscript^\ud835\udc4c\ud835\udc56\\hat{Y}_{i}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Y^jsubscript^\ud835\udc4c\ud835\udc57\\hat{Y}_{j}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is rather different, it means the influences of dataset bias are diversified and hence it would be challenging to summarize a unified bias pattern based on these samples. Conversely, if Y^isubscript^\ud835\udc4c\ud835\udc56\\hat{Y}_{i}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Y^jsubscript^\ud835\udc4c\ud835\udc57\\hat{Y}_{j}over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT are similar, it would be easier to conclude the influence caused by the bias, as the influence of dataset bias is typical. Based on the two characteristics, we introduce the following two criteria to select the informative biased instances:Report issue for preceding element\nInfluential Criterion:p^j,lj<\u03c4p,s.t.Sim(Y^j,Yj)<\u03b1,\\displaystyle\\textbf{Influential Criterion}\\!:\\hat{p}_{j,l_{j}}\\!<\\!\\tau_{p},% \\!\\ s.t.\\ Sim(\\hat{Y}_{j},\\!Y_{j})\\!<\\!\\alpha,Influential Criterion : over^ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_j , italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT < italic_\u03c4 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_s . italic_t . italic_S italic_i italic_m ( over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) < italic_\u03b1 , (2) Typical Criterion:S\u2062i\u2062m\u2062(Y^i,Y^j)>\u03b2,:Typical Criterion\ud835\udc46\ud835\udc56\ud835\udc5asubscript^\ud835\udc4c\ud835\udc56subscript^\ud835\udc4c\ud835\udc57\ud835\udefd\\displaystyle\\textbf{Typical Criterion}\\!:Sim(\\hat{Y}_{i},\\!\\hat{Y}_{j})\\!>\\!\\beta,Typical Criterion : italic_S italic_i italic_m ( over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , over^ start_ARG italic_Y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) > italic_\u03b2 , (3) where ljsubscript\ud835\udc59\ud835\udc57l_{j}italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is the gold subsequent text, p^i,ljsubscript^\ud835\udc5d\ud835\udc56subscript\ud835\udc59\ud835\udc57\\hat{p}_{i,l_{j}}over^ start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_i , italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT is the predicted probability of gold subsequent text, and \u03c4p\u2208[0,1]subscript\ud835\udf0f\ud835\udc5d01\\tau_{p}\\in[0,1]italic_\u03c4 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u2208 [ 0 , 1 ] is a threshold for controlling the probability that \u2133\u2133\\mathcal{M}caligraphic_M generates gold subsequent text.Report issue for preceding element\nBias Pattern Induction Based on the identified informative biased instances, we further induce certain explainable patterns that characterize several major types of dataset biases among the corpus. To this end, we first group the counter example pairs into several clusters, and then induce patterns for each cluster.Report issue for preceding element\nThe cluster of counter example pairs is derived based on the bias representation vectors of the counter example pairs, which refers to the representation vector of the bias component of a counter example pair. We obtain the bias representation vectors of a counter example pair\u27e8(Xi,Yi),(Xj,Yj)\u27e9subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57\\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle\u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9by extracting the similar parts in the representations of two examples (i.e. Hi\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56H^{\\mathcal{M}}_{i}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Hj\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57H^{\\mathcal{M}}_{j}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT). This is because, as described in the definition of counter instance pair, the similar parts of Hi\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56H^{\\mathcal{M}}_{i}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Hj\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57H^{\\mathcal{M}}_{j}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT carry the biased information.Report issue for preceding element\nAfter obtaining the representation vector of the biases in each counter example pair, we first apply Principal Component Analysis to reduce the dimension of bias representation vectors to two dimensions. As the dimension of data increases, the distances between data points become increasingly similar, so traditional distance metrics (such as Euclidean distance) would be less effective and in turn affect the performance of clustering algorithms. Then we perform clustering based on the dimension-reduced biased representation vectors using the density-based clustering method DBSCAN 111We find that the first two principal components can explain over 96% of the total variance. Thus, the left part may mainly be noise and would disturb the process of clustering. Hence, we perform the DBSCAN based on the first two PCA components. . Finally, we obtain counter example pairs within each cluster, and provide them to GPT 4 for summarizing bias patterns. For example, from the selected counter example pair in Figure 1 (b), we can summarize the position bias.Report issue for preceding element\nTo prevent the LLMs from utilizing dataset biases for making generation, meanwhile avoiding the drawbacks of fine-tuning-based methods, we propose a cost-effective and efficient in-context learning (ICL) based method. Concretely:Report issue for preceding element\nIn the zero-shot scenario, as shown in Figure 1 (b), we use the automatically induced bias patterns to explicitly tell the LLM what kind of information it should not use during inference by appending the text \u201c[bias xxx] is not related to [the goal of the task]\u201d to the end of the original prompt.Report issue for preceding element\nIn the few-shot scenario, we propose a counterfactual ICL method, which provides LLMs with automatically derived counterfactual examples to correct the LLM\u2019s belief about bias. Specifically, if we could find \u201ccounterfactual examples\u201d, on which using biased information for inference would conversely lead to incorrect generations. Then by providing such examples to LLMs in the prompt, LLMs would be implicitly informed that the biased information is not related to the subsequent text, and thus it would be regularized to not use biased information for making inferences. To find such \u201ccounterfactual examples\u201d, notice that according to the Influential Criterion, for an arbitrary counter example pair\u27e8(Xi,Yi),(Xj,Yj)\u27e9subscript\ud835\udc4b\ud835\udc56subscript\ud835\udc4c\ud835\udc56subscript\ud835\udc4b\ud835\udc57subscript\ud835\udc4c\ud835\udc57\\langle(X_{i},Y_{i}),(X_{j},Y_{j})\\rangle\u27e8 ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u27e9, the LLM would make improper generation upon instance i\ud835\udc56iitalic_i or j\ud835\udc57jitalic_j. Without generality, we denote this instance as i\ud835\udc56iitalic_i and instance i\ud835\udc56iitalic_i could be regarded as a counterfactual example for debiasing LLMs. Intuitively, in instance i\ud835\udc56iitalic_i the dataset bias leads to improper generations, which is contrary to most cases within the corpus, hence we call instance i\ud835\udc56iitalic_i as a counterfactual example.Report issue for preceding element\nHence, to correct the LLM\u2019s belief about bias, we construct the prompt with such counterfactual examples using the following format: \u201c<EXAMPLES>. Note that you should not utilize biased information to make generations\u201d, where <EXAMPLES> are the counterfactual examples.Report issue for preceding element\nIn this work, we use llama2-13B-chat [CITATION] and vicuna-13B-v1.5 [CITATION] for our experiments. Without loss of generality, we examine our approach on datasets that have a clear set of possible answers, e.g., multiple-choice question-answering task. So that we can implement the S\u2062i\u2062m\u2062(\u22c5)\ud835\udc46\ud835\udc56\ud835\udc5a\u22c5Sim(\\cdot)italic_S italic_i italic_m ( \u22c5 ) function in Equation 1 using an exact match of strings. If matched, the function\u2019s value is 1, otherwise it\u2019s 0. So \u03b1\ud835\udefc\\alphaitalic_\u03b1 and \u03b2\ud835\udefd\\betaitalic_\u03b2 can be any value between 0 and 1. Additionally, we derive the representation of input text by employing the embedding vector of the last token at the top of the LLM\u2019s layer, and the cosine function is employed as the scoring function S\u2062(\u22c5)\ud835\udc46\u22c5S(\\cdot)italic_S ( \u22c5 ) to measure the similarity between these hidden states.Report issue for preceding element\nTo derive bias representation vector of a counter example pair, we need to extract similar parts in the hidden states corresponding to two examples of the counter example pair. This is because, the similar parts in the hidden states carry the biased information as mentioned in Section 3.2. To this end, we obtain the similar components of two hidden states in an element-wise manner. Specifically, we use the following function:Report issue for preceding element\nf(Hi\u2062k,Hj\u2062k)={(Hi\u2062k+Hj\u2062k)/2i\u2062f\u2062|Hi\u2062k\u2212Hj\u2062k|Hi\u2062k+Hj\u2062k<\u03bc0o\u2062t\u2062h\u2062e\u2062r\u2062w\u2062i\u2062s\u2062ef(H_{ik},H_{jk})\\!=\\!\\left\\{\\begin{matrix}(H_{ik}\\!+\\!H_{jk})/2&if\\frac{|H_{ik% }-H_{jk}|}{H_{ik}+H_{jk}}\\!<\\!\\mu\\\\ 0&otherwise\\end{matrix}\\right.italic_f ( italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT , italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT ) = { start_ARG start_ROW start_CELL ( italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT ) / 2 end_CELL start_CELL italic_i italic_f divide start_ARG | italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT - italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT | end_ARG start_ARG italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT end_ARG < italic_\u03bc end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL italic_o italic_t italic_h italic_e italic_r italic_w italic_i italic_s italic_e end_CELL end_ROW end_ARG (4) where Hi\u2062k,Hj\u2062ksubscript\ud835\udc3b\ud835\udc56\ud835\udc58subscript\ud835\udc3b\ud835\udc57\ud835\udc58H_{ik},H_{jk}italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT , italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT are the k-th element of two hidden states Hi\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc56H^{\\mathcal{M}}_{i}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Hj\u2133subscriptsuperscript\ud835\udc3b\u2133\ud835\udc57H^{\\mathcal{M}}_{j}italic_H start_POSTSUPERSCRIPT caligraphic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. If Hi\u2062ksubscript\ud835\udc3b\ud835\udc56\ud835\udc58H_{ik}italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT and Hj\u2062ksubscript\ud835\udc3b\ud835\udc57\ud835\udc58H_{jk}italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT are similar enough, then their difference should be relatively small. We measure such difference using |Hi\u2062k\u2212Hj\u2062k|subscript\ud835\udc3b\ud835\udc56\ud835\udc58subscript\ud835\udc3b\ud835\udc57\ud835\udc58|H_{ik}-H_{jk}|| italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT - italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT |/|Hi\u2062k+Hj\u2062k|subscript\ud835\udc3b\ud835\udc56\ud835\udc58subscript\ud835\udc3b\ud835\udc57\ud835\udc58|H_{ik}+H_{jk}|| italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT |, and then using a threshold \u03bc\ud835\udf07\\muitalic_\u03bc to determine if |Hi\u2062k\u2212Hj\u2062k|subscript\ud835\udc3b\ud835\udc56\ud835\udc58subscript\ud835\udc3b\ud835\udc57\ud835\udc58|H_{ik}-H_{jk}|| italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT - italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT |/|Hi\u2062k+Hj\u2062k|subscript\ud835\udc3b\ud835\udc56\ud835\udc58subscript\ud835\udc3b\ud835\udc57\ud835\udc58|H_{ik}+H_{jk}|| italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT | is small enough, in other words, Hi\u2062ksubscript\ud835\udc3b\ud835\udc56\ud835\udc58H_{ik}italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT and Hj\u2062ksubscript\ud835\udc3b\ud835\udc57\ud835\udc58H_{jk}italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT are similar enough. If they are similar enough, we use the average of Hi\u2062ksubscript\ud835\udc3b\ud835\udc56\ud835\udc58H_{ik}italic_H start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT and Hj\u2062ksubscript\ud835\udc3b\ud835\udc57\ud835\udc58H_{jk}italic_H start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT to represent the k-th element of the bias representation vector of a counter example pair. If not, we use 0 to represent the k-th element of the bias representation vector. In practice, we choose \u03bc\ud835\udf07\\muitalic_\u03bc by controlling the ratio that the two elements of certain position can be considered as similar enough in MNLI dataset when using llama2-13B-chat. We set a strict threshold of 0.15 for the ratio to ensure that the bias representation vectors of the counter example pairs have purer bias information.Report issue for preceding element\nMoreover, note that, it is UNNECESSARY to run CAL upon the whole corpus to obtain the biased instances and the bias patterns. A subset would be enough (e.g., 2,0000 instances) to save the computational cost. In the Section 4.8 and Appendix C, we provide the sensitivity analysis of the dataset size and hyperparameters, including the influence of the size of data for obtaining the counter instance pairs and the thresholds.Report issue for preceding element\nIn few-shot scenarios, to make results comparable, we ensure that the number of examples in prompts equals that used in other few-shot baselines. Additionally, we maintain the order of gold answers that appear in the few-shot examples to avoid introducing additional label bias. We report the average results across 10 runs considering the randomness in sampling counterfactual examples.Report issue for preceding element\nBelow we call our method zero-shot-CAL and few-shot-CAL in zero-shot and few-shot settings respectively. More details about experimental settings are provided in Appendix.Report issue for preceding element\nWe examine the effectiveness of CAL by investigating whether CAL could debias LLMs to improve the generalizability and unharmfulness of LLMs.Report issue for preceding element\nTo evaluate the improvement of generalizability, we conduct experiments by deriving biased instances and bias patterns on dataset A and utilizing the identified instances and biased patterns to debias both dataset A and dataset B. Heuristically, two datasets A and B may share different dataset bias distributions. If an LLM only adapts to dataset A, then its performance upon dataset B would be impacted. On the contrary, if an LLM can focus more on semantics, the performance on both datasets would be improved. Hence, the generalizability could be evaluated by the performance improvement compared to baseline methods. Specifically, We evaluate our approach on benchmarks representing two categories of bias: (1) Generative-LLM-specific biases. We employ the Chatbot and the MT-Bench datasets [CITATION] as benchmarks. On both datasets, LLM is required to choose a better response from two candidates. We induce the bias patterns on the Chatbot dataset, then test whether the Chatbot-based bias patterns can be utilized to debias LLMs on both the Chatbot and the MT-Bench dataset. (2) Task-specific biases. We choose the natural language inference dataset MNLI [CITATION] and the corresponding manually debiased dataset HANS [CITATION] as benchmarks. Hence, models that only utilize the biased information often perform close to a random baseline on HANS. The bias patterns are induced from the MNLI dataset, then test whether CAL can utilize the induced bias patterns to debias LLMs on both the MNLI and the HANS datasets.Report issue for preceding element\nTo evaluate the improvement of unharmfulness, we conduct experiments on the BBQ [CITATION] and the UNQOVER [CITATION] dataset, which is designed for evaluating stereotype biases (such as gender bias and racial bias) of LLMs. These two datasets containing 9 and 4 types of stereotype bias, respectively. On these two datasets, if the model achieves a higher accuracy, then it could be regarded as having a lower likelihood of containing stereotypes.Report issue for preceding element\nOn Chatbot and MT-Bench dataset, model performance is evaluated based on the agreement ratio between human-majority annotations and LLMs. On other datasets, model performance is evaluated using accuracy.Report issue for preceding element\nWe compare the casual-guided active learning method with two categories of baseline methods:Report issue for preceding element\nvanilla zero-shot and few-shot baselines We examine the vanilla zero-shot and few-shot performance of LLMs using the prompt of [CITATION].Report issue for preceding element\nzero-shot-known-bias These methods mainly rely on human prior knowledge of bias to design debiasing prompts. For Chatbot and MT-Bench datasets, we compare CAL with the debiasing method of swapping positions proposed in [CITATION]. For BBQ and UNQOVER datasets, we follow the instruction from [CITATION] to avoid stereotype bias. For MNLI and HANS datasets, we use the debiasing prompt to prevent lexical overlap and subsequence bias proposed in [CITATION].Report issue for preceding element\nTo the best of our knowledge, the only few-shot debiasing method comes from [CITATION]. However, this method is unsuitable for our dataset. Details can be seen in Appendix G.Report issue for preceding element\nWe list the experimental results of two LLMs on six datasets in Table 1. From which we find that:Report issue for preceding element\n(1) Compared to the vanilla zero-shot shows that, in general, the prior knowledge-based zero-shot debiasing methods show improved performance on all the datasets. This indicates that through ICL, LLMs can both effectively debias themselves and avoid the in-distribution performance degradation which is always associated with fine-tuning-based approaches [CITATION], suggesting the superiority of ICL-based debiasing methods.Report issue for preceding element\n(2) Compared to the zero-shot baselines and few-shot baselines, in general, few-shot CAL achieves consistent performance improvement on the two categories of benchmarks. This demonstrates that, CAL can improve both the generalizability and the unharmfuless of LLMs, and suggests that by utilizing the essential differences between semantic information, CAL can identify a set of biased instances, and the counterfactual ICL-based prompts can effectively leverage the biased counterfactual examples to debias LLMs. Report issue for preceding element\n(3) Compared with vanilla zero-shot baselines, zero-shot CAL can consistently improve model performance on all the datasets, and even surpass the performance of few-shot methods on part of benchmarks. The effectiveness of zero-shot CAL suggests that the biased patterns induced by CAL are typical and truly exist in the datasets. This is because, by utilizing the causal invariance together with the influential and typical criterion, a set of typical biased instances could be selected, so that the biased patterns could be effectively induced.Report issue for preceding element\n(4) Compared with the prior knowledge-based zero-shot debiasing methods, zero-shot CAL shows comparable or better performance on two categories of benchmarks. On the one hand, the complexity of the distribution of dataset biases brings challenges for precisely and comprehensively detecting the potential biases. On the other hand, the comparable performance between zero-shot CAL and prior knowledge-based zero-shot debiasing methods shows the effectiveness of our approach, and the potential for application in real-world scenarios, as it would be impractical to investigate all biases for various real-world corpus.Report issue for preceding element\n(5) In general, our method is effective for both llama2-13B-chat and vicuna-13B-v1.5. This suggests the prevalence of biases in LLMs, and demonstrates the generality of our approach in adapting to different LLMs.Report issue for preceding element\nWe argue that one of our potential major contributions is that by utilizing the causal invariance together with the influential and typical criterion, we can identify a set of typical biased instances, and then autonomously summarize explainable bias patterns from data. In Figure 2, we present the results of clustering analysis based on the bias representations derived from bias instances, and bias patterns summarized from the clustered categories. Experiments are conducted using llama2-13B-chat.Report issue for preceding element\nOverall, it can be observed that bias representations are concentrated in several distinct groups after dimensionality reduction through PCA. Moreover, the bias patterns summarized based on different clustering categories are also distinguished. This indicates that our method could discover different types of biased instances and then induce bias patterns.Report issue for preceding element\nBased on the counter example pairs derived from the Chatbot dataset, CAL can simultaneously induce position bias, verbosity bias, and format bias, which is separately identified by several previous research [CITATION], suggesting the efficiency and effectiveness of our approach. Furthermore, we also observe several potential bias patterns such as \u201clength or complexity of a response\u201d and \u201cthe presence of specific details or a confident tone\u201d,Report issue for preceding element\nthat are previously unreported. When we tell llama2-13B-chat not to make predictions based on these biases, its performance increases on both Chatbot and MT-Bench datasets, suggesting that these patterns could be the truly existing biases. Among the 9 known types of stereotype biases in the BBQ dataset [CITATION], our method can automatically identify 7 of them without prior knowledge (the bias of gender, sexual orientation, and religion are grouped into \u201ccultural association of a name\u201d during the bias induction procedure). On the MNLI dataset, we observe some unreported new bias patterns such as \u201cspeculative language in the hypothesis\u201d (e.g., should, perhaps, possibly), and we can also improve the performance of llama2-13B-chat by telling it not to make predictions based on these bias patterns. More analyses of the counter example pairs can be seen in Appendix B.Report issue for preceding element\nThe automatically summarized bias patterns demonstrate the diversity of dataset biases in practical datasets, and it would be impractical to identify all of them manually. Therefore, there is an urgent need for methods to automatically identify biases. As a pioneer work, we explored that the LLMs can be automatically debiased by combining the causal mechanism and active learning, suggesting the potential feasibility of utilizing LLMs to autonomously debias themselves.Report issue for preceding element\nThe pretraining corpus of different LLMs share unnegligible overlaps, so they would also possess common biases. Hence, we investigate the generalizability of the automatically induced bias patterns by testing if it is possible to debias LLM-A based on the bias pattern identified from another LLM-B. Specifically, we attempt to debias GPT-4 based on the bias pattern (and the corresponding debiasing prompt) identified from llama2-13b-chat. Experimental results are shown in Table 2, from which we can observe that compared to vanilla zero-shot, ZS-CAL achieves higher performance in most cases. This demonstrated that different LLMs might share similar bias patterns and we can debias an LLM based on the bias pattern identified from other LLMs, which further demonstrates the universality of our method.Report issue for preceding element\nIn the above sections, we induce the explainable bias patterns using GPT-4. We also attempt to use the open-source LLM Qwen1.5-72B-Chat for inducing bias patterns to examine the generalizability. As Table 3 shows, the results still outperform the baseline methods with the biased patterns induced by free open-source LLM, while slightly inferior to that of GPT-4. This shows the generality of our approach, and implicates the potential application in real-world scenarios.Report issue for preceding element\nTo investigate the influence of the dataset size used in our framework, We conducted experiments using a 20% subset of the MNLI dataset utilized in our main experiments, employing the llama2-13b-chat model. As Table 4 shows, the performance of CAL keeps relatively stable with 20% data. Moreover, our approach still far outperforms the baseline method on the HANS dataset, which demonstrates the effectiveness of our approach to debias LLMs. This indicates that our method is still effective in situations where data is relatively scarce.Report issue for preceding element\nPrevious analyses demonstrate that LLMs still suffer from biases such as position bias [CITATION] and stereotyping bias [CITATION]. To mitigate the LLMs\u2019 biases, one line of methods relies on researchers\u2019 prior knowledge to artificially recognize the potential dataset biases, followed by debiasing through prompt-based regularization or aligning with human through instruct tuning [CITATION]. However, these methods are limited by the dependence on researchers\u2019 prior. Moreover, due to the diversity of dataset biases [CITATION], it is unrealistic to identify them one by one manually. To tackle these issues, automatic debiasing methods are proposed. They automatically extract bias features characterizing the dataset biases by training certain biased models [CITATION] for regularizing the main model. However, such methods are designed for discriminative models and are hard to adapt to generative LLMs.Report issue for preceding element\nIn this paper, we propose a causal-guided active learning framework for automatically debiasing generative LLMs. We borrow the idea from active learning [CITATION] by first automatically identifying the potentially biased instances using the causal invariance mechanism, then automatically selecting the informative biased instances using the typical criterion and influential criterion. Based on such biased instances, the LLMs are regularized using the ICL-based method to prevent them from utilizing the bias patterns.Report issue for preceding element\nIn this paper, we propose a causal-guided active learning framework. Depending on the difference between the dataset biases and semantics in causal invariance, we can automatically identify counter example pairs that contain bias. Then we utilize an influential and a typical criterion to select counter example pairs that are more informative for inducing bias patterns. Finally, a cost-saving yet effective ICL-based debiasing method is proposed to prevent the LLM from utilizing biases for generation. Experimental results show that our approach can effectively recognize various bias patterns automatically, and debias LLMs to enhance their generalizability and unharmfulness.Report issue for preceding element\nWe thank the anonymous reviewers for their constructive comments and gratefully acknowledge the National Natural Science Foundation of China (U22B2059, 62176079), and the Natural Science Foundation of Heilongjiang Province (Y02022F005).Report issue for preceding element\nAlthough our method can automatically debias LLMs, the identification of typical bias instances relies on the hidden state and the predicted probability of the gold subsequent text, which are inaccessible in proprietary models such as GPT-4. This limitation makes it challenging for us to comprehensively uncover the bias patterns present in closed-source models.Report issue for preceding element",
  "citations": [
    {
      "tag": "Pearl et\u00a0al. (2000)",
      "title": "Models, reasoning and inference.",
      "authors": "Judea Pearl et\u00a0al. 2000.",
      "journal": "Cambridge, UK: CambridgeUniversityPress, 19."
    },
    {
      "tag": "Lyu et\u00a0al. (2023)",
      "title": "Feature-level debiased natural language understanding.",
      "authors": "Yougang Lyu, Piji Li, Yechang Yang, Maarten de\u00a0Rijke, Pengjie Ren, Yukun Zhao, Dawei Yin, and Zhaochun Ren. 2023.",
      "journal": "InProceedings of the AAAI Conference on Artificial Intelligence, volume\u00a037, pages 13353\u201313361."
    },
    {
      "tag": "Xu et\u00a0al. (2023)",
      "title": "An llm can fool itself: A prompt-based adversarial attack.",
      "authors": "Xilie Xu, Keyi Kong, Ning Liu, Lizhen Cui, Di\u00a0Wang, Jingfeng Zhang, and Mohan Kankanhalli. 2023.",
      "journal": "arXiv preprint arXiv:2310.13345."
    },
    {
      "tag": "Chiang et\u00a0al. (2023)",
      "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.",
      "authors": "Wei-Lin Chiang, Zhuohan Li, Zi\u00a0Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph\u00a0E Gonzalez, et\u00a0al. 2023.",
      "journal": "See https://vicuna. lmsys. org (accessed 14 April 2023)."
    },
    {
      "tag": "Liu et\u00a0al. (2023b)",
      "title": "Trustworthy llms: a survey and guideline for evaluating large language models\u2019 alignment.",
      "authors": "Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo, Hao Cheng, Yegor Klochkov, Muhammad\u00a0Faaiz Taufiq, and Hang Li. 2023b.",
      "journal": "InSocially Responsible Language Modelling Research."
    },
    {
      "tag": "Huang et\u00a0al. (2023)",
      "title": "Trustgpt: A benchmark for trustworthy and responsible large language models.",
      "authors": "Yue Huang, Qihui Zhang, Lichao Sun, et\u00a0al. 2023.",
      "journal": "arXiv preprint arXiv:2306.11507."
    },
    {
      "tag": "Sanh et\u00a0al. (2020)",
      "title": "Learning from others\u2019 mistakes: Avoiding dataset biases without modeling them.",
      "authors": "Victor Sanh, Thomas Wolf, Yonatan Belinkov, and Alexander\u00a0M Rush. 2020.",
      "journal": "InInternational Conference on Learning Representations."
    },
    {
      "tag": "Poliak et\u00a0al. (2018)",
      "title": "Hypothesis only baselines in natural language inference.",
      "authors": "Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, and Benjamin Van\u00a0Durme. 2018.",
      "journal": "InProceedings of the Seventh Joint Conference on Lexical and Computational Semantics, pages 180\u2013191."
    },
    {
      "tag": "Pearl (2009)",
      "title": "Causality.",
      "authors": "Judea Pearl. 2009.",
      "journal": "Cambridge university press."
    },
    {
      "tag": "Ganguli et\u00a0al. (2023)",
      "title": "The capacity for moral self-correction in large language models.",
      "authors": "Deep Ganguli, Amanda Askell, Nicholas Schiefer, Thomas Liao, Kamil\u0117 Luko\u0161i\u016bt\u0117, Anna Chen, Anna Goldie, Azalia Mirhoseini, Catherine Olsson, Danny Hernandez, et\u00a0al. 2023.",
      "journal": "arXiv preprint arXiv:2302.07459."
    },
    {
      "tag": "Utama et\u00a0al. (2020)",
      "title": "Towards debiasing nlu models from unknown biases.",
      "authors": "Prasetya\u00a0Ajie Utama, Nafise\u00a0Sadat Moosavi, and Iryna Gurevych. 2020.",
      "journal": "InProceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7597\u20137610."
    },
    {
      "tag": "Liu et\u00a0al. (2022)",
      "title": "A survey on active deep learning: From model driven to data driven.",
      "authors": "Peng Liu, Lizhe Wang, Rajiv Ranjan, Guojin He, and Lei Zhao. 2022.",
      "journal": "ACM Comput. Surv., 54."
    },
    {
      "tag": "Achiam et\u00a0al. (2023)",
      "title": "Gpt-4 technical report.",
      "authors": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia\u00a0Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et\u00a0al. 2023.",
      "journal": "arXiv preprint arXiv:2303.08774."
    },
    {
      "tag": "Zhan et\u00a0al. (2022)",
      "title": "A comparative survey of deep active learning.",
      "authors": "Xueying Zhan, Qingzhong Wang, Kuan-hao Huang, Haoyi Xiong, Dejing Dou, and Antoni\u00a0B. Chan. 2022.",
      "journal": "arXiv preprint arXiv:2203.13450."
    },
    {
      "tag": "Aribandi et\u00a0al. (2021)",
      "title": "Ext5: Towards extreme multi-task scaling for transfer learning.",
      "authors": "Vamsi Aribandi, Yi\u00a0Tay, Tal Schuster, Jinfeng Rao, Huaixiu\u00a0Steven Zheng, Sanket\u00a0Vaibhav Mehta, Honglei Zhuang, Vinh\u00a0Q Tran, Dara Bahri, Jianmo Ni, et\u00a0al. 2021.",
      "journal": "InInternational Conference on Learning Representations."
    },
    {
      "tag": "Schick et\u00a0al. (2021)",
      "title": "Self-diagnosis and self-debiasing: A proposal for reducing corpus-based bias in nlp.",
      "authors": "Timo Schick, Sahana Udupa, and Hinrich Sch\u00fctze. 2021.",
      "journal": "Transactions of the Association for Computational Linguistics, 9:1408\u20131424."
    },
    {
      "tag": "Du et\u00a0al. (2023)",
      "title": "Towards stable natural language understanding via information entropy guided debiasing.",
      "authors": "Li\u00a0Du, Xiao Ding, Zhouhao Sun, Ting Liu, Bing Qin, and Jingshuo Liu. 2023.",
      "journal": "InProceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2868\u20132882."
    },
    {
      "tag": "Schuster et\u00a0al. (2019)",
      "title": "Towards debiasing fact verification models.",
      "authors": "Tal Schuster, Darsh Shah, Yun Jie\u00a0Serene Yeo, Daniel Roberto\u00a0Filizzola Ortiz, Enrico Santus, and Regina Barzilay. 2019.",
      "journal": "InProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3419\u20133425."
    },
    {
      "tag": "Si et\u00a0al. (2023)",
      "title": "Prompting gpt-3 to be reliable.",
      "authors": "Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan\u00a0Lee Boyd-Graber, and Lijuan Wang. 2023.",
      "journal": "InThe Eleventh International Conference on Learning Representations."
    },
    {
      "tag": "Parrish et\u00a0al. (2022)",
      "title": "Bbq: A hand-built bias benchmark for question answering.",
      "authors": "Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu\u00a0Mon Htut, and Samuel Bowman. 2022.",
      "journal": "InFindings of the Association for Computational Linguistics: ACL 2022, pages 2086\u20132105."
    },
    {
      "tag": "Zheng et\u00a0al. (2023)",
      "title": "Judging LLM-as-a-judge with MT-bench and chatbot arena.",
      "authors": "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi\u00a0Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph\u00a0E. Gonzalez, and Ion Stoica. 2023.",
      "journal": "InThirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track."
    },
    {
      "tag": "Cohn et\u00a0al. (1994)",
      "title": "Active learning with statistical models.",
      "authors": "David Cohn, Zoubin Ghahramani, and Michael Jordan. 1994.",
      "journal": "InAdvances in Neural Information Processing Systems, volume\u00a07."
    },
    {
      "tag": "Zhang et\u00a0al. (2022)",
      "title": "A survey of active learning for natural language processing.",
      "authors": "Zhisong Zhang, Emma Strubell, and Eduard Hovy. 2022.",
      "journal": "InProceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 6166\u20136190. Association for Computational Linguistics."
    },
    {
      "tag": "Zhu et\u00a0al. (2023)",
      "title": "Judgelm: Fine-tuned large language models are scalable judges.",
      "authors": "Lianghui Zhu, Xinggang Wang, and Xinlong Wang. 2023.",
      "journal": "arXiv preprint arXiv:2310.17631."
    },
    {
      "tag": "Navigli et\u00a0al. (2023)",
      "title": "Biases in large language models: Origins, inventory and discussion.",
      "authors": "Roberto Navigli, Simone Conia, and Bj\u00f6rn Ross. 2023.",
      "journal": "ACM Journal of Data and Information Quality."
    },
    {
      "tag": "Shaikh et\u00a0al. (2023)",
      "title": "On second thought, let\u2019s not think step by step! bias and toxicity in zero-shot reasoning.",
      "authors": "Omar Shaikh, Hongxin Zhang, William Held, Michael Bernstein, and Diyi Yang. 2023.",
      "journal": "InProceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4454\u20134470, Toronto, Canada. Association for Computational Linguistics."
    },
    {
      "tag": "Nie et\u00a0al. (2020)",
      "title": "Adversarial nli: A new benchmark for natural language understanding.",
      "authors": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. 2020.",
      "journal": "InProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4885\u20134901."
    },
    {
      "tag": "Williams et\u00a0al. (2018)",
      "title": "A broad-coverage challenge corpus for sentence understanding through inference.",
      "authors": "Adina Williams, Nikita Nangia, and Samuel\u00a0R Bowman. 2018.",
      "journal": "InNAACL-HLT."
    },
    {
      "tag": "Oba et\u00a0al. (2023)",
      "title": "In-contextual bias suppression for large language models.",
      "authors": "Daisuke Oba, Masahiro Kaneko, and Danushka Bollegala. 2023.",
      "journal": "arXiv preprint arXiv:2309.07251."
    },
    {
      "tag": "Touvron et\u00a0al. (2023)",
      "title": "Llama 2: Open foundation and fine-tuned chat models.",
      "authors": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et\u00a0al. 2023.",
      "journal": "arXiv preprint arXiv:2307.09288."
    },
    {
      "tag": "Li et\u00a0al. (2020)",
      "title": "Unqovering stereotyping biases via underspecified questions.",
      "authors": "Tao Li, Daniel Khashabi, Tushar Khot, Ashish Sabharwal, and Vivek Srikumar. 2020.",
      "journal": "InFindings of the Association for Computational Linguistics: EMNLP 2020, pages 3475\u20133489."
    },
    {
      "tag": "Liu et\u00a0al. (2023a)",
      "title": "Mftcoder: Boosting code llms with multitask fine-tuning.",
      "authors": "Bingchang Liu, Chaoyu Chen, Cong Liao, Zi\u00a0Gong, Huan Wang, Zhichao Lei, Ming Liang, Dajun Chen, Min Shen, Hailian Zhou, et\u00a0al. 2023a.",
      "journal": "arXiv preprint arXiv:2311.02303."
    },
    {
      "tag": "McCoy et\u00a0al. (2019)",
      "title": "Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference.",
      "authors": "Tom McCoy, Ellie Pavlick, and Tal Linzen. 2019.",
      "journal": "InProceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3428\u20133448."
    }
  ]
}