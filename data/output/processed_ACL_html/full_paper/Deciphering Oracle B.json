{
  "title": "Deciphering Oracle Bone Language with Diffusion Models",
  "text": "Oracle Bone Script (OBS) represents an ancient language inscribed on turtle shells and animal bones, extensively utilized during China\u2019s Shang Dynasty, a feudal dynasty dating back 3,000 years. The script not only chronicled the human geography and daily activities of that period but also encapsulates invaluable historical significance, offering a unique window into the linguistic and cultural practices of early Chinese civilization. However, despite the discovery of tens of thousands of fragments of oracle bones, a significant portion of the characters remain undeciphered Wang and Deng ( 2024 ) , leaving the rest shrouded in mystery. To date, more than 4,500 Oracle Bone Script (OBS) characters have been discovered, but only about 1,600 of these have been deciphered and linked to their modern Chinese counterparts. In modern Chinese, Unicode includes more than 90,000 Chinese characters, though only approximately 3,500 characters are commonly used in contemporary Chinese society. This challenge of understanding the remaining undeciphered OBS characters and linking them to modern Chinese has attracted significant research interest, with attempts being made to leverage modern AI technologies for the understanding of such an ancient language Zhang et\u00a0al. ( 2022 ); Jiang et\u00a0al. ( 2023 ); Wang and Deng ( 2024 ); Guan et\u00a0al. ( 2024 ) . Report issue for preceding element\nHowever, the majority of existing methodologies primarily focus on the recognition and understanding of already deciphered OBS Guo et\u00a0al. ( 2015 ); Meng et\u00a0al. ( 2018 ); Zhang et\u00a0al. ( 2019 ); Hu ( 2023 ) , with the utilization of AI to assist in the decipherment of unknown inscriptions remaining an underexplored area. This is partly because, unlike modern languages that can be digitized and stored as text due to established encoding systems, OBS lacks a standard input method or encoding scheme, resulting in its preservation predominantly in the form of images rather than digital text usually used in NLP methods. Additionally, since OBS was inscribed on turtle shells and animal bones, many of which have been damaged or fragmented upon discovery, there is essentially no complete corpus available. This absence of a comprehensive corpus severely limits the applicability of language models that require extensive datasets for training, such as BERT Devlin et\u00a0al. ( 2018 ) , RoBERTa Liu et\u00a0al. ( 2019 ) , and GPT Brown et\u00a0al. ( 2020 ) . Report issue for preceding element\nTo address the challenges inherent in the decipherment of OBS using conventional NLP methodologies, this paper introduces a novel approach by employing image-based generative techniques for auxiliary decipherment of OBS. Specifically, we train a conditional diffusion model that utilizes unseen categories of OBS as a conditional input to generate corresponding images of its modern counterpart. This direct provision of modern representations or potential decipherment clues leverages the model\u2019s learned evolution from ancient scripts to contemporary fonts, circumventing the corpus construction and other challenges that traditional NLP methods face with ancient languages. Notably, while our experiments focus on OBS, this training paradigm holds the potential for extension to other ancient languages, such as Cuneiform and Hieroglyphics. In summary, this paper makes three key contributions: Report issue for preceding element\n\u2022 We introduce a novel approach to the task of ancient script decipherment by utilizing image generation techniques, offering a novel solution to challenges that conventional NLP methods struggle to address. Report issue for preceding element \u2022 We propose Oracle Bone Script Decipher (OBSD), a conditional diffusion model optimized for OBS decipherment. Our Localized Structural Sampling technique enhances the model\u2019s ability to discern and interpret the intricate patterns of characters. Report issue for preceding element \u2022 OBSD demonstrates its effectiveness in decipherment through comprehensive ablation studies and benchmark comparisons. It offers a pioneering approach for AI-assisted ancient language decipherment, potentially laying a foundation for future research. Report issue for preceding element\nWe introduce a novel approach to the task of ancient script decipherment by utilizing image generation techniques, offering a novel solution to challenges that conventional NLP methods struggle to address. Report issue for preceding element\nWe propose Oracle Bone Script Decipher (OBSD), a conditional diffusion model optimized for OBS decipherment. Our Localized Structural Sampling technique enhances the model\u2019s ability to discern and interpret the intricate patterns of characters. Report issue for preceding element\nOBSD demonstrates its effectiveness in decipherment through comprehensive ablation studies and benchmark comparisons. It offers a pioneering approach for AI-assisted ancient language decipherment, potentially laying a foundation for future research. Report issue for preceding element\nApplying machine learning to the study of ancient languages represents a notable shift in linguistics and epigraphy. This area, distinct from the NLP tasks typically associated with modern languages, involves digitization, linguistic analysis, textual criticism, translation, and decipherment Jin et\u00a0al. ( 2023 ); Nuhn et\u00a0al. ( 2012 ); Ravi and Knight ( 2011 ) . For a comprehensive overview of this field, we direct interested readers to the survey by Sommerschield et al. Sommerschield et\u00a0al. ( 2023 ); Li et\u00a0al. ( 2020 ); Huang et\u00a0al. ( 2019 ); Yang and Fu ( 2020 ); Guo et\u00a0al. ( 2015 ) . Due to space constraints, our review is limited to literature most pertinent to oracle bone language decipherment. Report issue for preceding element\nThe oracle bone language is considered a form of hieroglyphic that uses pictorial symbols to represent specific meanings. It originated around 1500 BC and has evolved over thousands of years into modern Chinese characters. The evolution timeline can be summarized into seven periods as follows: Oracle Bone Script (1500 BC), Bronze Inscriptions (1300 BC - 221 BC), Seal Script (1100 BC - 221 BC), Spring & Autumn Characters (770 BC - 476 BC), Warring States Characters (475 BC - 221 BC), Clerical Script (221 BC - 220 AD) and Regular Script (around 3rd century AD). The continuous evolutionary path makes OBS a unique presence among ancient scripts. Many of its character forms have been preserved in modern standard Chinese characters. While these are significant overlaps in the forms and meanings of characters between adjacent periods, greater differences can be found between more distant periods. Some characters disappeared and later reappeared across different periods, highlighting the dynamic nature of this ancient writing system. Report issue for preceding element\nWhile the majority of work related to OBS has focused on employing CV or NLP techniques to recognize Zhang et\u00a0al. ( 2021a ); Fu et\u00a0al. ( 2022 ); Wang et\u00a0al. ( 2022 ) or understand Han et\u00a0al. ( 2020 ); Qi et\u00a0al. ( 2023 ); Hu ( 2023 ) already deciphered characters, the use of AI to assist in deciphering characters with unknown meanings remains a largely unexplored and challenging task. Among these, the case-based reasoning strategy developed by Zhang et al. Zhang et\u00a0al. ( 2021b ) stands out in its method of drawing parallels to already interpreted characters to decipher OBS. While effective to a degree, this approach is inherently constrained by its dependence on the corpus of previously deciphered characters, potentially stymieing the discovery of novel meanings. On another front, Chang et al.\u2019s cascade generative adversarial networks framework Chang et\u00a0al. ( 2022 ) presents an innovative attempt at deciphering, yet it faces challenges due to evolutionary gaps in OBS and the completeness of training data. These challenges arise because when a character disappears for a specific period, the evolutionary path relied upon by such methods no longer remains intact, significantly impacting the success rate of deciphering and restricting their effectiveness to small datasets with clear evolutionary paths. Report issue for preceding element\nIn this study, we focus on the task of OBS decipherment, aiming to predict the corresponding modern Chinese character forms for the oracle bone language. This endeavor not only seeks to match known characters but also to uncover new forms that could elucidate the meanings of these ancient scripts. Formally, the training set denoted as S = { ( s i , c i ) \u2223 s i \u2062 is an OBS instance and \u2062 c i \u2208 C } \ud835\udc46 conditional-set subscript \ud835\udc60 \ud835\udc56 subscript \ud835\udc50 \ud835\udc56 subscript \ud835\udc60 \ud835\udc56 is an OBS instance and subscript \ud835\udc50 \ud835\udc56 \ud835\udc36 S=\\{(s_{i},c_{i})\\mid s_{i}\\text{ is an OBS instance and }c_{i}\\in C\\} italic_S = { ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \u2223 italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is an OBS instance and italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 italic_C } , pairs OBS instances with their modern Chinese counterparts from a set of known Categories C \ud835\udc36 C italic_C . The model is designed to extend beyond the training set S \ud835\udc46 S italic_S , identifying modern equivalents for OBS instances s \u2032 superscript \ud835\udc60 \u2032 s^{\\prime} italic_s start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , and proposing new character forms where existing matches are absent. Report issue for preceding element\nTo achieve this, our approach utilizes a diffusion-based Ho et\u00a0al. ( 2020 ) model, for transforming OBS character images X ~ ~ \ud835\udc4b \\tilde{X} over~ start_ARG italic_X end_ARG into their modern Chinese equivalents, as illustrated in Figure 1 . The model operates in two phases: the forward process, the forward phase introduces noise to the modern Chinese character images X 0 subscript \ud835\udc4b 0 X_{0} italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , transitioning them towards a state resembling pure noise via a controlled Markov chain process, ultimately conforming to a Gaussian distribution \ud835\udca9 \u2062 ( 0 , I ) \ud835\udca9 0 \ud835\udc3c \\mathcal{N}(0,I) caligraphic_N ( 0 , italic_I ) . This is mathematically articulated as follows: Report issue for preceding element q \u2062 ( X 1 : T \u2223 X 0 ) = \u220f t = 1 T q \u2062 ( X t \u2223 X t \u2212 1 ) \ud835\udc5e conditional subscript \ud835\udc4b : 1 \ud835\udc47 subscript \ud835\udc4b 0 superscript subscript product \ud835\udc61 1 \ud835\udc47 \ud835\udc5e conditional subscript \ud835\udc4b \ud835\udc61 subscript \ud835\udc4b \ud835\udc61 1 q\\left(X_{1:T}\\mid X_{0}\\right)=\\prod_{t=1}^{T}q\\left(X_{t}\\mid X_{t-1}\\right) italic_q ( italic_X start_POSTSUBSCRIPT 1 : italic_T end_POSTSUBSCRIPT \u2223 italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = \u220f start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_q ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2223 italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) (1)\nwhere T \ud835\udc47 T italic_T denotes the total number of steps. For each step t \ud835\udc61 t italic_t , noise is added according to the following equation: Report issue for preceding element q \u2062 ( X t \u2223 X t \u2212 1 ) = \ud835\udca9 \u2062 ( X t \u2223 \u03b1 t \u2062 X t \u2212 1 , ( 1 \u2212 \u03b1 t ) \u2062 I ) \ud835\udc5e conditional subscript \ud835\udc4b \ud835\udc61 subscript \ud835\udc4b \ud835\udc61 1 \ud835\udca9 conditional subscript \ud835\udc4b \ud835\udc61 subscript \ud835\udefc \ud835\udc61 subscript \ud835\udc4b \ud835\udc61 1 1 subscript \ud835\udefc \ud835\udc61 \ud835\udc3c q\\left(X_{t}\\mid X_{t-1}\\right)=\\mathcal{N}\\left(X_{t}\\mid\\sqrt{\\alpha_{t}}X_{%\nt-1},\\left(1-\\alpha_{t}\\right)I\\right) italic_q ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2223 italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) = caligraphic_N ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2223 square-root start_ARG italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , ( 1 - italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) italic_I ) Report issue for preceding element (2)\nwhere \u03b1 t subscript \ud835\udefc \ud835\udc61 \\alpha_{t} italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is a hyperparameter controlling the noise intensity, and I \ud835\udc3c I italic_I represents the identity matrix. The transition from X 0 subscript \ud835\udc4b 0 X_{0} italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to a noisy state X t subscript \ud835\udc4b \ud835\udc61 X_{t} italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT over t \ud835\udc61 t italic_t step is captured by the equation: Report issue for preceding element X t = \u03b3 t \u2062 X 0 + 1 \u2212 \u03b3 t \u2062 \u03f5 , \u03f5 \u223c \ud835\udca9 \u2062 ( 0 , I ) formulae-sequence subscript \ud835\udc4b \ud835\udc61 subscript \ud835\udefe \ud835\udc61 subscript \ud835\udc4b 0 1 subscript \ud835\udefe \ud835\udc61 italic-\u03f5 similar-to italic-\u03f5 \ud835\udca9 0 \ud835\udc3c X_{t}=\\sqrt{\\gamma_{t}}X_{0}+\\sqrt{1-\\gamma_{t}}\\epsilon,\\quad\\epsilon\\sim%\n\\mathcal{N}(0,I) italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = square-root start_ARG italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + square-root start_ARG 1 - italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_\u03f5 , italic_\u03f5 \u223c caligraphic_N ( 0 , italic_I ) (3)\nwith \u03b3 t subscript \ud835\udefe \ud835\udc61 \\gamma_{t} italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT being the cumulative product of \u03b1 \ud835\udefc \\alpha italic_\u03b1 values up to t \ud835\udc61 t italic_t . Report issue for preceding element\nThe denoising phase employs a U-Net architecture Ronneberger et\u00a0al. ( 2015 ) for the model f \u03b8 subscript \ud835\udc53 \ud835\udf03 f_{\\theta} italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT , trained to predict the noise \u03f5 italic-\u03f5 \\epsilon italic_\u03f5 and restore the image. The training objective minimizes the loss function: Report issue for preceding element \u2112 = \ud835\udd3c \u03f5 , \u03b3 \u2062 \u2016 \u03f5 \u2212 f \u03b8 \u2062 ( X ~ , X t , \u03b3 ) \u2016 2 \u2112 subscript \ud835\udd3c italic-\u03f5 \ud835\udefe superscript norm italic-\u03f5 subscript \ud835\udc53 \ud835\udf03 ~ \ud835\udc4b subscript \ud835\udc4b \ud835\udc61 \ud835\udefe 2 \\mathcal{L}=\\mathbb{E}_{\\epsilon,\\gamma}\\left\\|\\epsilon-f_{\\theta}\\left(\\tilde%\n{X},X_{t},\\gamma\\right)\\right\\|^{2} caligraphic_L = blackboard_E start_POSTSUBSCRIPT italic_\u03f5 , italic_\u03b3 end_POSTSUBSCRIPT \u2225 italic_\u03f5 - italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( over~ start_ARG italic_X end_ARG , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\u03b3 ) \u2225 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT (4)\nwhich measures the discrepancy between the actual noise \u03f5 italic-\u03f5 \\epsilon italic_\u03f5 and its estimation by the f \u03b8 subscript \ud835\udc53 \ud835\udf03 f_{\\theta} italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT . In the inference stage p \u03b8 \u2062 ( X t \u2223 X t , X ~ ) subscript \ud835\udc5d \ud835\udf03 conditional subscript \ud835\udc4b \ud835\udc61 subscript \ud835\udc4b \ud835\udc61 ~ \ud835\udc4b p_{\\theta}(X_{t}\\mid X_{t},\\tilde{X}) italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2223 italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over~ start_ARG italic_X end_ARG ) , we reverse the noise addition process, starting from the noisiest state X T subscript \ud835\udc4b \ud835\udc47 X_{T} italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT and iteratively denoising down to t = 1 \ud835\udc61 1 t=1 italic_t = 1 . Report issue for preceding element X t \u2212 1 = 1 \u03b1 t \u2062 ( X t \u2212 1 \u2212 \u03b1 t 1 \u2212 \u03b3 t \u2062 f \u03b8 \u2062 ( X ~ , X t , \u03b3 t ) ) + 1 \u2212 \u03b1 t \u2062 \u03f5 t subscript \ud835\udc4b \ud835\udc61 1 1 subscript \ud835\udefc \ud835\udc61 subscript \ud835\udc4b \ud835\udc61 1 subscript \ud835\udefc \ud835\udc61 1 subscript \ud835\udefe \ud835\udc61 subscript \ud835\udc53 \ud835\udf03 ~ \ud835\udc4b subscript \ud835\udc4b \ud835\udc61 subscript \ud835\udefe \ud835\udc61 1 subscript \ud835\udefc \ud835\udc61 subscript italic-\u03f5 \ud835\udc61 X_{t-1}=\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(X_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-%\n\\gamma_{t}}}f_{\\theta}\\left(\\tilde{X},X_{t},\\gamma_{t}\\right)\\right)+\\sqrt{1-%\n\\alpha_{t}}\\epsilon_{t} italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 - italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG 1 - italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( over~ start_ARG italic_X end_ARG , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) + square-root start_ARG 1 - italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT Report issue for preceding element (5)\nwhere \u03f5 t \u223c \ud835\udca9 \u2062 ( 0 , I ) similar-to subscript italic-\u03f5 \ud835\udc61 \ud835\udca9 0 \ud835\udc3c \\epsilon_{t}\\sim\\mathcal{N}(0,I) italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u223c caligraphic_N ( 0 , italic_I ) introduces randomness to enhance the diversity of model generated results. The outcome is the denoised image X ^ 0 subscript ^ \ud835\udc4b 0 \\hat{X}_{0} over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , representing the deciphered results. Report issue for preceding element\nBuilding on this, our OBSD model integrates an Initial Decipherment phase with a Zero-shot Refinement stage to improve the decipherment accuracy. As shown in Figure 2 , initially, an OBS image X ~ ~ \ud835\udc4b \\tilde{X} over~ start_ARG italic_X end_ARG undergoes conditional diffusion to approximate an initial decipherment X 0 subscript \ud835\udc4b 0 X_{0} italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , which is then refined using a zero-shot learning approach, leveraging a reference style image X r \u2062 e \u2062 f subscript \ud835\udc4b \ud835\udc5f \ud835\udc52 \ud835\udc53 X_{ref} italic_X start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT to correct and enhance the structure. with a distinct style to enhance X 0 subscript \ud835\udc4b 0 X_{0} italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , learning from the structure of modern Chinese characters. The final result X F subscript \ud835\udc4b \ud835\udc39 X_{F} italic_X start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT emerges as a refined representation of the intended modern Chinese character, benefiting from the refinement process\u2019s structural insights. Report issue for preceding element\nAfter revisiting the fundamentals in Section 3.1 , a preliminary and somewhat naive idea was to directly utilize OBS images as the condition X ~ ~ \ud835\udc4b \\tilde{X} over~ start_ARG italic_X end_ARG and modern Chinese characters as the target images X 0 subscript \ud835\udc4b 0 X_{0} italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to train a conditional diffusion model for decipherment. However, as shown in Figure 3 , we observed that directly training such a model did not result in the accurate generation of the corresponding photos of modern Chinese characters. Instead, the model produces images comprised of a multitude of random stroke fragments, resembling gibberish. We speculate that this discrepancy arises because diffusion models are primarily designed for generating natural images, where the input conditions, such as edges and sketches, provide structural information to guide the generation of target images. However, in the context of deciphering OBS, the structural disparity between the input OBS images and the expected modern Chinese character outcomes is significant (see Figure 4(a) ), rendering the standard conditional diffusion model ineffective for accurate reconstruction of the target modern characters. To address this challenge, we introduce the concept of Localized Structural Sampling (LSS) as a means to aid the diffusion model in learning how to map local radical structures of OBS to the corresponding modern Chinese character space (see Figure 4(b) red marks), thereby enhancing the model\u2019s capability to bridge the structural gap between ancient inscriptions and contemporary linguistic forms. Report issue for preceding element\nFigure 4 has demonstrated that despite the considerable structural evolution from OBS to modern Chinese characters, certain local structures have been preserved. As shown in Figure 5 , to enable the diffusion model to learn these localized radical features, the LSS module employs a sliding window approach to segment the target modern Chinese character images X 0 \u2208 R H \u00d7 W \u00d7 3 subscript \ud835\udc4b 0 superscript \ud835\udc45 \ud835\udc3b \ud835\udc4a 3 X_{0}\\in R^{H\\times W\\times 3} italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2208 italic_R start_POSTSUPERSCRIPT italic_H \u00d7 italic_W \u00d7 3 end_POSTSUPERSCRIPT and corresponding OBS images X ~ \u2208 R H \u00d7 W \u00d7 3 ~ \ud835\udc4b superscript \ud835\udc45 \ud835\udc3b \ud835\udc4a 3 \\tilde{X}\\in R^{H\\times W\\times 3} over~ start_ARG italic_X end_ARG \u2208 italic_R start_POSTSUPERSCRIPT italic_H \u00d7 italic_W \u00d7 3 end_POSTSUPERSCRIPT into D \ud835\udc37 D italic_D patches of size p ~ \u00d7 p ~ ~ \ud835\udc5d ~ \ud835\udc5d \\tilde{p}\\times\\tilde{p} over~ start_ARG italic_p end_ARG \u00d7 over~ start_ARG italic_p end_ARG , denoted as X ~ ( d ) superscript ~ \ud835\udc4b \ud835\udc51 \\tilde{X}^{(d)} over~ start_ARG italic_X end_ARG start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT and X t ( d ) \u2208 R p ~ \u00d7 p ~ \u00d7 3 , d = 1 , 2 , \u2026 \u2062 D , p ~ = 64 formulae-sequence superscript subscript \ud835\udc4b \ud835\udc61 \ud835\udc51 superscript \ud835\udc45 ~ \ud835\udc5d ~ \ud835\udc5d 3 formulae-sequence \ud835\udc51 1 2 \u2026 \ud835\udc37 ~ \ud835\udc5d 64 X_{t}^{(d)}\\in R^{\\tilde{p}\\times\\tilde{p}\\times 3},d=1,2,...D,\\tilde{p}=64 italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT \u2208 italic_R start_POSTSUPERSCRIPT over~ start_ARG italic_p end_ARG \u00d7 over~ start_ARG italic_p end_ARG \u00d7 3 end_POSTSUPERSCRIPT , italic_d = 1 , 2 , \u2026 italic_D , over~ start_ARG italic_p end_ARG = 64 . Here, X t subscript \ud835\udc4b \ud835\udc61 X_{t} italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT represents the modern text image with added Gaussian noise \u03f5 t subscript italic-\u03f5 \ud835\udc61 \\epsilon_{t} italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT at timestep t \ud835\udc61 t italic_t . Consequently, we focus on learning the conditional reverse process as follows: Report issue for preceding element p \u03b8 \u2062 ( X 0 : T ( i ) \u2223 X ~ ( i ) ) = p \u2062 ( X T ( i ) ) \u2062 \u220f t = 1 T p \u03b8 \u2062 ( X t \u2212 1 ( i ) \u2223 X t ( i ) , X ~ ( i ) ) subscript \ud835\udc5d \ud835\udf03 conditional superscript subscript \ud835\udc4b : 0 \ud835\udc47 \ud835\udc56 superscript ~ \ud835\udc4b \ud835\udc56 \ud835\udc5d superscript subscript \ud835\udc4b \ud835\udc47 \ud835\udc56 superscript subscript product \ud835\udc61 1 \ud835\udc47 subscript \ud835\udc5d \ud835\udf03 conditional superscript subscript \ud835\udc4b \ud835\udc61 1 \ud835\udc56 superscript subscript \ud835\udc4b \ud835\udc61 \ud835\udc56 superscript ~ \ud835\udc4b \ud835\udc56 p_{\\theta}(X_{0:T}^{(i)}\\mid\\tilde{X}^{(i)})=p(X_{T}^{(i)})\\prod_{t=1}^{T}p_{%\n\\theta}(X_{t-1}^{(i)}\\mid X_{t}^{(i)},\\tilde{X}^{(i)}) italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT 0 : italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT \u2223 over~ start_ARG italic_X end_ARG start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ) = italic_p ( italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ) \u220f start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT \u2223 italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , over~ start_ARG italic_X end_ARG start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ) Report issue for preceding element (6)\nBy adopting this approach, the model iteratively refines each patch by learning the nuanced mappings from the localized structures of OBS to their modern counterparts. The loss function in Equation 4 can then be rewritten as follows: Report issue for preceding element \u03f5 ^ t ( d ) = f \u03b8 \u2062 ( X t ( d ) , X ~ ( d ) , t ) \u2112 \u2032 = \ud835\udd3c t , d \u2062 \u2016 \u03f5 ^ t ( d ) \u2212 \u03f5 t ( d ) \u2016 2 superscript subscript ^ italic-\u03f5 \ud835\udc61 \ud835\udc51 subscript \ud835\udc53 \ud835\udf03 superscript subscript \ud835\udc4b \ud835\udc61 \ud835\udc51 superscript ~ \ud835\udc4b \ud835\udc51 \ud835\udc61 superscript \u2112 \u2032 subscript \ud835\udd3c \ud835\udc61 \ud835\udc51 superscript norm superscript subscript ^ italic-\u03f5 \ud835\udc61 \ud835\udc51 superscript subscript italic-\u03f5 \ud835\udc61 \ud835\udc51 2 \\begin{array}[]{c}\\hat{\\epsilon}_{t}^{(d)}=f_{\\theta}(X_{t}^{(d)},\\tilde{X}^{(%\nd)},t)\\\\\n\\mathcal{L^{\\prime}}=\\mathbb{E}_{t,d}\\parallel\\hat{\\epsilon}_{t}^{(d)}-%\n\\epsilon_{t}^{(d)}\\parallel^{2}\\end{array} start_ARRAY start_ROW start_CELL over^ start_ARG italic_\u03f5 end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT = italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT , over~ start_ARG italic_X end_ARG start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT , italic_t ) end_CELL end_ROW start_ROW start_CELL caligraphic_L start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = blackboard_E start_POSTSUBSCRIPT italic_t , italic_d end_POSTSUBSCRIPT \u2225 over^ start_ARG italic_\u03f5 end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT - italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT \u2225 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_CELL end_ROW end_ARRAY (7)\nHere, the model\u2019s goal is to minimize the difference between the estimated noise \u03f5 ^ t ( d ) superscript subscript ^ italic-\u03f5 \ud835\udc61 \ud835\udc51 \\hat{\\epsilon}_{t}^{(d)} over^ start_ARG italic_\u03f5 end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT , and the actual noise, \u03f5 t ( d ) superscript subscript italic-\u03f5 \ud835\udc61 \ud835\udc51 \\epsilon_{t}^{(d)} italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT , within each patch. Report issue for preceding element\nIn the inference phase, our approach involves dissecting the OBS image X ~ ~ \ud835\udc4b \\tilde{X} over~ start_ARG italic_X end_ARG into p ~ \u00d7 p ~ ~ \ud835\udc5d ~ \ud835\udc5d \\tilde{p}\\times\\tilde{p} over~ start_ARG italic_p end_ARG \u00d7 over~ start_ARG italic_p end_ARG patches, with p \ud835\udc5d p italic_p set at 64, through a structured grid layout, utilizing a sliding window for systematic extraction. The grid is arranged such that each cell hosts r \u00d7 r \ud835\udc5f \ud835\udc5f r\\times r italic_r \u00d7 italic_r patches, with r \ud835\udc5f r italic_r set at 16, allowing for a finer subdivision than the patch size p ~ ~ \ud835\udc5d \\tilde{p} over~ start_ARG italic_p end_ARG . Patches are extracted by navigating the grid in both horizontal and vertical directions with a step size of r \ud835\udc5f r italic_r . The initial decipherment model then progressively refines each patch by denoising and sampling. Report issue for preceding element\nUnique to our method is the handling of overlaps between patches. Instead of waiting until the denoising is complete, we average the overlapped sections at every timestep t \ud835\udc61 t italic_t , ensuring a uniform effect across the shared areas. This continuous averaging at each timestep prevents the formation of merging artifacts that typically occur when patches are processed independently. By smoothing transitions between patches during the sampling, we avoid edge discrepancies, maintaining the visual coherence of the reconstructed image. The sampling dynamics at each step are defined by Equation 5 , which guides the process toward a seamless and artifact-free image assembly. Algorithm 1 shows the pseudocode of LSS. Figure 5 demonstrates the overview pipeline of initial decipherment. Report issue for preceding element\nDespite advancements in generating modern Chinese characters with Localized Structural Sampling, initial decipherment efforts encounter notable obstacles, such as structural deformities and artifacts, highlighted in Figure 6 . These issues stem from the many-to-one training approach used, where multiple OBS instances are mapped to a single modern Chinese character image (see Figure 8 ), leading to confusion and inaccuracies in capturing character evolution, and resulting in artifacts or incomplete structures due to a limited variety of modern Chinese character samples. Report issue for preceding element\nTo overcome these challenges, we propose a zero-shot refinement strategy that involves training a model on a diverse collection of modern Chinese characters. Considering the multiple writing styles for modern Chinese characters, we aim to improve the model\u2019s understanding of their structure by employing a transformation task between different styles. We trained the module on 20 different modern Chinese character fonts to learn structural transformations between different modern Chinese character writing styles. As shown in Figure 8 , this training process is one-to-one. This method simplifies data collection by leveraging readily available font variations, thereby enhancing the model\u2019s understanding of character structures and enabling the application of this knowledge to improve initial decipherment results without direct training on OBS-to-modern character mappings. Report issue for preceding element\nOur zero-shot refinement approach is grounded in a generic font style transformation framework, as depicted in Figure 7 and based on Yang et\u00a0al. ( 2024 ) . The process involves a dual-encoder system to adapt the style of a source font image X 0 subscript \ud835\udc4b 0 X_{0} italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to a target style X r \u2062 e \u2062 f subscript \ud835\udc4b \ud835\udc5f \ud835\udc52 \ud835\udc53 X_{ref} italic_X start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT , preserving content integrity. The style encoder E s subscript \ud835\udc38 \ud835\udc60 E_{s} italic_E start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT extracts style features e s subscript \ud835\udc52 \ud835\udc60 e_{s} italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT from X r \u2062 e \u2062 f subscript \ud835\udc4b \ud835\udc5f \ud835\udc52 \ud835\udc53 X_{ref} italic_X start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT , while the content encoder E c subscript \ud835\udc38 \ud835\udc50 E_{c} italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT processes X o subscript \ud835\udc4b \ud835\udc5c X_{o} italic_X start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT and X r \u2062 e \u2062 f subscript \ud835\udc4b \ud835\udc5f \ud835\udc52 \ud835\udc53 X_{ref} italic_X start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT to obtain multi-scale content features F 0 = { f o 1 , f o 2 , f o 3 } subscript \ud835\udc39 0 superscript subscript \ud835\udc53 \ud835\udc5c 1 superscript subscript \ud835\udc53 \ud835\udc5c 2 superscript subscript \ud835\udc53 \ud835\udc5c 3 F_{0}=\\{f_{o}^{1},f_{o}^{2},f_{o}^{3}\\} italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = { italic_f start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_f start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_f start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT } and F r \u2062 e \u2062 f = { f r \u2062 e \u2062 f 1 , f r \u2062 e \u2062 f 2 , f r \u2062 e \u2062 f 3 } subscript \ud835\udc39 \ud835\udc5f \ud835\udc52 \ud835\udc53 superscript subscript \ud835\udc53 \ud835\udc5f \ud835\udc52 \ud835\udc53 1 superscript subscript \ud835\udc53 \ud835\udc5f \ud835\udc52 \ud835\udc53 2 superscript subscript \ud835\udc53 \ud835\udc5f \ud835\udc52 \ud835\udc53 3 F_{ref}=\\{f_{ref}^{1},f_{ref}^{2},f_{ref}^{3}\\} italic_F start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT = { italic_f start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_f start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_f start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT } , refined by a specialized UNet with Multi-scale Content Aggregation (MCA) and Reference-Structure Interaction (RSI) blocks for enhanced feature integration. The model employs cross-attention mechanisms to align features and address structural differences, formalized as: Report issue for preceding element S r \u2062 e \u2062 f \u2208 \u211d C r \u2062 e \u2062 f i \u00d7 H i \u2062 W i = flatten \u2062 ( f r \u2062 e \u2062 f i ) S s \u2208 \u211d C s i \u00d7 H i \u2062 W i = flatten \u2062 ( o i ) Q = \u03a6 q \u2062 ( S r \u2062 e \u2062 f ) , K = \u03a6 k \u2062 ( S s ) , V = \u03a6 v \u2062 ( S s ) subscript \ud835\udc46 \ud835\udc5f \ud835\udc52 \ud835\udc53 superscript \u211d superscript subscript \ud835\udc36 \ud835\udc5f \ud835\udc52 \ud835\udc53 \ud835\udc56 subscript \ud835\udc3b \ud835\udc56 subscript \ud835\udc4a \ud835\udc56 flatten superscript subscript \ud835\udc53 \ud835\udc5f \ud835\udc52 \ud835\udc53 \ud835\udc56 subscript \ud835\udc46 \ud835\udc60 superscript \u211d superscript subscript \ud835\udc36 \ud835\udc60 \ud835\udc56 subscript \ud835\udc3b \ud835\udc56 subscript \ud835\udc4a \ud835\udc56 flatten subscript \ud835\udc5c \ud835\udc56 formulae-sequence \ud835\udc44 subscript \u03a6 \ud835\udc5e subscript \ud835\udc46 \ud835\udc5f \ud835\udc52 \ud835\udc53 formulae-sequence \ud835\udc3e subscript \u03a6 \ud835\udc58 subscript \ud835\udc46 \ud835\udc60 \ud835\udc49 subscript \u03a6 \ud835\udc63 subscript \ud835\udc46 \ud835\udc60 \\begin{array}[]{c}S_{ref}\\in\\mathbb{R}^{C_{ref}^{i}\\times H_{i}W_{i}}=\\text{%\nflatten}(f_{ref}^{i})\\\\\nS_{s}\\in\\mathbb{R}^{C_{s}^{i}\\times H_{i}W_{i}}=\\text{flatten}(o_{i})\\\\\nQ=\\Phi_{q}(S_{ref}),~{}K=\\Phi_{k}(S_{s}),~{}V=\\Phi_{v}(S_{s})\\end{array} start_ARRAY start_ROW start_CELL italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \u00d7 italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = flatten ( italic_f start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) end_CELL end_ROW start_ROW start_CELL italic_S start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \u00d7 italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = flatten ( italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_CELL end_ROW start_ROW start_CELL italic_Q = roman_\u03a6 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT ) , italic_K = roman_\u03a6 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) , italic_V = roman_\u03a6 start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) end_CELL end_ROW end_ARRAY (8)\nwhere o i subscript \ud835\udc5c \ud835\udc56 o_{i} italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents the UNet feature derived from f o i superscript subscript \ud835\udc53 \ud835\udc5c \ud835\udc56 f_{o}^{i} italic_f start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT and e s subscript \ud835\udc52 \ud835\udc60 e_{s} italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , and \u03a6 q subscript \u03a6 \ud835\udc5e \\Phi_{q} roman_\u03a6 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , \u03a6 k subscript \u03a6 \ud835\udc58 \\Phi_{k} roman_\u03a6 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , \u03a6 v subscript \u03a6 \ud835\udc63 \\Phi_{v} roman_\u03a6 start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT denote linear projections. The deformation offset \u03b4 offset subscript \ud835\udeff offset \\delta_{\\text{offset}} italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT is calculated as follows: Report issue for preceding element F attn = softmax \u2062 ( Q \u2062 K T d k ) \u2062 V \u03b4 offset = FFN \u2062 ( F attn ) subscript \ud835\udc39 attn softmax \ud835\udc44 superscript \ud835\udc3e \ud835\udc47 subscript \ud835\udc51 \ud835\udc58 \ud835\udc49 subscript \ud835\udeff offset FFN subscript \ud835\udc39 attn \\begin{array}[]{c}F_{\\text{attn}}=\\text{softmax}(\\frac{QK^{T}}{\\sqrt{d_{k}}})V%\n\\\\\n\\delta_{\\text{offset}}=\\text{FFN}(F_{\\text{attn}})\\end{array} start_ARRAY start_ROW start_CELL italic_F start_POSTSUBSCRIPT attn end_POSTSUBSCRIPT = softmax ( divide start_ARG italic_Q italic_K start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT end_ARG start_ARG square-root start_ARG italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG end_ARG ) italic_V end_CELL end_ROW start_ROW start_CELL italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT = FFN ( italic_F start_POSTSUBSCRIPT attn end_POSTSUBSCRIPT ) end_CELL end_ROW end_ARRAY (9)\nThe output I f subscript \ud835\udc3c \ud835\udc53 I_{f} italic_I start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT is the result of rendering the source image with DCN Dai et\u00a0al. ( 2017 ) , considering the calculated deformation offset: Report issue for preceding element I f = DCN \u2062 ( o i , \u03b4 offset ) subscript \ud835\udc3c \ud835\udc53 DCN subscript \ud835\udc5c \ud835\udc56 subscript \ud835\udeff offset I_{f}=\\text{DCN}(o_{i},\\delta_{\\text{offset}}) italic_I start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = DCN ( italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT ) (10)\nIn adapting the framework for OBS decipherment, we streamline the model by focusing on a singular font style, thereby omitting the style contrastive refinement module and its contrastive loss, simplifying the training process. The encoders are trained using the offset loss \u2112 offset subscript \u2112 offset \\mathcal{L}_{\\text{offset}} caligraphic_L start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT , which measures the mean magnitude of deformation offsets: Report issue for preceding element \u2112 offset = m \u2062 e \u2062 a \u2062 n \u2062 ( \u2016 \u03b4 offset \u2016 ) subscript \u2112 offset \ud835\udc5a \ud835\udc52 \ud835\udc4e \ud835\udc5b norm subscript \ud835\udeff offset \\mathbf{\\mathcal{L}}_{\\text{offset}}=mean(\\left\\|\\delta_{\\text{offset}}\\right\\|) caligraphic_L start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT = italic_m italic_e italic_a italic_n ( \u2225 italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT \u2225 ) (11)\nwhere \u03b4 offset subscript \ud835\udeff offset \\delta_{\\text{offset}} italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT signifies the deformation offset, encapsulating structural information gleaned from the reference features, and the mean operation computes the average magnitude of these offsets. Report issue for preceding element\nAfter training, the zero-shot refinement module was directly employed to refine the results generated by the diffusion model. Report issue for preceding element\nTo train and evaluate the proposed OBSD model, we selected the HUST-OBS dataset Wang et\u00a0al. ( 2024 ) and EVOBC dataset Guan et\u00a0al. ( 2024 ) , which stands as one of the largest repositories of OBS, with 1,590 distinct characters depicted in 71,698 images. Recognizing the complexities involved in deciphering unknown OBS, which usually require comprehensive expert validation, we opted for already deciphered inscriptions in our testing set to streamline the evaluation process. Importantly, the categories of characters in the testing set were specifically chosen to be absent from the training set, ensuring that the model faces the genuine challenge of deciphering unseen and novel categories. The dataset was partitioned into training and test sets with a 9:1 ratio, providing a robust framework for assessment. Report issue for preceding element\nWhile the proposed OBSD model approaches OBS decipherment from an image generation perspective, it is crucial to acknowledge that traditional image generation metrics, such as SSIM Nilsson and Akenine-M\u00f6ller ( 2020 ) , are not suitable for this distinct challenge. Instead, we adopted OCR technology as a more objective measure of decipherment success. Our custom-built OCR tool, OBS-OCR, is a simple classifier using ResNet-101 backbone specifically trained on a large dataset of 88,899 categories modern Chinese characters to evaluate the model\u2019s output. The custom-built OCR tool achieved a recognition accuracy of 99.87% on 88,899 categories of Chinese characters, which demonstrates reliable performance to evaluate the decipherment results. Its aim is to automatically recognize the results generated by the diffusion models and compare these results with the ground truth in order to evaluate the model\u2019s deciphering performance. By comparing the OCR-recognized characters against their ground truth labels, we simulate a quantifiable form of expert validation. To make a more reliable and objective evaluation, we also incorporated the widely-used, open-source Chinese OCR tool PaddleOCR 1 1 1 https://github.com/PaddlePaddle/PaddleOCR as an additional OCR tool to support further evaluations. This dual-OCR method provides a robust framework for assessing the model\u2019s efficacy in accurately deciphering oracle bone languages. Report issue for preceding element\nIn quantitatively evaluating the performance of our proposed OBSD, we employ two distinct assessment criteria: single-round decipherment and multi-round decipherment. The single-round decipherment evaluation aims to gauge the method\u2019s capability to decipher individual samples accurately, providing insight into its immediate effectiveness. On the other hand, the multi-round decipherment assessment offers a more practical appraisal of the method\u2019s performance, where multiple attempts at deciphering a single image are permitted. This approach mirrors the iterative nature of real-world decipherment tasks, allowing for a comprehensive assessment of the method\u2019s resilience and adaptability over successive trials. Report issue for preceding element\nGiven the absence of dedicated tools for oracle bone language decipherment, we employ a comparative framework that adapts leading image-to-image translation methods to this specialized task. This set includes GAN-based approaches such as Pix2Pix Isola et\u00a0al. ( 2017 ) , CycleGAN Zhu et\u00a0al. ( 2017 ) , DRIT++ Lee et\u00a0al. ( 2020 ) , and diffusion-based methods like CDE Saharia et\u00a0al. ( 2022b ) , Palette Saharia et\u00a0al. ( 2022a ) , BBDM Li et\u00a0al. ( 2023 ) . This setting not only mirrors the core mechanism of our OBSD method but also allows for a comprehensive evaluation against the backdrop of the latest advancements in image translation. Each method was carefully adapted to the OBS context, ensuring consistent training and testing conditions for a fair evaluation. Report issue for preceding element\nIn the single-round decipherment evaluation, as shown in Table 1 , our OBSD demonstrates a significant advantage over the adapted image-to-image translation methods in deciphering oracle bone language. Notably, the top-1 accuracy for OBS-OCR and PaddleOCR achieved by OBSD stand at 41.0% and 30.0%, respectively, surpassing the performance of other methods. As the rank increases, there is a clear trend of improving accuracy, at Top-500 accuracy, OBSD reaches a 64.5% OBS-OCR recognition accuracy. It is noteworthy that all GAN-based approaches, such as Pix2Pix, Palette, DRIT++, and CycleGAN, exhibit minimal effectiveness in this context, with top-1 accuracies at 0%. This could be attributed to the GANs\u2019 inherent challenge in capturing the complex and nuanced mappings required for accurately deciphering the oracle bone language into modern Chinese. Surprisingly, the adapted diffusion models, despite their general-purpose nature, have shown commendable performance, underscoring the viability of leveraging image generation techniques in addressing the challenges traditional NLP algorithms encounter in decipherment tasks. This aligns with our methodological premise, validating the novel approach of integrating image-based generative models into the domain of linguistic decipherment. Report issue for preceding element\nIn addition, Table 2 presents the multi-round decipherment results, where a progressive increase in decipherment success rates can be witnessed across multiple trials. The OBS-OCR metric starts at a success rate of 41.0%, and levels out at 80.0% by the 10th trial, showcasing the cumulative benefit of iterative testing. Similarly, the PaddleOCR metric exhibits a consistent upward trend, commencing at 30.0% and culminating at 58.5% in the final trial. These results validate the incremental improvements achievable through successive attempts. Report issue for preceding element\nTo further examine the impact of individual components in our proposed method, we conducted an ablation study focusing on the LSS module and zero-shot refinement. The results, presented in Table 3 , highlight the limitations of employing only the basic conditional diffusion model for OBS decipherment, which resulted in notably low accuracy rates. Specifically, training the diffusion model without any enhancements led to outputs that were essentially nonsensical, characterized by random and uninterpretable stroke combinations (see Figure 3 ). The introduction of the LSS module marked a significant improvement, enabling the generation of decipherment outcomes with a Top-1 recognition rate of 37.5% for OBS-OCR and 24% for PaddleOCR. The addition of the zero-shot refinement module, in conjunction with the LSS, further increased the Top-1 accuracy for both OBS-OCR and PaddleOCR by an additional 3.5% and 6%, respectively. Report issue for preceding element\nFigure 9 showcases the qualitative results of various image-to-image translation models, with our method, OBSD, standing out by producing the most accurate reconstructions of modern Chinese characters from OBS inputs. Pix2Pix Isola et\u00a0al. ( 2017 ) , for example, generates outputs that are highly uniform across different inputs, demonstrating a lack of differentiation in character decipherment. On the other hand, DRIT++ Lee et\u00a0al. ( 2020 ) struggles to produce complete characters, often resulting in fragmented and unrecognizable forms. In stark contrast, OBSD demonstrates a robust capability to discern and reconstruct the intricate details of each OBS, leading to coherent and precise character forms that closely align with the ground truth. These results not only highlight the efficacy of OBSD but also its potential as a tool for experts in the field of oracle bone language decipherment. Report issue for preceding element\nTo demonstrate the performance of OBSD on authentic, undeciphered OBS, we present an extensive evaluation in the appendix, depicted in Figure 10 , 11 , 12 and 13 . This evaluation showcases a range of decipherment outcomes, from partial reconstructions that shed light on the structural elements of OBS characters, such as radicals and strokes, to complete character forms that exhibit a high resemblance to modern Chinese script. While the bulk of these results provide structural clues, the fully reconstructed characters hold particular promise, indicating the potential of OBSD to contribute meaningfully to the field of oracle bone language decipherment. Report issue for preceding element\nExperiment Results: We compared the proposed OBSD with other generic image generation models for the OBS deciphering task. As shown in Figure 9 , most generic image generation models fail to produce structurally complete Chinese characters. This is because these methods, based on conditional generation, attempt to directly map the input OBS image to modern characters, neglecting the structural and writing conventions of the characters. In contrast, the proposed OBSD addresses these issues by incorporating local radical structure information into the training process, resulting in more accurate outputs. Report issue for preceding element\nAnalysis of Proposed Modules: According to the experimental results, we found that the proposed LSS module effectively directs the diffusion model\u2019s focus towards the local structures of both OBS and modern Chinese characters. This results in clearer character strokes and more reasonable character structures. Additionally, the Zero-shot Refinement module refines the initial decipherment results by learning the structural characteristics of modern Chinese characters, ensuring a more precise and coherent structure. Report issue for preceding element\nGeneralizability to Other Languages: The proposed method was initially designed for ideographic or pictographic languages, such as Chinese characters or Mayan script, where a single character represents a word or morpheme. This design enables the adaptation of the method to similar languages. For alphabetic scripts, which typically have a small number of letters, decipherment is rarely an issue. The applicability of these methods to other languages presents an interesting research question, which we will explore in our future work. Report issue for preceding element\nIn this work, we presented OBSD, an innovative approach leveraging conditional image generation for the decipherment of OBS. Our novel Local Structure Sampling technique addresses the inherent challenges in learning modern Chinese characters\u2019 structures from limited samples, enabling effective structural correspondence learning between OBS and modern Chinese characters. Furthermore, the integration of a zero-shot refinement module significantly enhances the decipherment accuracy, a claim substantiated by promising results on the HUST-OBS dataset and EVOBC dataset. The potential of OBSD extends beyond OBS, offering prospects for deciphering other ancient scripts, such as hieroglyphs and Maya glyphs. Looking ahead, we aim to collaborate with epigraphy experts to further validate and refine the OBSD, aspiring to advance AI\u2019s role in the decipherment of ancient languages. Report issue for preceding element\nIn this study, we employed OCR technology, including a custom-built tool and the off-the-shelf package PaddleOCR, to evaluate the success of our OBSD in deciphering oracle bone language. While this approach offers a novel and objective metric, it is important to recognize its inherent limitations. However, these methods cannot be directly applied to evaluate truly undeciphered OBS, where the absence of ground truth necessitates expert validation. Report issue for preceding element\nEvaluating the decipherment results of entirely unknown OBS characters presents a unique challenge that goes beyond the capabilities of OCR technology. This task involves interpreting historical, cultural, and linguistic contexts that are deeply embedded within the languages. Therefore, the ultimate validation of our model\u2019s decipherment for such inscriptions requires the involvement of scholars and experts in oracle bone studies. We acknowledge the importance of this expert validation and are exploring collaborations with specialists in the field to assess the relevance and accuracy of our model\u2019s outputs for genuinely undeciphered texts. Report issue for preceding element\nThis work was supported by the National Natural Science Foundation of China (No. 61936003, No.62225603, No.62206103, No.62441604). Report issue for preceding element",
  "masked_text": "Oracle Bone Script (OBS) represents an ancient language inscribed on turtle shells and animal bones, extensively utilized during China\u2019s Shang Dynasty, a feudal dynasty dating back 3,000 years. The script not only chronicled the human geography and daily activities of that period but also encapsulates invaluable historical significance, offering a unique window into the linguistic and cultural practices of early Chinese civilization. However, despite the discovery of tens of thousands of fragments of oracle bones, a significant portion of the characters remain undeciphered [CITATION], leaving the rest shrouded in mystery. To date, more than 4,500 Oracle Bone Script (OBS) characters have been discovered, but only about 1,600 of these have been deciphered and linked to their modern Chinese counterparts. In modern Chinese, Unicode includes more than 90,000 Chinese characters, though only approximately 3,500 characters are commonly used in contemporary Chinese society. This challenge of understanding the remaining undeciphered OBS characters and linking them to modern Chinese has attracted significant research interest, with attempts being made to leverage modern AI technologies for the understanding of such an ancient language [CITATION].Report issue for preceding element\nHowever, the majority of existing methodologies primarily focus on the recognition and understanding of already deciphered OBS [CITATION], with the utilization of AI to assist in the decipherment of unknown inscriptions remaining an underexplored area. This is partly because, unlike modern languages that can be digitized and stored as text due to established encoding systems, OBS lacks a standard input method or encoding scheme, resulting in its preservation predominantly in the form of images rather than digital text usually used in NLP methods. Additionally, since OBS was inscribed on turtle shells and animal bones, many of which have been damaged or fragmented upon discovery, there is essentially no complete corpus available. This absence of a comprehensive corpus severely limits the applicability of language models that require extensive datasets for training, such as BERT [CITATION], RoBERTa [CITATION], and GPT [CITATION].Report issue for preceding element\nTo address the challenges inherent in the decipherment of OBS using conventional NLP methodologies, this paper introduces a novel approach by employing image-based generative techniques for auxiliary decipherment of OBS. Specifically, we train a conditional diffusion model that utilizes unseen categories of OBS as a conditional input to generate corresponding images of its modern counterpart. This direct provision of modern representations or potential decipherment clues leverages the model\u2019s learned evolution from ancient scripts to contemporary fonts, circumventing the corpus construction and other challenges that traditional NLP methods face with ancient languages. Notably, while our experiments focus on OBS, this training paradigm holds the potential for extension to other ancient languages, such as Cuneiform and Hieroglyphics. In summary, this paper makes three key contributions:Report issue for preceding element\n\u2022 We introduce a novel approach to the task of ancient script decipherment by utilizing image generation techniques, offering a novel solution to challenges that conventional NLP methods struggle to address.Report issue for preceding element \u2022 We propose Oracle Bone Script Decipher (OBSD), a conditional diffusion model optimized for OBS decipherment. Our Localized Structural Sampling technique enhances the model\u2019s ability to discern and interpret the intricate patterns of characters.Report issue for preceding element \u2022 OBSD demonstrates its effectiveness in decipherment through comprehensive ablation studies and benchmark comparisons. It offers a pioneering approach for AI-assisted ancient language decipherment, potentially laying a foundation for future research.Report issue for preceding element\nWe introduce a novel approach to the task of ancient script decipherment by utilizing image generation techniques, offering a novel solution to challenges that conventional NLP methods struggle to address.Report issue for preceding element\nWe propose Oracle Bone Script Decipher (OBSD), a conditional diffusion model optimized for OBS decipherment. Our Localized Structural Sampling technique enhances the model\u2019s ability to discern and interpret the intricate patterns of characters.Report issue for preceding element\nOBSD demonstrates its effectiveness in decipherment through comprehensive ablation studies and benchmark comparisons. It offers a pioneering approach for AI-assisted ancient language decipherment, potentially laying a foundation for future research.Report issue for preceding element\nApplying machine learning to the study of ancient languages represents a notable shift in linguistics and epigraphy. This area, distinct from the NLP tasks typically associated with modern languages, involves digitization, linguistic analysis, textual criticism, translation, and decipherment [CITATION]. For a comprehensive overview of this field, we direct interested readers to the survey by Sommerschield et al. [CITATION]. Due to space constraints, our review is limited to literature most pertinent to oracle bone language decipherment.Report issue for preceding element\nThe oracle bone language is considered a form of hieroglyphic that uses pictorial symbols to represent specific meanings. It originated around 1500 BC and has evolved over thousands of years into modern Chinese characters. The evolution timeline can be summarized into seven periods as follows: Oracle Bone Script (1500 BC), Bronze Inscriptions (1300 BC - 221 BC), Seal Script (1100 BC - 221 BC), Spring & Autumn Characters (770 BC - 476 BC), Warring States Characters (475 BC - 221 BC), Clerical Script (221 BC - 220 AD) and Regular Script (around 3rd century AD). The continuous evolutionary path makes OBS a unique presence among ancient scripts. Many of its character forms have been preserved in modern standard Chinese characters. While these are significant overlaps in the forms and meanings of characters between adjacent periods, greater differences can be found between more distant periods. Some characters disappeared and later reappeared across different periods, highlighting the dynamic nature of this ancient writing system.Report issue for preceding element\nWhile the majority of work related to OBS has focused on employing CV or NLP techniques to recognize [CITATION] or understand [CITATION] already deciphered characters, the use of AI to assist in deciphering characters with unknown meanings remains a largely unexplored and challenging task. Among these, the case-based reasoning strategy developed by Zhang et al. [CITATION] stands out in its method of drawing parallels to already interpreted characters to decipher OBS. While effective to a degree, this approach is inherently constrained by its dependence on the corpus of previously deciphered characters, potentially stymieing the discovery of novel meanings. On another front, Chang et al.\u2019s cascade generative adversarial networks framework [CITATION] presents an innovative attempt at deciphering, yet it faces challenges due to evolutionary gaps in OBS and the completeness of training data. These challenges arise because when a character disappears for a specific period, the evolutionary path relied upon by such methods no longer remains intact, significantly impacting the success rate of deciphering and restricting their effectiveness to small datasets with clear evolutionary paths.Report issue for preceding element\nIn this study, we focus on the task of OBS decipherment, aiming to predict the corresponding modern Chinese character forms for the oracle bone language. This endeavor not only seeks to match known characters but also to uncover new forms that could elucidate the meanings of these ancient scripts. Formally, the training set denoted as S={(si,ci)\u2223si\u2062 is an OBS instance and \u2062ci\u2208C}\ud835\udc46conditional-setsubscript\ud835\udc60\ud835\udc56subscript\ud835\udc50\ud835\udc56subscript\ud835\udc60\ud835\udc56 is an OBS instance and subscript\ud835\udc50\ud835\udc56\ud835\udc36S=\\{(s_{i},c_{i})\\mid s_{i}\\text{ is an OBS instance and }c_{i}\\in C\\}italic_S = { ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \u2223 italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is an OBS instance and italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u2208 italic_C }, pairs OBS instances with their modern Chinese counterparts from a set of known Categories C\ud835\udc36Citalic_C. The model is designed to extend beyond the training set S\ud835\udc46Sitalic_S, identifying modern equivalents for OBS instances s\u2032superscript\ud835\udc60\u2032s^{\\prime}italic_s start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT, and proposing new character forms where existing matches are absent.Report issue for preceding element\nTo achieve this, our approach utilizes a diffusion-based [CITATION] model, for transforming OBS character images X~~\ud835\udc4b\\tilde{X}over~ start_ARG italic_X end_ARG into their modern Chinese equivalents, as illustrated in Figure 1. The model operates in two phases: the forward process, the forward phase introduces noise to the modern Chinese character images X0subscript\ud835\udc4b0X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, transitioning them towards a state resembling pure noise via a controlled Markov chain process, ultimately conforming to a Gaussian distribution \ud835\udca9\u2062(0,I)\ud835\udca90\ud835\udc3c\\mathcal{N}(0,I)caligraphic_N ( 0 , italic_I ). This is mathematically articulated as follows:Report issue for preceding element q\u2062(X1:T\u2223X0)=\u220ft=1Tq\u2062(Xt\u2223Xt\u22121)\ud835\udc5econditionalsubscript\ud835\udc4b:1\ud835\udc47subscript\ud835\udc4b0superscriptsubscriptproduct\ud835\udc611\ud835\udc47\ud835\udc5econditionalsubscript\ud835\udc4b\ud835\udc61subscript\ud835\udc4b\ud835\udc611q\\left(X_{1:T}\\mid X_{0}\\right)=\\prod_{t=1}^{T}q\\left(X_{t}\\mid X_{t-1}\\right)italic_q ( italic_X start_POSTSUBSCRIPT 1 : italic_T end_POSTSUBSCRIPT \u2223 italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = \u220f start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_q ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2223 italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) (1)\nwhere T\ud835\udc47Titalic_T denotes the total number of steps. For each step t\ud835\udc61titalic_t, noise is added according to the following equation:Report issue for preceding element q\u2062(Xt\u2223Xt\u22121)=\ud835\udca9\u2062(Xt\u2223\u03b1t\u2062Xt\u22121,(1\u2212\u03b1t)\u2062I)\ud835\udc5econditionalsubscript\ud835\udc4b\ud835\udc61subscript\ud835\udc4b\ud835\udc611\ud835\udca9conditionalsubscript\ud835\udc4b\ud835\udc61subscript\ud835\udefc\ud835\udc61subscript\ud835\udc4b\ud835\udc6111subscript\ud835\udefc\ud835\udc61\ud835\udc3cq\\left(X_{t}\\mid X_{t-1}\\right)=\\mathcal{N}\\left(X_{t}\\mid\\sqrt{\\alpha_{t}}X_{% t-1},\\left(1-\\alpha_{t}\\right)I\\right)italic_q ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2223 italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) = caligraphic_N ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2223 square-root start_ARG italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , ( 1 - italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) italic_I )Report issue for preceding element (2)\nwhere \u03b1tsubscript\ud835\udefc\ud835\udc61\\alpha_{t}italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is a hyperparameter controlling the noise intensity, and I\ud835\udc3cIitalic_I represents the identity matrix. The transition from X0subscript\ud835\udc4b0X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to a noisy state Xtsubscript\ud835\udc4b\ud835\udc61X_{t}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT over t\ud835\udc61titalic_t step is captured by the equation:Report issue for preceding element Xt=\u03b3t\u2062X0+1\u2212\u03b3t\u2062\u03f5,\u03f5\u223c\ud835\udca9\u2062(0,I)formulae-sequencesubscript\ud835\udc4b\ud835\udc61subscript\ud835\udefe\ud835\udc61subscript\ud835\udc4b01subscript\ud835\udefe\ud835\udc61italic-\u03f5similar-toitalic-\u03f5\ud835\udca90\ud835\udc3cX_{t}=\\sqrt{\\gamma_{t}}X_{0}+\\sqrt{1-\\gamma_{t}}\\epsilon,\\quad\\epsilon\\sim% \\mathcal{N}(0,I)italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = square-root start_ARG italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + square-root start_ARG 1 - italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_\u03f5 , italic_\u03f5 \u223c caligraphic_N ( 0 , italic_I ) (3)\nwith \u03b3tsubscript\ud835\udefe\ud835\udc61\\gamma_{t}italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT being the cumulative product of \u03b1\ud835\udefc\\alphaitalic_\u03b1 values up to t\ud835\udc61titalic_t.Report issue for preceding element\nThe denoising phase employs a U-Net architecture [CITATION] for the model f\u03b8subscript\ud835\udc53\ud835\udf03f_{\\theta}italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT, trained to predict the noise \u03f5italic-\u03f5\\epsilonitalic_\u03f5 and restore the image. The training objective minimizes the loss function:Report issue for preceding element \u2112=\ud835\udd3c\u03f5,\u03b3\u2062\u2016\u03f5\u2212f\u03b8\u2062(X~,Xt,\u03b3)\u20162\u2112subscript\ud835\udd3citalic-\u03f5\ud835\udefesuperscriptnormitalic-\u03f5subscript\ud835\udc53\ud835\udf03~\ud835\udc4bsubscript\ud835\udc4b\ud835\udc61\ud835\udefe2\\mathcal{L}=\\mathbb{E}_{\\epsilon,\\gamma}\\left\\|\\epsilon-f_{\\theta}\\left(\\tilde% {X},X_{t},\\gamma\\right)\\right\\|^{2}caligraphic_L = blackboard_E start_POSTSUBSCRIPT italic_\u03f5 , italic_\u03b3 end_POSTSUBSCRIPT \u2225 italic_\u03f5 - italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( over~ start_ARG italic_X end_ARG , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\u03b3 ) \u2225 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT (4)\nwhich measures the discrepancy between the actual noise \u03f5italic-\u03f5\\epsilonitalic_\u03f5 and its estimation by the f\u03b8subscript\ud835\udc53\ud835\udf03f_{\\theta}italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT. In the inference stage p\u03b8\u2062(Xt\u2223Xt,X~)subscript\ud835\udc5d\ud835\udf03conditionalsubscript\ud835\udc4b\ud835\udc61subscript\ud835\udc4b\ud835\udc61~\ud835\udc4bp_{\\theta}(X_{t}\\mid X_{t},\\tilde{X})italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u2223 italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over~ start_ARG italic_X end_ARG ), we reverse the noise addition process, starting from the noisiest state XTsubscript\ud835\udc4b\ud835\udc47X_{T}italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT and iteratively denoising down to t=1\ud835\udc611t=1italic_t = 1.Report issue for preceding element Xt\u22121=1\u03b1t\u2062(Xt\u22121\u2212\u03b1t1\u2212\u03b3t\u2062f\u03b8\u2062(X~,Xt,\u03b3t))+1\u2212\u03b1t\u2062\u03f5tsubscript\ud835\udc4b\ud835\udc6111subscript\ud835\udefc\ud835\udc61subscript\ud835\udc4b\ud835\udc611subscript\ud835\udefc\ud835\udc611subscript\ud835\udefe\ud835\udc61subscript\ud835\udc53\ud835\udf03~\ud835\udc4bsubscript\ud835\udc4b\ud835\udc61subscript\ud835\udefe\ud835\udc611subscript\ud835\udefc\ud835\udc61subscriptitalic-\u03f5\ud835\udc61X_{t-1}=\\frac{1}{\\sqrt{\\alpha_{t}}}\\left(X_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{1-% \\gamma_{t}}}f_{\\theta}\\left(\\tilde{X},X_{t},\\gamma_{t}\\right)\\right)+\\sqrt{1-% \\alpha_{t}}\\epsilon_{t}italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 - italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG 1 - italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( over~ start_ARG italic_X end_ARG , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\u03b3 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) + square-root start_ARG 1 - italic_\u03b1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPTReport issue for preceding element (5)\nwhere \u03f5t\u223c\ud835\udca9\u2062(0,I)similar-tosubscriptitalic-\u03f5\ud835\udc61\ud835\udca90\ud835\udc3c\\epsilon_{t}\\sim\\mathcal{N}(0,I)italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u223c caligraphic_N ( 0 , italic_I ) introduces randomness to enhance the diversity of model generated results. The outcome is the denoised image X^0subscript^\ud835\udc4b0\\hat{X}_{0}over^ start_ARG italic_X end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, representing the deciphered results.Report issue for preceding element\nBuilding on this, our OBSD model integrates an Initial Decipherment phase with a Zero-shot Refinement stage to improve the decipherment accuracy. As shown in Figure 2, initially, an OBS image X~~\ud835\udc4b\\tilde{X}over~ start_ARG italic_X end_ARG undergoes conditional diffusion to approximate an initial decipherment X0subscript\ud835\udc4b0X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, which is then refined using a zero-shot learning approach, leveraging a reference style image Xr\u2062e\u2062fsubscript\ud835\udc4b\ud835\udc5f\ud835\udc52\ud835\udc53X_{ref}italic_X start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT to correct and enhance the structure. with a distinct style to enhance X0subscript\ud835\udc4b0X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, learning from the structure of modern Chinese characters. The final result XFsubscript\ud835\udc4b\ud835\udc39X_{F}italic_X start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT emerges as a refined representation of the intended modern Chinese character, benefiting from the refinement process\u2019s structural insights.Report issue for preceding element\nAfter revisiting the fundamentals in Section 3.1, a preliminary and somewhat naive idea was to directly utilize OBS images as the condition X~~\ud835\udc4b\\tilde{X}over~ start_ARG italic_X end_ARG and modern Chinese characters as the target images X0subscript\ud835\udc4b0X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to train a conditional diffusion model for decipherment. However, as shown in Figure 3, we observed that directly training such a model did not result in the accurate generation of the corresponding photos of modern Chinese characters. Instead, the model produces images comprised of a multitude of random stroke fragments, resembling gibberish. We speculate that this discrepancy arises because diffusion models are primarily designed for generating natural images, where the input conditions, such as edges and sketches, provide structural information to guide the generation of target images. However, in the context of deciphering OBS, the structural disparity between the input OBS images and the expected modern Chinese character outcomes is significant (see Figure 4(a)), rendering the standard conditional diffusion model ineffective for accurate reconstruction of the target modern characters. To address this challenge, we introduce the concept of Localized Structural Sampling (LSS) as a means to aid the diffusion model in learning how to map local radical structures of OBS to the corresponding modern Chinese character space (see Figure 4(b) red marks), thereby enhancing the model\u2019s capability to bridge the structural gap between ancient inscriptions and contemporary linguistic forms.Report issue for preceding element\nFigure 4 has demonstrated that despite the considerable structural evolution from OBS to modern Chinese characters, certain local structures have been preserved. As shown in Figure 5, to enable the diffusion model to learn these localized radical features, the LSS module employs a sliding window approach to segment the target modern Chinese character images X0\u2208RH\u00d7W\u00d73subscript\ud835\udc4b0superscript\ud835\udc45\ud835\udc3b\ud835\udc4a3X_{0}\\in R^{H\\times W\\times 3}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u2208 italic_R start_POSTSUPERSCRIPT italic_H \u00d7 italic_W \u00d7 3 end_POSTSUPERSCRIPT and corresponding OBS images X~\u2208RH\u00d7W\u00d73~\ud835\udc4bsuperscript\ud835\udc45\ud835\udc3b\ud835\udc4a3\\tilde{X}\\in R^{H\\times W\\times 3}over~ start_ARG italic_X end_ARG \u2208 italic_R start_POSTSUPERSCRIPT italic_H \u00d7 italic_W \u00d7 3 end_POSTSUPERSCRIPT into D\ud835\udc37Ditalic_D patches of size p~\u00d7p~~\ud835\udc5d~\ud835\udc5d\\tilde{p}\\times\\tilde{p}over~ start_ARG italic_p end_ARG \u00d7 over~ start_ARG italic_p end_ARG, denoted as X~(d)superscript~\ud835\udc4b\ud835\udc51\\tilde{X}^{(d)}over~ start_ARG italic_X end_ARG start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT and Xt(d)\u2208Rp~\u00d7p~\u00d73,d=1,2,\u2026\u2062D,p~=64formulae-sequencesuperscriptsubscript\ud835\udc4b\ud835\udc61\ud835\udc51superscript\ud835\udc45~\ud835\udc5d~\ud835\udc5d3formulae-sequence\ud835\udc5112\u2026\ud835\udc37~\ud835\udc5d64X_{t}^{(d)}\\in R^{\\tilde{p}\\times\\tilde{p}\\times 3},d=1,2,...D,\\tilde{p}=64italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT \u2208 italic_R start_POSTSUPERSCRIPT over~ start_ARG italic_p end_ARG \u00d7 over~ start_ARG italic_p end_ARG \u00d7 3 end_POSTSUPERSCRIPT , italic_d = 1 , 2 , \u2026 italic_D , over~ start_ARG italic_p end_ARG = 64. Here, Xtsubscript\ud835\udc4b\ud835\udc61X_{t}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT represents the modern text image with added Gaussian noise \u03f5tsubscriptitalic-\u03f5\ud835\udc61\\epsilon_{t}italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT at timestep t\ud835\udc61titalic_t. Consequently, we focus on learning the conditional reverse process as follows:Report issue for preceding element p\u03b8\u2062(X0:T(i)\u2223X~(i))=p\u2062(XT(i))\u2062\u220ft=1Tp\u03b8\u2062(Xt\u22121(i)\u2223Xt(i),X~(i))subscript\ud835\udc5d\ud835\udf03conditionalsuperscriptsubscript\ud835\udc4b:0\ud835\udc47\ud835\udc56superscript~\ud835\udc4b\ud835\udc56\ud835\udc5dsuperscriptsubscript\ud835\udc4b\ud835\udc47\ud835\udc56superscriptsubscriptproduct\ud835\udc611\ud835\udc47subscript\ud835\udc5d\ud835\udf03conditionalsuperscriptsubscript\ud835\udc4b\ud835\udc611\ud835\udc56superscriptsubscript\ud835\udc4b\ud835\udc61\ud835\udc56superscript~\ud835\udc4b\ud835\udc56p_{\\theta}(X_{0:T}^{(i)}\\mid\\tilde{X}^{(i)})=p(X_{T}^{(i)})\\prod_{t=1}^{T}p_{% \\theta}(X_{t-1}^{(i)}\\mid X_{t}^{(i)},\\tilde{X}^{(i)})italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT 0 : italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT \u2223 over~ start_ARG italic_X end_ARG start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ) = italic_p ( italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT ) \u220f start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT \u2223 italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , over~ start_ARG italic_X end_ARG start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT )Report issue for preceding element (6)\nBy adopting this approach, the model iteratively refines each patch by learning the nuanced mappings from the localized structures of OBS to their modern counterparts. The loss function in Equation 4 can then be rewritten as follows:Report issue for preceding element \u03f5^t(d)=f\u03b8\u2062(Xt(d),X~(d),t)\u2112\u2032=\ud835\udd3ct,d\u2062\u2016\u03f5^t(d)\u2212\u03f5t(d)\u20162superscriptsubscript^italic-\u03f5\ud835\udc61\ud835\udc51subscript\ud835\udc53\ud835\udf03superscriptsubscript\ud835\udc4b\ud835\udc61\ud835\udc51superscript~\ud835\udc4b\ud835\udc51\ud835\udc61superscript\u2112\u2032subscript\ud835\udd3c\ud835\udc61\ud835\udc51superscriptnormsuperscriptsubscript^italic-\u03f5\ud835\udc61\ud835\udc51superscriptsubscriptitalic-\u03f5\ud835\udc61\ud835\udc512\\begin{array}[]{c}\\hat{\\epsilon}_{t}^{(d)}=f_{\\theta}(X_{t}^{(d)},\\tilde{X}^{(% d)},t)\\\\ \\mathcal{L^{\\prime}}=\\mathbb{E}_{t,d}\\parallel\\hat{\\epsilon}_{t}^{(d)}-% \\epsilon_{t}^{(d)}\\parallel^{2}\\end{array}start_ARRAY start_ROW start_CELL over^ start_ARG italic_\u03f5 end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT = italic_f start_POSTSUBSCRIPT italic_\u03b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT , over~ start_ARG italic_X end_ARG start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT , italic_t ) end_CELL end_ROW start_ROW start_CELL caligraphic_L start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT = blackboard_E start_POSTSUBSCRIPT italic_t , italic_d end_POSTSUBSCRIPT \u2225 over^ start_ARG italic_\u03f5 end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT - italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT \u2225 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_CELL end_ROW end_ARRAY (7)\nHere, the model\u2019s goal is to minimize the difference between the estimated noise \u03f5^t(d)superscriptsubscript^italic-\u03f5\ud835\udc61\ud835\udc51\\hat{\\epsilon}_{t}^{(d)}over^ start_ARG italic_\u03f5 end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT, and the actual noise, \u03f5t(d)superscriptsubscriptitalic-\u03f5\ud835\udc61\ud835\udc51\\epsilon_{t}^{(d)}italic_\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT, within each patch.Report issue for preceding element\nIn the inference phase, our approach involves dissecting the OBS image X~~\ud835\udc4b\\tilde{X}over~ start_ARG italic_X end_ARG into p~\u00d7p~~\ud835\udc5d~\ud835\udc5d\\tilde{p}\\times\\tilde{p}over~ start_ARG italic_p end_ARG \u00d7 over~ start_ARG italic_p end_ARG patches, with p\ud835\udc5dpitalic_p set at 64, through a structured grid layout, utilizing a sliding window for systematic extraction. The grid is arranged such that each cell hosts r\u00d7r\ud835\udc5f\ud835\udc5fr\\times ritalic_r \u00d7 italic_r patches, with r\ud835\udc5fritalic_r set at 16, allowing for a finer subdivision than the patch size p~~\ud835\udc5d\\tilde{p}over~ start_ARG italic_p end_ARG. Patches are extracted by navigating the grid in both horizontal and vertical directions with a step size of r\ud835\udc5fritalic_r. The initial decipherment model then progressively refines each patch by denoising and sampling.Report issue for preceding element\nUnique to our method is the handling of overlaps between patches. Instead of waiting until the denoising is complete, we average the overlapped sections at every timestep t\ud835\udc61titalic_t, ensuring a uniform effect across the shared areas. This continuous averaging at each timestep prevents the formation of merging artifacts that typically occur when patches are processed independently. By smoothing transitions between patches during the sampling, we avoid edge discrepancies, maintaining the visual coherence of the reconstructed image. The sampling dynamics at each step are defined by Equation 5, which guides the process toward a seamless and artifact-free image assembly. Algorithm 1 shows the pseudocode of LSS. Figure 5 demonstrates the overview pipeline of initial decipherment.Report issue for preceding element\nDespite advancements in generating modern Chinese characters with Localized Structural Sampling, initial decipherment efforts encounter notable obstacles, such as structural deformities and artifacts, highlighted in Figure 6. These issues stem from the many-to-one training approach used, where multiple OBS instances are mapped to a single modern Chinese character image (see Figure 8), leading to confusion and inaccuracies in capturing character evolution, and resulting in artifacts or incomplete structures due to a limited variety of modern Chinese character samples.Report issue for preceding element\nTo overcome these challenges, we propose a zero-shot refinement strategy that involves training a model on a diverse collection of modern Chinese characters. Considering the multiple writing styles for modern Chinese characters, we aim to improve the model\u2019s understanding of their structure by employing a transformation task between different styles. We trained the module on 20 different modern Chinese character fonts to learn structural transformations between different modern Chinese character writing styles. As shown in Figure 8, this training process is one-to-one. This method simplifies data collection by leveraging readily available font variations, thereby enhancing the model\u2019s understanding of character structures and enabling the application of this knowledge to improve initial decipherment results without direct training on OBS-to-modern character mappings.Report issue for preceding element\nOur zero-shot refinement approach is grounded in a generic font style transformation framework, as depicted in Figure 7 and based on [CITATION]. The process involves a dual-encoder system to adapt the style of a source font image X0subscript\ud835\udc4b0X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT to a target style Xr\u2062e\u2062fsubscript\ud835\udc4b\ud835\udc5f\ud835\udc52\ud835\udc53X_{ref}italic_X start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT, preserving content integrity. The style encoder Essubscript\ud835\udc38\ud835\udc60E_{s}italic_E start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT extracts style features essubscript\ud835\udc52\ud835\udc60e_{s}italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT from Xr\u2062e\u2062fsubscript\ud835\udc4b\ud835\udc5f\ud835\udc52\ud835\udc53X_{ref}italic_X start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT, while the content encoder Ecsubscript\ud835\udc38\ud835\udc50E_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT processes Xosubscript\ud835\udc4b\ud835\udc5cX_{o}italic_X start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT and Xr\u2062e\u2062fsubscript\ud835\udc4b\ud835\udc5f\ud835\udc52\ud835\udc53X_{ref}italic_X start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT to obtain multi-scale content features F0={fo1,fo2,fo3}subscript\ud835\udc390superscriptsubscript\ud835\udc53\ud835\udc5c1superscriptsubscript\ud835\udc53\ud835\udc5c2superscriptsubscript\ud835\udc53\ud835\udc5c3F_{0}=\\{f_{o}^{1},f_{o}^{2},f_{o}^{3}\\}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = { italic_f start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_f start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_f start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT } and Fr\u2062e\u2062f={fr\u2062e\u2062f1,fr\u2062e\u2062f2,fr\u2062e\u2062f3}subscript\ud835\udc39\ud835\udc5f\ud835\udc52\ud835\udc53superscriptsubscript\ud835\udc53\ud835\udc5f\ud835\udc52\ud835\udc531superscriptsubscript\ud835\udc53\ud835\udc5f\ud835\udc52\ud835\udc532superscriptsubscript\ud835\udc53\ud835\udc5f\ud835\udc52\ud835\udc533F_{ref}=\\{f_{ref}^{1},f_{ref}^{2},f_{ref}^{3}\\}italic_F start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT = { italic_f start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_f start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_f start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT }, refined by a specialized UNet with Multi-scale Content Aggregation (MCA) and Reference-Structure Interaction (RSI) blocks for enhanced feature integration. The model employs cross-attention mechanisms to align features and address structural differences, formalized as:Report issue for preceding element Sr\u2062e\u2062f\u2208\u211dCr\u2062e\u2062fi\u00d7Hi\u2062Wi=flatten\u2062(fr\u2062e\u2062fi)Ss\u2208\u211dCsi\u00d7Hi\u2062Wi=flatten\u2062(oi)Q=\u03a6q\u2062(Sr\u2062e\u2062f),K=\u03a6k\u2062(Ss),V=\u03a6v\u2062(Ss)subscript\ud835\udc46\ud835\udc5f\ud835\udc52\ud835\udc53superscript\u211dsuperscriptsubscript\ud835\udc36\ud835\udc5f\ud835\udc52\ud835\udc53\ud835\udc56subscript\ud835\udc3b\ud835\udc56subscript\ud835\udc4a\ud835\udc56flattensuperscriptsubscript\ud835\udc53\ud835\udc5f\ud835\udc52\ud835\udc53\ud835\udc56subscript\ud835\udc46\ud835\udc60superscript\u211dsuperscriptsubscript\ud835\udc36\ud835\udc60\ud835\udc56subscript\ud835\udc3b\ud835\udc56subscript\ud835\udc4a\ud835\udc56flattensubscript\ud835\udc5c\ud835\udc56formulae-sequence\ud835\udc44subscript\u03a6\ud835\udc5esubscript\ud835\udc46\ud835\udc5f\ud835\udc52\ud835\udc53formulae-sequence\ud835\udc3esubscript\u03a6\ud835\udc58subscript\ud835\udc46\ud835\udc60\ud835\udc49subscript\u03a6\ud835\udc63subscript\ud835\udc46\ud835\udc60\\begin{array}[]{c}S_{ref}\\in\\mathbb{R}^{C_{ref}^{i}\\times H_{i}W_{i}}=\\text{% flatten}(f_{ref}^{i})\\\\ S_{s}\\in\\mathbb{R}^{C_{s}^{i}\\times H_{i}W_{i}}=\\text{flatten}(o_{i})\\\\ Q=\\Phi_{q}(S_{ref}),~{}K=\\Phi_{k}(S_{s}),~{}V=\\Phi_{v}(S_{s})\\end{array}start_ARRAY start_ROW start_CELL italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \u00d7 italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = flatten ( italic_f start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) end_CELL end_ROW start_ROW start_CELL italic_S start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT \u2208 blackboard_R start_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \u00d7 italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = flatten ( italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_CELL end_ROW start_ROW start_CELL italic_Q = roman_\u03a6 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT ) , italic_K = roman_\u03a6 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) , italic_V = roman_\u03a6 start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) end_CELL end_ROW end_ARRAY (8)\nwhere oisubscript\ud835\udc5c\ud835\udc56o_{i}italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents the UNet feature derived from foisuperscriptsubscript\ud835\udc53\ud835\udc5c\ud835\udc56f_{o}^{i}italic_f start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT and essubscript\ud835\udc52\ud835\udc60e_{s}italic_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, and \u03a6qsubscript\u03a6\ud835\udc5e\\Phi_{q}roman_\u03a6 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT, \u03a6ksubscript\u03a6\ud835\udc58\\Phi_{k}roman_\u03a6 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, \u03a6vsubscript\u03a6\ud835\udc63\\Phi_{v}roman_\u03a6 start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT denote linear projections. The deformation offset \u03b4offsetsubscript\ud835\udeffoffset\\delta_{\\text{offset}}italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT is calculated as follows:Report issue for preceding element Fattn=softmax\u2062(Q\u2062KTdk)\u2062V\u03b4offset=FFN\u2062(Fattn)subscript\ud835\udc39attnsoftmax\ud835\udc44superscript\ud835\udc3e\ud835\udc47subscript\ud835\udc51\ud835\udc58\ud835\udc49subscript\ud835\udeffoffsetFFNsubscript\ud835\udc39attn\\begin{array}[]{c}F_{\\text{attn}}=\\text{softmax}(\\frac{QK^{T}}{\\sqrt{d_{k}}})V% \\\\ \\delta_{\\text{offset}}=\\text{FFN}(F_{\\text{attn}})\\end{array}start_ARRAY start_ROW start_CELL italic_F start_POSTSUBSCRIPT attn end_POSTSUBSCRIPT = softmax ( divide start_ARG italic_Q italic_K start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT end_ARG start_ARG square-root start_ARG italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG end_ARG ) italic_V end_CELL end_ROW start_ROW start_CELL italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT = FFN ( italic_F start_POSTSUBSCRIPT attn end_POSTSUBSCRIPT ) end_CELL end_ROW end_ARRAY (9)\nThe output Ifsubscript\ud835\udc3c\ud835\udc53I_{f}italic_I start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT is the result of rendering the source image with DCN [CITATION], considering the calculated deformation offset:Report issue for preceding element If=DCN\u2062(oi,\u03b4offset)subscript\ud835\udc3c\ud835\udc53DCNsubscript\ud835\udc5c\ud835\udc56subscript\ud835\udeffoffsetI_{f}=\\text{DCN}(o_{i},\\delta_{\\text{offset}})italic_I start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = DCN ( italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT ) (10)\nIn adapting the framework for OBS decipherment, we streamline the model by focusing on a singular font style, thereby omitting the style contrastive refinement module and its contrastive loss, simplifying the training process. The encoders are trained using the offset loss \u2112offsetsubscript\u2112offset\\mathcal{L}_{\\text{offset}}caligraphic_L start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT, which measures the mean magnitude of deformation offsets:Report issue for preceding element \u2112offset=m\u2062e\u2062a\u2062n\u2062(\u2016\u03b4offset\u2016)subscript\u2112offset\ud835\udc5a\ud835\udc52\ud835\udc4e\ud835\udc5bnormsubscript\ud835\udeffoffset\\mathbf{\\mathcal{L}}_{\\text{offset}}=mean(\\left\\|\\delta_{\\text{offset}}\\right\\|)caligraphic_L start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT = italic_m italic_e italic_a italic_n ( \u2225 italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT \u2225 ) (11)\nwhere \u03b4offsetsubscript\ud835\udeffoffset\\delta_{\\text{offset}}italic_\u03b4 start_POSTSUBSCRIPT offset end_POSTSUBSCRIPT signifies the deformation offset, encapsulating structural information gleaned from the reference features, and the mean operation computes the average magnitude of these offsets.Report issue for preceding element\nAfter training, the zero-shot refinement module was directly employed to refine the results generated by the diffusion model.Report issue for preceding element\nTo train and evaluate the proposed OBSD model, we selected the HUST-OBS dataset [CITATION] and EVOBC dataset [CITATION], which stands as one of the largest repositories of OBS, with 1,590 distinct characters depicted in 71,698 images. Recognizing the complexities involved in deciphering unknown OBS, which usually require comprehensive expert validation, we opted for already deciphered inscriptions in our testing set to streamline the evaluation process. Importantly, the categories of characters in the testing set were specifically chosen to be absent from the training set, ensuring that the model faces the genuine challenge of deciphering unseen and novel categories. The dataset was partitioned into training and test sets with a 9:1 ratio, providing a robust framework for assessment.Report issue for preceding element\nWhile the proposed OBSD model approaches OBS decipherment from an image generation perspective, it is crucial to acknowledge that traditional image generation metrics, such as SSIM [CITATION], are not suitable for this distinct challenge. Instead, we adopted OCR technology as a more objective measure of decipherment success. Our custom-built OCR tool, OBS-OCR, is a simple classifier using ResNet-101 backbone specifically trained on a large dataset of 88,899 categories modern Chinese characters to evaluate the model\u2019s output. The custom-built OCR tool achieved a recognition accuracy of 99.87% on 88,899 categories of Chinese characters, which demonstrates reliable performance to evaluate the decipherment results. Its aim is to automatically recognize the results generated by the diffusion models and compare these results with the ground truth in order to evaluate the model\u2019s deciphering performance. By comparing the OCR-recognized characters against their ground truth labels, we simulate a quantifiable form of expert validation. To make a more reliable and objective evaluation, we also incorporated the widely-used, open-source Chinese OCR tool PaddleOCR 111https://github.com/PaddlePaddle/PaddleOCR as an additional OCR tool to support further evaluations. This dual-OCR method provides a robust framework for assessing the model\u2019s efficacy in accurately deciphering oracle bone languages.Report issue for preceding element\nIn quantitatively evaluating the performance of our proposed OBSD, we employ two distinct assessment criteria: single-round decipherment and multi-round decipherment. The single-round decipherment evaluation aims to gauge the method\u2019s capability to decipher individual samples accurately, providing insight into its immediate effectiveness. On the other hand, the multi-round decipherment assessment offers a more practical appraisal of the method\u2019s performance, where multiple attempts at deciphering a single image are permitted. This approach mirrors the iterative nature of real-world decipherment tasks, allowing for a comprehensive assessment of the method\u2019s resilience and adaptability over successive trials.Report issue for preceding element\nGiven the absence of dedicated tools for oracle bone language decipherment, we employ a comparative framework that adapts leading image-to-image translation methods to this specialized task. This set includes GAN-based approaches such as Pix2Pix [CITATION], CycleGAN [CITATION], DRIT++ [CITATION], and diffusion-based methods like CDE [CITATION], Palette [CITATION], BBDM [CITATION]. This setting not only mirrors the core mechanism of our OBSD method but also allows for a comprehensive evaluation against the backdrop of the latest advancements in image translation. Each method was carefully adapted to the OBS context, ensuring consistent training and testing conditions for a fair evaluation.Report issue for preceding element\nIn the single-round decipherment evaluation, as shown in Table 1, our OBSD demonstrates a significant advantage over the adapted image-to-image translation methods in deciphering oracle bone language. Notably, the top-1 accuracy for OBS-OCR and PaddleOCR achieved by OBSD stand at 41.0% and 30.0%, respectively, surpassing the performance of other methods. As the rank increases, there is a clear trend of improving accuracy, at Top-500 accuracy, OBSD reaches a 64.5% OBS-OCR recognition accuracy. It is noteworthy that all GAN-based approaches, such as Pix2Pix, Palette, DRIT++, and CycleGAN, exhibit minimal effectiveness in this context, with top-1 accuracies at 0%. This could be attributed to the GANs\u2019 inherent challenge in capturing the complex and nuanced mappings required for accurately deciphering the oracle bone language into modern Chinese. Surprisingly, the adapted diffusion models, despite their general-purpose nature, have shown commendable performance, underscoring the viability of leveraging image generation techniques in addressing the challenges traditional NLP algorithms encounter in decipherment tasks. This aligns with our methodological premise, validating the novel approach of integrating image-based generative models into the domain of linguistic decipherment.Report issue for preceding element\nIn addition, Table 2 presents the multi-round decipherment results, where a progressive increase in decipherment success rates can be witnessed across multiple trials. The OBS-OCR metric starts at a success rate of 41.0%, and levels out at 80.0% by the 10th trial, showcasing the cumulative benefit of iterative testing. Similarly, the PaddleOCR metric exhibits a consistent upward trend, commencing at 30.0% and culminating at 58.5% in the final trial. These results validate the incremental improvements achievable through successive attempts.Report issue for preceding element\nTo further examine the impact of individual components in our proposed method, we conducted an ablation study focusing on the LSS module and zero-shot refinement. The results, presented in Table 3, highlight the limitations of employing only the basic conditional diffusion model for OBS decipherment, which resulted in notably low accuracy rates. Specifically, training the diffusion model without any enhancements led to outputs that were essentially nonsensical, characterized by random and uninterpretable stroke combinations (see Figure 3). The introduction of the LSS module marked a significant improvement, enabling the generation of decipherment outcomes with a Top-1 recognition rate of 37.5% for OBS-OCR and 24% for PaddleOCR. The addition of the zero-shot refinement module, in conjunction with the LSS, further increased the Top-1 accuracy for both OBS-OCR and PaddleOCR by an additional 3.5% and 6%, respectively.Report issue for preceding element\nFigure 9 showcases the qualitative results of various image-to-image translation models, with our method, OBSD, standing out by producing the most accurate reconstructions of modern Chinese characters from OBS inputs. Pix2Pix [CITATION], for example, generates outputs that are highly uniform across different inputs, demonstrating a lack of differentiation in character decipherment. On the other hand, DRIT++ [CITATION] struggles to produce complete characters, often resulting in fragmented and unrecognizable forms. In stark contrast, OBSD demonstrates a robust capability to discern and reconstruct the intricate details of each OBS, leading to coherent and precise character forms that closely align with the ground truth. These results not only highlight the efficacy of OBSD but also its potential as a tool for experts in the field of oracle bone language decipherment.Report issue for preceding element\nTo demonstrate the performance of OBSD on authentic, undeciphered OBS, we present an extensive evaluation in the appendix, depicted in Figure 10, 11, 12 and 13. This evaluation showcases a range of decipherment outcomes, from partial reconstructions that shed light on the structural elements of OBS characters, such as radicals and strokes, to complete character forms that exhibit a high resemblance to modern Chinese script. While the bulk of these results provide structural clues, the fully reconstructed characters hold particular promise, indicating the potential of OBSD to contribute meaningfully to the field of oracle bone language decipherment.Report issue for preceding element\nExperiment Results: We compared the proposed OBSD with other generic image generation models for the OBS deciphering task. As shown in Figure 9, most generic image generation models fail to produce structurally complete Chinese characters. This is because these methods, based on conditional generation, attempt to directly map the input OBS image to modern characters, neglecting the structural and writing conventions of the characters. In contrast, the proposed OBSD addresses these issues by incorporating local radical structure information into the training process, resulting in more accurate outputs.Report issue for preceding element\nAnalysis of Proposed Modules: According to the experimental results, we found that the proposed LSS module effectively directs the diffusion model\u2019s focus towards the local structures of both OBS and modern Chinese characters. This results in clearer character strokes and more reasonable character structures. Additionally, the Zero-shot Refinement module refines the initial decipherment results by learning the structural characteristics of modern Chinese characters, ensuring a more precise and coherent structure.Report issue for preceding element\nGeneralizability to Other Languages: The proposed method was initially designed for ideographic or pictographic languages, such as Chinese characters or Mayan script, where a single character represents a word or morpheme. This design enables the adaptation of the method to similar languages. For alphabetic scripts, which typically have a small number of letters, decipherment is rarely an issue. The applicability of these methods to other languages presents an interesting research question, which we will explore in our future work.Report issue for preceding element\nIn this work, we presented OBSD, an innovative approach leveraging conditional image generation for the decipherment of OBS. Our novel Local Structure Sampling technique addresses the inherent challenges in learning modern Chinese characters\u2019 structures from limited samples, enabling effective structural correspondence learning between OBS and modern Chinese characters. Furthermore, the integration of a zero-shot refinement module significantly enhances the decipherment accuracy, a claim substantiated by promising results on the HUST-OBS dataset and EVOBC dataset. The potential of OBSD extends beyond OBS, offering prospects for deciphering other ancient scripts, such as hieroglyphs and Maya glyphs. Looking ahead, we aim to collaborate with epigraphy experts to further validate and refine the OBSD, aspiring to advance AI\u2019s role in the decipherment of ancient languages.Report issue for preceding element\nIn this study, we employed OCR technology, including a custom-built tool and the off-the-shelf package PaddleOCR, to evaluate the success of our OBSD in deciphering oracle bone language. While this approach offers a novel and objective metric, it is important to recognize its inherent limitations. However, these methods cannot be directly applied to evaluate truly undeciphered OBS, where the absence of ground truth necessitates expert validation.Report issue for preceding element\nEvaluating the decipherment results of entirely unknown OBS characters presents a unique challenge that goes beyond the capabilities of OCR technology. This task involves interpreting historical, cultural, and linguistic contexts that are deeply embedded within the languages. Therefore, the ultimate validation of our model\u2019s decipherment for such inscriptions requires the involvement of scholars and experts in oracle bone studies. We acknowledge the importance of this expert validation and are exploring collaborations with specialists in the field to assess the relevance and accuracy of our model\u2019s outputs for genuinely undeciphered texts.Report issue for preceding element\nThis work was supported by the National Natural Science Foundation of China (No. 61936003, No.62225603, No.62206103, No.62441604).Report issue for preceding element",
  "citations": [
    {
      "tag": "Meng et\u00a0al. (2018)",
      "title": "Recognition of oracle bone inscriptions using deep learning based on\ndata augmentation.",
      "authors": "Lin Meng, Naoki Kamitoku, and Katsuhiro Yamazaki. 2018.",
      "journal": "InMetrology for Archaeology and Cultural Heritage, pages\n33\u201338. IEEE."
    },
    {
      "tag": "Isola et\u00a0al. (2017)",
      "title": "Image-to-image translation with conditional adversarial networks.",
      "authors": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei\u00a0A Efros. 2017.",
      "journal": "InProc. IEEE Conf. Comp. Vis. Patt. Recogn., pages\n1125\u20131134."
    },
    {
      "tag": "Wang et\u00a0al. (2022)",
      "title": "Unsupervised structure-texture separation network for oracle\ncharacter recognition.",
      "authors": "Mei Wang, Weihong Deng, and Cheng-Lin Liu. 2022.",
      "journal": "IEEE Trans. Image Process., 31:3137\u20133150."
    },
    {
      "tag": "Dai et\u00a0al. (2017)",
      "title": "Deformable convolutional networks.",
      "authors": "Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi\u00a0Li, Guodong Zhang, Han Hu, and Yichen\nWei. 2017.",
      "journal": "InProc. IEEE Int. Conf. Comp. Vis., pages 764\u2013773."
    },
    {
      "tag": "Huang et\u00a0al. (2019)",
      "title": "Obc306: A large-scale oracle bone character recognition dataset.",
      "authors": "Shuangping Huang, Haobin Wang, Yongge Liu, Xiaosong Shi, and Lianwen Jin. 2019.",
      "journal": "InProc. Int. Conf. Doc. Anal. and Recognit., pages 681\u2013688.\nIEEE."
    },
    {
      "tag": "Guo et\u00a0al. (2015)",
      "title": "Building hierarchical representations for oracle character and sketch\nrecognition.",
      "authors": "Jun Guo, Changhu Wang, Edgar Roman-Rangel, Hongyang Chao, and Yong Rui. 2015.",
      "journal": "IEEE Trans. Image Process., 25(1):104\u2013118."
    },
    {
      "tag": "Zhang et\u00a0al. (2019)",
      "title": "Oracle character recognition by nearest neighbor classification with\ndeep metric learning.",
      "authors": "Yi-Kang Zhang, Heng Zhang, Yong-Ge Liu, Qing Yang, and Cheng-Lin Liu. 2019.",
      "journal": "InProc. Int. Conf. Doc. Anal. and Recognit., pages 309\u2013314.\nIEEE."
    },
    {
      "tag": "Guan et\u00a0al. (2024)",
      "title": "An open dataset for the evolution of oracle bone characters: Evobc.",
      "authors": "Haisu Guan, Jinpeng Wan, Yuliang Liu, Pengjie Wang, Kaile Zhang, Zhebin Kuang,\nXinyu Wang, Xiang Bai, and Lianwen Jin. 2024.",
      "journal": "arXiv preprint arXiv:2401.12467."
    },
    {
      "tag": "Liu et\u00a0al. (2019)",
      "title": "Roberta: A robustly optimized bert pretraining approach.",
      "authors": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer\nLevy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.",
      "journal": "arXiv preprint arXiv:1907.11692."
    },
    {
      "tag": "Nuhn et\u00a0al. (2012)",
      "title": "Deciphering foreign language by combining language models and context\nvectors.",
      "authors": "Malte Nuhn, Arne Mauser, and Hermann Ney. 2012.",
      "journal": "InProc. Annu. Meet. Assoc. Comput. Linguist., pages 156\u2013164."
    },
    {
      "tag": "Sommerschield et\u00a0al. (2023)",
      "title": "Machine learning for ancient languages: A survey.",
      "authors": "Thea Sommerschield, Yannis Assael, John Pavlopoulos, Vanessa Stefanak, Andrew\nSenior, Chris Dyer, John Bodel, Jonathan Prag, Ion Androutsopoulos, and Nando\nde\u00a0Freitas. 2023.",
      "journal": "Comput. Linguist., pages 1\u201344."
    },
    {
      "tag": "Nilsson and Akenine-M\u00f6ller (2020)",
      "title": "Understanding ssim.",
      "authors": "Jim Nilsson and Tomas Akenine-M\u00f6ller. 2020.",
      "journal": "arXiv preprint arXiv:2006.13846."
    },
    {
      "tag": "Hu (2023)",
      "title": "Coding design of oracle bone inscriptions input method based on\n\u201czhonghuaziku\u201d database.",
      "authors": "Dongxin Hu. 2023.",
      "journal": "InProc. Annu. Meet. Assoc. Comput. Linguist. Workshop, pages\n138\u2013147."
    },
    {
      "tag": "Brown et\u00a0al. (2020)",
      "title": "Language models are few-shot learners.",
      "authors": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared\u00a0D Kaplan, Prafulla\nDhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\net\u00a0al. 2020.",
      "journal": "Proc. Advances in Neural Inf. Process. Syst., 33:1877\u20131901."
    },
    {
      "tag": "Wang et\u00a0al. (2024)",
      "title": "An open dataset for oracle bone script recognition and decipherment.",
      "authors": "Pengjie Wang, Kaile Zhang, Yuliang Liu, Jinpeng Wan, Haisu Guan, Zhebin Kuang,\nXinyu Wang, Lianwen Jin, and Xiang Bai. 2024.",
      "journal": "arXiv preprint arXiv:2401.15365."
    },
    {
      "tag": "Chang et\u00a0al. (2022)",
      "title": "Sundial-gan: A cascade generative adversarial networks framework for\ndeciphering oracle bone inscriptions.",
      "authors": "Xiang Chang, Fei Chao, Changjing Shang, and Qiang Shen. 2022.",
      "journal": "InProc. ACM Int. Conf. Multimedia, pages 1195\u20131203."
    },
    {
      "tag": "Fu et\u00a0al. (2022)",
      "title": "Improvement of oracle bone inscription recognition accuracy: A deep\nlearning perspective.",
      "authors": "Xuanming Fu, Zhengfeng Yang, Zhenbing Zeng, Yidan Zhang, and Qianting Zhou.\n2022.",
      "journal": "ISPRS International Journal of Geo-Information, 11(1):45."
    },
    {
      "tag": "Qi et\u00a0al. (2023)",
      "title": "Vector based stylistic analysis on ancient chinese books: Take the\nthree commentaries on the spring and autumn annals as an example.",
      "authors": "Yue Qi, Liu Liu, Bin Li, and Dongbo Wang. 2023.",
      "journal": "InProc. Annu. Meet. Assoc. Comput. Linguist. Workshop, pages\n117\u2013121."
    },
    {
      "tag": "Ravi and Knight (2011)",
      "title": "Deciphering foreign language.",
      "authors": "Sujith Ravi and Kevin Knight. 2011.",
      "journal": "InProc. Annu. Meet. Assoc. Comput. Linguist., pages 12\u201321."
    },
    {
      "tag": "Saharia et\u00a0al. (2022a)",
      "title": "Palette: Image-to-image diffusion models.",
      "authors": "Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim\nSalimans, David Fleet, and Mohammad Norouzi. 2022a.",
      "journal": "InACM SIGGRAPH 2022 Conference Proceedings, pages 1\u201310."
    },
    {
      "tag": "Li et\u00a0al. (2023)",
      "title": "Bbdm: Image-to-image translation with brownian bridge diffusion\nmodels.",
      "authors": "Bo\u00a0Li, Kaitao Xue, Bin Liu, and Yu-Kun Lai. 2023.",
      "journal": "InProc. IEEE Conf. Comp. Vis. Patt. Recogn., pages\n1952\u20131961."
    },
    {
      "tag": "Yang et\u00a0al. (2024)",
      "title": "Fontdiffuser: One-shot font generation via denoising diffusion with\nmulti-scale content aggregation and style contrastive learning.",
      "authors": "Zhenhua Yang, Dezhi Peng, Yuxin Kong, Yuyi Zhang, Cong Yao, and Lianwen Jin.\n2024.",
      "journal": "InProc. AAAI Conf. Artificial Intell."
    },
    {
      "tag": "Zhu et\u00a0al. (2017)",
      "title": "Unpaired image-to-image translation using cycle-consistent\nadversarial networks.",
      "authors": "Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei\u00a0A Efros. 2017.",
      "journal": "InProc. IEEE Int. Conf. Comp. Vis., pages 2223\u20132232."
    },
    {
      "tag": "Devlin et\u00a0al. (2018)",
      "title": "Bert: Pre-training of deep bidirectional transformers for language\nunderstanding.",
      "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.",
      "journal": "Proc. Annu. Conf. North Am. Chapter Assoc. Comput. Linguist."
    },
    {
      "tag": "Yang and Fu (2020)",
      "title": "Oracle detection and recognition based on improved tiny-yolov4.",
      "authors": "Zhen Yang and Ting Fu. 2020.",
      "journal": "InProceedings of the 2020 4th International Conference on\nVideo and Image Processing, pages 128\u2013133."
    },
    {
      "tag": "Zhang et\u00a0al. (2022)",
      "title": "Data-driven oracle bone rejoining: A dataset and practical\nself-supervised learning scheme.",
      "authors": "Chongsheng Zhang, Bin Wang, Ke\u00a0Chen, Ruixing Zong, Bo-feng Mo, Yi\u00a0Men, George\nAlmpanidis, Shanxiong Chen, and Xiangliang Zhang. 2022.",
      "journal": "InProc. ACM SIGKDD Int. Conf. Knowledge discovery & data\nmining, pages 4482\u20134492."
    },
    {
      "tag": "Zhang et\u00a0al. (2021b)",
      "title": "Deciphering ancient chinese oracle bone inscriptions using case-based\nreasoning.",
      "authors": "Gechuan Zhang, Dairui Liu, Barry Smyth, and Ruihai Dong. 2021b.",
      "journal": "InInternational Conference on Case-Based Reasoning, pages\n309\u2013324. Springer."
    },
    {
      "tag": "Jin et\u00a0al. (2023)",
      "title": "Morphological and semantic evaluation of ancient chinese machine\ntranslation.",
      "authors": "Kai Jin, Dan Zhao, and Wuying Liu. 2023.",
      "journal": "InProc. Annu. Meet. Assoc. Comput. Linguist. Workshop, pages\n96\u2013102."
    },
    {
      "tag": "Ronneberger et\u00a0al. (2015)",
      "title": "U-net: Convolutional networks for biomedical image segmentation.",
      "authors": "Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015.",
      "journal": "InProc. Int. Conf. Med. Image Comput. Comput. Assist.\nIntervent., pages 234\u2013241. Springer."
    },
    {
      "tag": "Wang and Deng (2024)",
      "title": "A dataset of oracle characters for benchmarking machine learning\nalgorithms.",
      "authors": "Mei Wang and Weihong Deng. 2024.",
      "journal": "Scientific Data, 11(1):87."
    },
    {
      "tag": "Lee et\u00a0al. (2020)",
      "title": "Drit++: Diverse image-to-image translation via disentangled\nrepresentations.",
      "authors": "Hsin-Ying Lee, Hung-Yu Tseng, Qi\u00a0Mao, Jia-Bin Huang, Yu-Ding Lu, Maneesh Singh,\nand Ming-Hsuan Yang. 2020.",
      "journal": "Int. J. Comput. Vis., 128:2402\u20132417."
    },
    {
      "tag": "Li et\u00a0al. (2020)",
      "title": "Hwobc-a handwriting oracle bone character recognition database.",
      "authors": "Bang Li, Qianwen Dai, Feng Gao, Weiye Zhu, Qiang Li, and Yongge Liu. 2020.",
      "journal": "InJournal of Physics: Conference Series."
    },
    {
      "tag": "Saharia et\u00a0al. (2022b)",
      "title": "Image super-resolution via iterative refinement.",
      "authors": "Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David\u00a0J Fleet, and\nMohammad Norouzi. 2022b.",
      "journal": "IEEE Trans. Pattern Anal. Mach. Intell., 45(4):4713\u20134726."
    },
    {
      "tag": "Han et\u00a0al. (2020)",
      "title": "Isobs: An information system for oracle bone script.",
      "authors": "Xu\u00a0Han, Yuzhuo Bai, Keyue Qiu, Zhiyuan Liu, and Maosong Sun. 2020.",
      "journal": "InProc. Conf. Empir. Methods in Natural Language Process.,\npages 227\u2013233."
    },
    {
      "tag": "Ho et\u00a0al. (2020)",
      "title": "Denoising diffusion probabilistic models.",
      "authors": "Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020.",
      "journal": "Proc. Advances in Neural Inf. Process. Syst., 33:6840\u20136851."
    },
    {
      "tag": "Jiang et\u00a0al. (2023)",
      "title": "Oraclepoints: A hybrid neural representation for oracle character.",
      "authors": "Runhua Jiang, Yongge Liu, Boyuan Zhang, Xu\u00a0Chen, Deng Li, and Yahong Han. 2023.",
      "journal": "InProc. ACM Int. Conf. Multimedia, pages 7901\u20137911."
    },
    {
      "tag": "Zhang et\u00a0al. (2021a)",
      "title": "Ai-powered oracle bone inscriptions recognition and fragments\nrejoining.",
      "authors": "Chongsheng Zhang, Ruixing Zong, Shuang Cao, Yi\u00a0Men, and Bofeng Mo.\n2021a.",
      "journal": "InProc. Int. Joint Conf. Artificial Intell., pages\n5309\u20135311."
    }
  ]
}