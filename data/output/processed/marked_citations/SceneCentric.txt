Approaches for unsupervised segmentation tasks have been
significantly influenced by the literature on self-supervised
learning (SSL) and low-level vision tasks (e.g., optical flow
estimation), which we review first.
Self-supervised representation learning focuses on learn-
ing generic feature extractors from unlabeled data, aiming
for expressive features that facilitate a broad range of down-
stream tasks [CITATION_0]. To that end, various self-supervised pre-
text tasks have been proposed [CITATION_1]. The development
of Vision Transformers (ViTs) [CITATION_2] shaped current pretext
tasks while allowing for data-scalable training [CITATION_3].
Current approaches typically train ViTs on contrastive [CITATION_4], negative-free [CITATION_5], clustering-
based [CITATION_6], or masked modeling [CITATION_7] pretext
tasks. Recent state-of-the-art models (e.g., DINO [CITATION_8]) of-
fer semantically rich and dense features suitable for unsu-
pervised scene understanding [CITATION_9].

Unsupervised optical flow is concerned with learning op-
tical flow estimation without the need for ground-truth data.
While early deep networks relied on synthetic ground-truth
flow for supervision [CITATION_10], the domain gap to real
videos, among other factors, has prompted the development
of unsupervised deep optical flow pipelines [CITATION_11]. Current unsupervised optical flow methods (e.g.,
SMURF [CITATION_12]) offer accurate flow estimates, fast inference,
and generalization to various real-world domains.

Unsupervised instance segmentation aims to discover and
segment object instances in images [CITATION_13]. Recent work
[CITATION_14] bootstraps class-agnostic instance segmen-
tation networks using pseudo labels extracted from SSL fea-
tures on object-centric data. TokenCut [CITATION_15] applies normal-
ized cuts [N-Cut, 61] to DINO features, providing a fore-
ground pseudo mask. CutLER [CITATION_16] proposes MaskCut by
iteratively applying N-Cuts, retrieving up to three pseudo
masks per image. A second stream of works uses motion
cues to obtain an unsupervised signal for object discov-
ery [CITATION_17]. SF2SE3 [CITATION_18] clusters scene
flow from consecutive stereo frames into independent rigid
object motions in SE (3) space, improving object segmen-
tation and motion accuracy. MOD-UV [CITATION_19] uses motion
segmentation for pseudo labeling and multi-stage training.

Unsupervised semantic segmentation is approached by
early deep learning methods via representation learning
[CITATION_20]. STEGO [CITATION_21] leverages the self-supervised
DINO features as an inductive prior and distills the fea-
tures into a lower-dimensional space before unsupervised
probing. Later, [CITATION_22] proposed improvements to the
feature distillation or probing [CITATION_23]. DepthG [CITATION_24] extends
STEGO by spatially correlating the feature maps with depth
maps and furthest point sampling in the contrastive loss.
DiffSeg [CITATION_25] utilizes Stable Diffusion [CITATION_26] and iterative at-
tention merging for unsupervised semantic segmentation.

Unsupervised panoptic segmentation is a nascent re-
search avenue following recent advancements in unsuper-
vised semantic and instance segmentation. To the best of
our knowledge, U2Seg [CITATION_27] is the only method to date to approach unsupervised panoptic segmentation. U2Seg
leverages STEGO [CITATION_28] and CutLER [CITATION_29] to create panoptic
pseudo labels for training a panoptic network. However, its
dependence on CutLERâ€™s MaskCut approach significantly
In contrast, we
limits its accuracy on scene-centric data.
present the first unsupervised panoptic approach that learns
directly from scene-centric data, addressing key limitations
of U2Seg and MaskCut.
