{
  "content": [
    [
      "Qwen-vl: A versatile vision-language model for understand- ing, localization, text reading, and beyond",
      "Llava-onevision: Easy visual task transfer",
      "Vila: On pre-training for visual language models, 2023",
      "Improved baselines with visual instruction tuning",
      "Llava-next: Improved reason- ing, ocr, and world knowledge, 2024",
      "Visual instruction tuning",
      "Oryx mllm: On-demand spatial- temporal understanding at arbitrary resolution",
      "Deepseek-vl: towards real-world vision-language understanding",
      "Qwen2-vl: To see the world more clearly"
    ],
    [
      "Vila: On pre-training for visual language models, 2023",
      "Qwen2-vl: To see the world more clearly"
    ],
    [
      "Unimath: A foundational and multimodal mathe- matical reasoner"
    ],
    [
      "Internvl: Scaling up vision foundation mod- els and aligning for generic visual-linguistic tasks"
    ],
    [
      "Mon- key: Image resolution and text label are important things for large multi-modal models",
      "Llava-next: Improved reason- ing, ocr, and world knowledge, 2024",
      "Chain-of-spot: Interactive reasoning improves large vision-language models",
      "Cambrian-1: A fully open, vision-centric exploration of multimodal llms",
      "Llava-uhd: an lmm perceiving any aspect ratio and high-resolution images"
    ],
    [
      "G-llava: Solving geometric prob- lem with multi-modal large language model",
      "Mavis: Mathematical visual in- struction tuning",
      "Improve vision language model chain-of-thought reasoning"
    ],
    [
      "Chain-of- thought prompting elicits reasoning in large language models"
    ],
    [
      "Training a helpful and harmless assistant with reinforcement learning from human feedback"
    ],
    [
      "Direct prefer- ence optimization: Your language model is secretly a reward model"
    ],
    [
      "Self-play fine-tuning converts weak lan- guage models to strong language models"
    ]
  ],
  "positions": [
    61,
    169,
    183,
    209,
    278,
    507,
    552,
    1562,
    1767,
    2136
  ]
}