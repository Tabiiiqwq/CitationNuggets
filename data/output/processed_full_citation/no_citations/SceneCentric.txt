Approaches for unsupervised segmentation tasks have been
significantly influenced by the literature on self-supervised
learning (SSL) and low-level vision tasks (e.g., optical flow
estimation), which we review first.
Self-supervised representation learning focuses on learn-
ing generic feature extractors from unlabeled data, aiming
for expressive features that facilitate a broad range of down-
stream tasks . To that end, various self-supervised pre-
text tasks have been proposed . The development
of Vision Transformers (ViTs)  shaped current pretext
tasks while allowing for data-scalable training .
Current approaches typically train ViTs on contrastive , negative-free , clustering-
based , or masked modeling  pretext
tasks. Recent state-of-the-art models (e.g., DINO ) of-
fer semantically rich and dense features suitable for unsu-
pervised scene understanding .

Unsupervised optical flow is concerned with learning op-
tical flow estimation without the need for ground-truth data.
While early deep networks relied on synthetic ground-truth
flow for supervision , the domain gap to real
videos, among other factors, has prompted the development
of unsupervised deep optical flow pipelines . Current unsupervised optical flow methods (e.g.,
SMURF ) offer accurate flow estimates, fast inference,
and generalization to various real-world domains.

Unsupervised instance segmentation aims to discover and
segment object instances in images . Recent work
 bootstraps class-agnostic instance segmen-
tation networks using pseudo labels extracted from SSL fea-
tures on object-centric data. TokenCut  applies normal-
ized cuts [N-Cut, 61] to DINO features, providing a fore-
ground pseudo mask. CutLER  proposes MaskCut by
iteratively applying N-Cuts, retrieving up to three pseudo
masks per image. A second stream of works uses motion
cues to obtain an unsupervised signal for object discov-
ery . SF2SE3  clusters scene
flow from consecutive stereo frames into independent rigid
object motions in SE (3) space, improving object segmen-
tation and motion accuracy. MOD-UV  uses motion
segmentation for pseudo labeling and multi-stage training.

Unsupervised semantic segmentation is approached by
early deep learning methods via representation learning
. STEGO  leverages the self-supervised
DINO features as an inductive prior and distills the fea-
tures into a lower-dimensional space before unsupervised
probing. Later,  proposed improvements to the
feature distillation or probing . DepthG  extends
STEGO by spatially correlating the feature maps with depth
maps and furthest point sampling in the contrastive loss.
DiffSeg  utilizes Stable Diffusion  and iterative at-
tention merging for unsupervised semantic segmentation.

Unsupervised panoptic segmentation is a nascent re-
search avenue following recent advancements in unsuper-
vised semantic and instance segmentation. To the best of
our knowledge, U2Seg  is the only method to date to approach unsupervised panoptic segmentation. U2Seg
leverages STEGO  and CutLER  to create panoptic
pseudo labels for training a panoptic network. However, its
dependence on CutLERâ€™s MaskCut approach significantly
In contrast, we
limits its accuracy on scene-centric data.
present the first unsupervised panoptic approach that learns
directly from scene-centric data, addressing key limitations
of U2Seg and MaskCut.

